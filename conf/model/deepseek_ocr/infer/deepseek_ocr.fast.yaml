# Fast inference profile: low token budget, deterministic
temperature: 0.0
max_new_tokens: 256
no_repeat_ngram_size: 0
do_sample: false
