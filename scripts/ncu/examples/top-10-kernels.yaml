# Top kernels extracted from Nsight Systems profiling
# Source: summary_cuda_gpu_kern_sum.csv
# Sorted by: time_pct (column: Time (%))
# Format: each kernel has full name and regex pattern
# The regex pattern is used for ncu --kernel-name filtering
#
# NOTE: The regex patterns below use re.escape() for exact matching.
# You may want to manually edit these patterns to match kernel families
# instead of exact instances. For example:
#   - Exact: 'internal::gemvx::kernel<...>(int)7...' (matches one variant)
#   - Family: '.*internal::gemvx::kernel<.*\(int\)7.*>' (matches all (int)7 variants)
kernels:
-   name: std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, __nv_bfloat16, __nv_bfloat16, __nv_bfloat16, float, (bool)0, (bool)1, (bool)1, (bool)0, (int)7, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const __nv_bfloat16>, cublasGemvTensorStridedBatched<const __nv_bfloat16>, cublasGemvTensorStridedBatched<__nv_bfloat16>, float>>(T13)
    regex: ^std::enable_if<!T7,\ void>::type\ internal::gemvx::kernel<int,\ int,\ __nv_bfloat16,\ __nv_bfloat16,\ __nv_bfloat16,\ float,\ \(bool\)0,\ \(bool\)1,\ \(bool\)1,\ \(bool\)0,\ \(int\)7,\ \(bool\)0,\ cublasGemvParamsEx<int,\ cublasGemvTensorStridedBatched<const\ __nv_bfloat16>,\ cublasGemvTensorStridedBatched<const\ __nv_bfloat16>,\ cublasGemvTensorStridedBatched<__nv_bfloat16>,\ float>>\(T13\)$
    description: 'Kernel #1 - 30.0% of GPU time, 51146 calls'
-   name: std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, __nv_bfloat16, __nv_bfloat16, __nv_bfloat16, float, (bool)0, (bool)1, (bool)1, (bool)0, (int)6, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const __nv_bfloat16>, cublasGemvTensorStridedBatched<const __nv_bfloat16>, cublasGemvTensorStridedBatched<__nv_bfloat16>, float>>(T13)
    regex: ^std::enable_if<!T7,\ void>::type\ internal::gemvx::kernel<int,\ int,\ __nv_bfloat16,\ __nv_bfloat16,\ __nv_bfloat16,\ float,\ \(bool\)0,\ \(bool\)1,\ \(bool\)1,\ \(bool\)0,\ \(int\)6,\ \(bool\)0,\ cublasGemvParamsEx<int,\ cublasGemvTensorStridedBatched<const\ __nv_bfloat16>,\ cublasGemvTensorStridedBatched<const\ __nv_bfloat16>,\ cublasGemvTensorStridedBatched<__nv_bfloat16>,\ float>>\(T13\)$
    description: 'Kernel #2 - 12.9% of GPU time, 7164 calls'
-   name: void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>, (int)4, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T4, T5, T6, T7)
    regex: ^void\ at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda\(at::TensorIteratorBase\ \&\)::\[lambda\(\)\ \(instance\ 3\)\]::operator\ \(\)\(\)\ const::\[lambda\(\)\ \(instance\ 7\)\]::operator\ \(\)\(\)\ const::\[lambda\(float\)\ \(instance\ 1\)\],\ std::array<char\ \*,\ \(unsigned\ long\)2>,\ \(int\)4,\ TrivialOffsetCalculator<\(int\)1,\ unsigned\ int>,\ TrivialOffsetCalculator<\(int\)1,\ unsigned\ int>,\ at::native::memory::LoadWithCast<\(int\)1>,\ at::native::memory::StoreWithCast<\(int\)1>>\(int,\ T1,\ T2,\ T4,\ T5,\ T6,\ T7\)$
    description: 'Kernel #3 - 5.4% of GPU time, 19158 calls'
-   name: void at::native::vectorized_elementwise_kernel<(int)4, at::native::bfloat16_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda(float) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3)
    regex: ^void\ at::native::vectorized_elementwise_kernel<\(int\)4,\ at::native::bfloat16_copy_kernel_cuda\(at::TensorIteratorBase\ \&\)::\[lambda\(float\)\ \(instance\ 1\)\],\ std::array<char\ \*,\ \(unsigned\ long\)2>>\(int,\ T2,\ T3\)$
    description: 'Kernel #4 - 4.6% of GPU time, 19330 calls'
-   name: void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<c10::BFloat16, c10::BFloat16, c10::BFloat16, at::native::binary_internal::MulFunctor<float>>, std::array<char *, (unsigned long)3>>(int, T2, T3)
    regex: ^void\ at::native::vectorized_elementwise_kernel<\(int\)4,\ at::native::BinaryFunctor<c10::BFloat16,\ c10::BFloat16,\ c10::BFloat16,\ at::native::binary_internal::MulFunctor<float>>,\ std::array<char\ \*,\ \(unsigned\ long\)3>>\(int,\ T2,\ T3\)$
    description: 'Kernel #5 - 3.7% of GPU time, 21213 calls'
-   name: void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 6)]::operator ()() const::[lambda(c10::BFloat16) (instance 1)], std::array<char *, (unsigned long)2>>(int, T2, T3)
    regex: ^void\ at::native::vectorized_elementwise_kernel<\(int\)4,\ at::native::<unnamed>::silu_kernel\(at::TensorIteratorBase\ \&\)::\[lambda\(\)\ \(instance\ 1\)\]::operator\ \(\)\(\)\ const::\[lambda\(\)\ \(instance\ 6\)\]::operator\ \(\)\(\)\ const::\[lambda\(c10::BFloat16\)\ \(instance\ 1\)\],\ std::array<char\ \*,\ \(unsigned\ long\)2>>\(int,\ T2,\ T3\)$
    description: 'Kernel #6 - 3.6% of GPU time, 16238 calls'
-   name: void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::BFloat16, c10::BFloat16, c10::BFloat16, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)
    regex: ^void\ at::native::elementwise_kernel<\(int\)128,\ \(int\)4,\ void\ at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<c10::BFloat16,\ c10::BFloat16,\ c10::BFloat16,\ at::native::binary_internal::MulFunctor<float>>>\(at::TensorIteratorBase\ \&,\ const\ T1\ \&\)::\[lambda\(int\)\ \(instance\ 1\)\]>\(int,\ T3\)$
    description: 'Kernel #7 - 2.6% of GPU time, 9625 calls'
-   name: void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(T1::Params)
    regex: ^void\ cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>\(T1::Params\)$
    description: 'Kernel #8 - 2.6% of GPU time, 2067 calls'
-   name: void flash::flash_fwd_splitkv_kernel<Flash_fwd_kernel_traits<(int)128, (int)64, (int)128, (int)4, (bool)0, (bool)0, cutlass::bfloat16_t, Flash_kernel_traits<(int)128, (int)64, (int)128, (int)4, cutlass::bfloat16_t>>, (bool)0, (bool)0, (bool)0, (bool)0, (bool)1, (bool)0, (bool)1, (bool)0>(flash::Flash_fwd_params)
    regex: ^void\ flash::flash_fwd_splitkv_kernel<Flash_fwd_kernel_traits<\(int\)128,\ \(int\)64,\ \(int\)128,\ \(int\)4,\ \(bool\)0,\ \(bool\)0,\ cutlass::bfloat16_t,\ Flash_kernel_traits<\(int\)128,\ \(int\)64,\ \(int\)128,\ \(int\)4,\ cutlass::bfloat16_t>>,\ \(bool\)0,\ \(bool\)0,\ \(bool\)0,\ \(bool\)0,\ \(bool\)1,\ \(bool\)0,\ \(bool\)1,\ \(bool\)0>\(flash::Flash_fwd_params\)$
    description: 'Kernel #9 - 2.1% of GPU time, 2388 calls'
-   name: void at::native::<unnamed>::CatArrayBatchedCopy_vectorized<at::native::<unnamed>::OpaqueType<(unsigned int)2>, unsigned int, (int)3, (int)128, (int)1, (int)16, (int)8>(char *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)
    regex: ^void\ at::native::<unnamed>::CatArrayBatchedCopy_vectorized<at::native::<unnamed>::OpaqueType<\(unsigned\ int\)2>,\ unsigned\ int,\ \(int\)3,\ \(int\)128,\ \(int\)1,\ \(int\)16,\ \(int\)8>\(char\ \*,\ at::native::<unnamed>::CatArrInputTensorMetadata<T1,\ T2,\ T4,\ T5>,\ at::native::<unnamed>::TensorSizeStride<T2,\ \(unsigned\ int\)4>,\ int,\ T2\)$
    description: 'Kernel #10 - 2.1% of GPU time, 4752 calls'
