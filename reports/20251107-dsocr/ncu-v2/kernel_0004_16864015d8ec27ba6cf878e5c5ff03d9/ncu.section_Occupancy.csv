"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Max Active Clusters","cluster","0",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Max Cluster Size","block","8",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Overall GPU Occupancy","%","0",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Cluster Occupancy","%","0",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Block Limit Barriers","block","24",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Block Limit SM","block","24",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Block Limit Registers","block","16",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Block Limit Shared Mem","block","32",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Block Limit Warps","block","12",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Theoretical Active Warps per SM","warp","48",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Theoretical Occupancy","%","100",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Achieved Occupancy","%","8.31",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","Achieved Active Warps Per SM","warp","3.99",
"0","1742248","python3.12","127.0.0.1","void unrolled_elementwise_kernel<direct_copy_kernel_cuda(TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() lambda() (instance 7)]::operator ()() lambda(float) (instance 1)], array<char *, 2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, LoadWithCast<1>, StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)","1","7","(128, 1, 1)","(2, 1, 1)","0","12.0","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (8.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","91.69"
