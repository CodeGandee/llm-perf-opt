"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","DRAM Frequency","Ghz","13.77",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","SM Frequency","Ghz","1.99",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","46,970",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","Memory Throughput","%","61.83",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.13",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","Duration","us","23.42",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","49.23",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","61.83",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","39,578.42",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","41.49",
"0","1741703","python3.12","127.0.0.1","void Kernel2<cutlass_80_wmma_tensorop_bf16_s161616gemm_bf16_32x32_128x2_tn_align8>(Params)","1","7","(128, 1, 1)","(152, 4, 1)","0","12.0","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
