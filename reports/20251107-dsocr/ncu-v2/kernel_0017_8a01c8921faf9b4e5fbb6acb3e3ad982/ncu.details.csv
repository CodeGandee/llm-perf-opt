"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","dram__bytes_read.sum","Mbyte","2.34",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","dram__bytes_write.sum","byte","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","dram__throughput.avg.pct_of_peak_sustained_elapsed","%","13.59",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","flop_count_hp.sum","","n/a",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","flop_count_sp.sum","","n/a",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","gpu__time_duration.sum","us","9.82",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","sm__ops_path_tensor_src_bf16_dst_bf16.sum","","n/a",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","sm__ops_path_tensor_src_bf16_dst_fp32.sum","","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Command line profiler metrics","sm__throughput.avg.pct_of_peak_sustained_elapsed","%","38.78",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","DRAM Frequency","Ghz","13.71",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","SM Frequency","Ghz","1.99",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","19,706",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","Memory Throughput","%","13.59",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","DRAM Throughput","%","13.59",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","Duration","us","9.82",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","12.15",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","13.27",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","15,200.74",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","38.78",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","SpeedOfLight","","","","SOLBottleneck","OPT","This workload exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.","",""
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The workload achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","Memory Throughput","Gbyte/s","238.46",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","Mem Busy","%","8.94",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","Max Bandwidth","%","13.59",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","L1/TEX Hit Rate","%","25",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","L2 Hit Rate","%","25.39",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Memory Workload Analysis","Mem Pipes Busy","%","16.33",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Scheduler Statistics","One or More Eligible","%","51.82",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.52",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Scheduler Statistics","No Eligible","%","48.18",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.64",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","1.81",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this workload each scheduler only issues an instruction every 1.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this workload allocates an average of 9.64 active warps per scheduler, but only an average of 1.81 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","48.18"
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Max Active Clusters","cluster","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Max Cluster Size","block","8",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Overall GPU Occupancy","%","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Cluster Occupancy","%","0",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Block Limit Barriers","block","24",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Block Limit SM","block","24",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Block Limit Registers","block","3",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Block Limit Shared Mem","block","8",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Block Limit Warps","block","3",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Theoretical Active Warps per SM","warp","48",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Theoretical Occupancy","%","100",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Achieved Occupancy","%","77.47",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","Achieved Active Warps Per SM","warp","37.18",
"0","1749636","python3.12","127.0.0.1","void unnamed>::CatArrayBatchedCopy<unnamed>::OpaqueType<2>, unsigned int, 4, 64, 64>(T1 *, unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, unnamed>::TensorSizeStride<T2, 4>, int, T2)","1","7","(512, 1, 1)","(340, 2, 1)","0","12.0","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (77.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","22.53"
