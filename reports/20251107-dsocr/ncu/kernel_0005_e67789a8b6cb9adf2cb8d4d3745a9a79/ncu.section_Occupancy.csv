"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Max Active Clusters","cluster","0",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Max Cluster Size","block","8",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Overall GPU Occupancy","%","0",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Cluster Occupancy","%","0",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Block Limit Barriers","block","24",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Block Limit SM","block","24",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Block Limit Registers","block","1",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Block Limit Shared Mem","block","1",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Block Limit Warps","block","6",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Theoretical Active Warps per SM","warp","8",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Theoretical Occupancy","%","16.67",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Achieved Occupancy","%","16.51",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","Achieved Active Warps Per SM","warp","7.93",
"0","1704452","python3.12","127.0.0.1","void Kernel2<cutlass_80_tensorop_bf16_s16816gemm_relu_bf16_256x128_32x3_tn_align8>(Params)","1","7","(256, 1, 1)","(312, 2, 1)","0","12.0","Occupancy","","","","TheoreticalOccupancy","OPT","The 2.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 12. This kernel's theoretical occupancy (16.7%) is limited by the number of required registers, and the required amount of shared memory.","global","69.29"
