digraph dsocr_hooks {
  rankdir=LR;
  "model" [label="DeepseekOCRModel @ model\nout [1, 323, 1280] torch.bfloat16"];
  "model.embed_tokens" [label="Embedding @ model.embed_tokens\nin [1, 323] torch.int64 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0" [label="DeepseekV2DecoderLayer @ model.layers.0\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.0.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.mlp" [label="DeepseekV2MLP @ model.layers.0.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.mlp.act_fn" [label="SiLU @ model.layers.0.mlp.act_fn\nin [1, 323, 6848] torch.bfloat16 | out [1, 323, 6848] torch.bfloat16"];
  "model.layers.0.mlp.down_proj" [label="Linear @ model.layers.0.mlp.down_proj\nin [1, 323, 6848] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.mlp.gate_proj" [label="Linear @ model.layers.0.mlp.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 6848] torch.bfloat16"];
  "model.layers.0.mlp.up_proj" [label="Linear @ model.layers.0.mlp.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 6848] torch.bfloat16"];
  "model.layers.0.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.0.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.self_attn" [label="LlamaFlashAttention2 @ model.layers.0.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.self_attn.k_proj" [label="Linear @ model.layers.0.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.self_attn.o_proj" [label="Linear @ model.layers.0.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.self_attn.q_proj" [label="Linear @ model.layers.0.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.0.self_attn.v_proj" [label="Linear @ model.layers.0.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1" [label="DeepseekV2DecoderLayer @ model.layers.1\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.1.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.mlp" [label="DeepseekV2MoE @ model.layers.1.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.0\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.0.act_fn" [label="SiLU @ model.layers.1.mlp.experts.0.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.0.down_proj" [label="Linear @ model.layers.1.mlp.experts.0.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.0.gate_proj" [label="Linear @ model.layers.1.mlp.experts.0.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.0.up_proj" [label="Linear @ model.layers.1.mlp.experts.0.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.1\nin [57, 1280] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.1.act_fn" [label="SiLU @ model.layers.1.mlp.experts.1.act_fn\nin [57, 896] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.1.down_proj" [label="Linear @ model.layers.1.mlp.experts.1.down_proj\nin [57, 896] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.1.gate_proj" [label="Linear @ model.layers.1.mlp.experts.1.gate_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.1.up_proj" [label="Linear @ model.layers.1.mlp.experts.1.up_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.10\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.10.act_fn" [label="SiLU @ model.layers.1.mlp.experts.10.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.10.down_proj" [label="Linear @ model.layers.1.mlp.experts.10.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.10.gate_proj" [label="Linear @ model.layers.1.mlp.experts.10.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.10.up_proj" [label="Linear @ model.layers.1.mlp.experts.10.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.11\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.11.act_fn" [label="SiLU @ model.layers.1.mlp.experts.11.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.11.down_proj" [label="Linear @ model.layers.1.mlp.experts.11.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.11.gate_proj" [label="Linear @ model.layers.1.mlp.experts.11.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.11.up_proj" [label="Linear @ model.layers.1.mlp.experts.11.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.12\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.12.act_fn" [label="SiLU @ model.layers.1.mlp.experts.12.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.12.down_proj" [label="Linear @ model.layers.1.mlp.experts.12.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.12.gate_proj" [label="Linear @ model.layers.1.mlp.experts.12.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.12.up_proj" [label="Linear @ model.layers.1.mlp.experts.12.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.14\nin [43, 1280] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.14.act_fn" [label="SiLU @ model.layers.1.mlp.experts.14.act_fn\nin [43, 896] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.14.down_proj" [label="Linear @ model.layers.1.mlp.experts.14.down_proj\nin [43, 896] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.14.gate_proj" [label="Linear @ model.layers.1.mlp.experts.14.gate_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.14.up_proj" [label="Linear @ model.layers.1.mlp.experts.14.up_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.15\nin [57, 1280] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.15.act_fn" [label="SiLU @ model.layers.1.mlp.experts.15.act_fn\nin [57, 896] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.15.down_proj" [label="Linear @ model.layers.1.mlp.experts.15.down_proj\nin [57, 896] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.15.gate_proj" [label="Linear @ model.layers.1.mlp.experts.15.gate_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.15.up_proj" [label="Linear @ model.layers.1.mlp.experts.15.up_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.16\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.16.act_fn" [label="SiLU @ model.layers.1.mlp.experts.16.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.16.down_proj" [label="Linear @ model.layers.1.mlp.experts.16.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.16.gate_proj" [label="Linear @ model.layers.1.mlp.experts.16.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.16.up_proj" [label="Linear @ model.layers.1.mlp.experts.16.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.17\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.17.act_fn" [label="SiLU @ model.layers.1.mlp.experts.17.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.17.down_proj" [label="Linear @ model.layers.1.mlp.experts.17.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.17.gate_proj" [label="Linear @ model.layers.1.mlp.experts.17.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.17.up_proj" [label="Linear @ model.layers.1.mlp.experts.17.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.18\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.18.act_fn" [label="SiLU @ model.layers.1.mlp.experts.18.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.18.down_proj" [label="Linear @ model.layers.1.mlp.experts.18.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.18.gate_proj" [label="Linear @ model.layers.1.mlp.experts.18.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.18.up_proj" [label="Linear @ model.layers.1.mlp.experts.18.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.19\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.19.act_fn" [label="SiLU @ model.layers.1.mlp.experts.19.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.19.down_proj" [label="Linear @ model.layers.1.mlp.experts.19.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.19.gate_proj" [label="Linear @ model.layers.1.mlp.experts.19.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.19.up_proj" [label="Linear @ model.layers.1.mlp.experts.19.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.2\nin [47, 1280] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.2.act_fn" [label="SiLU @ model.layers.1.mlp.experts.2.act_fn\nin [47, 896] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.2.down_proj" [label="Linear @ model.layers.1.mlp.experts.2.down_proj\nin [47, 896] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.2.gate_proj" [label="Linear @ model.layers.1.mlp.experts.2.gate_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.2.up_proj" [label="Linear @ model.layers.1.mlp.experts.2.up_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.20\nin [62, 1280] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.20.act_fn" [label="SiLU @ model.layers.1.mlp.experts.20.act_fn\nin [62, 896] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.20.down_proj" [label="Linear @ model.layers.1.mlp.experts.20.down_proj\nin [62, 896] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.20.gate_proj" [label="Linear @ model.layers.1.mlp.experts.20.gate_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.20.up_proj" [label="Linear @ model.layers.1.mlp.experts.20.up_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.21\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.21.act_fn" [label="SiLU @ model.layers.1.mlp.experts.21.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.21.down_proj" [label="Linear @ model.layers.1.mlp.experts.21.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.21.gate_proj" [label="Linear @ model.layers.1.mlp.experts.21.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.21.up_proj" [label="Linear @ model.layers.1.mlp.experts.21.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.22\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.22.act_fn" [label="SiLU @ model.layers.1.mlp.experts.22.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.22.down_proj" [label="Linear @ model.layers.1.mlp.experts.22.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.22.gate_proj" [label="Linear @ model.layers.1.mlp.experts.22.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.22.up_proj" [label="Linear @ model.layers.1.mlp.experts.22.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.23\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.23.act_fn" [label="SiLU @ model.layers.1.mlp.experts.23.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.23.down_proj" [label="Linear @ model.layers.1.mlp.experts.23.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.23.gate_proj" [label="Linear @ model.layers.1.mlp.experts.23.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.23.up_proj" [label="Linear @ model.layers.1.mlp.experts.23.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.24\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.24.act_fn" [label="SiLU @ model.layers.1.mlp.experts.24.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.24.down_proj" [label="Linear @ model.layers.1.mlp.experts.24.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.24.gate_proj" [label="Linear @ model.layers.1.mlp.experts.24.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.24.up_proj" [label="Linear @ model.layers.1.mlp.experts.24.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.25\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.25.act_fn" [label="SiLU @ model.layers.1.mlp.experts.25.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.25.down_proj" [label="Linear @ model.layers.1.mlp.experts.25.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.25.gate_proj" [label="Linear @ model.layers.1.mlp.experts.25.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.25.up_proj" [label="Linear @ model.layers.1.mlp.experts.25.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.27\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.27.act_fn" [label="SiLU @ model.layers.1.mlp.experts.27.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.27.down_proj" [label="Linear @ model.layers.1.mlp.experts.27.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.27.gate_proj" [label="Linear @ model.layers.1.mlp.experts.27.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.27.up_proj" [label="Linear @ model.layers.1.mlp.experts.27.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.28\nin [90, 1280] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.28.act_fn" [label="SiLU @ model.layers.1.mlp.experts.28.act_fn\nin [90, 896] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.28.down_proj" [label="Linear @ model.layers.1.mlp.experts.28.down_proj\nin [90, 896] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.28.gate_proj" [label="Linear @ model.layers.1.mlp.experts.28.gate_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.28.up_proj" [label="Linear @ model.layers.1.mlp.experts.28.up_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.29\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.29.act_fn" [label="SiLU @ model.layers.1.mlp.experts.29.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.29.down_proj" [label="Linear @ model.layers.1.mlp.experts.29.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.29.gate_proj" [label="Linear @ model.layers.1.mlp.experts.29.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.29.up_proj" [label="Linear @ model.layers.1.mlp.experts.29.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.3\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.3.act_fn" [label="SiLU @ model.layers.1.mlp.experts.3.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.3.down_proj" [label="Linear @ model.layers.1.mlp.experts.3.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.3.gate_proj" [label="Linear @ model.layers.1.mlp.experts.3.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.3.up_proj" [label="Linear @ model.layers.1.mlp.experts.3.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.30\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.30.act_fn" [label="SiLU @ model.layers.1.mlp.experts.30.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.30.down_proj" [label="Linear @ model.layers.1.mlp.experts.30.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.30.gate_proj" [label="Linear @ model.layers.1.mlp.experts.30.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.30.up_proj" [label="Linear @ model.layers.1.mlp.experts.30.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.31\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.31.act_fn" [label="SiLU @ model.layers.1.mlp.experts.31.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.31.down_proj" [label="Linear @ model.layers.1.mlp.experts.31.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.31.gate_proj" [label="Linear @ model.layers.1.mlp.experts.31.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.31.up_proj" [label="Linear @ model.layers.1.mlp.experts.31.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.32\nin [125, 1280] torch.bfloat16 | out [125, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.32.act_fn" [label="SiLU @ model.layers.1.mlp.experts.32.act_fn\nin [125, 896] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.32.down_proj" [label="Linear @ model.layers.1.mlp.experts.32.down_proj\nin [125, 896] torch.bfloat16 | out [125, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.32.gate_proj" [label="Linear @ model.layers.1.mlp.experts.32.gate_proj\nin [125, 1280] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.32.up_proj" [label="Linear @ model.layers.1.mlp.experts.32.up_proj\nin [125, 1280] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.33\nin [55, 1280] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.33.act_fn" [label="SiLU @ model.layers.1.mlp.experts.33.act_fn\nin [55, 896] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.33.down_proj" [label="Linear @ model.layers.1.mlp.experts.33.down_proj\nin [55, 896] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.33.gate_proj" [label="Linear @ model.layers.1.mlp.experts.33.gate_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.33.up_proj" [label="Linear @ model.layers.1.mlp.experts.33.up_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.34\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.34.act_fn" [label="SiLU @ model.layers.1.mlp.experts.34.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.34.down_proj" [label="Linear @ model.layers.1.mlp.experts.34.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.34.gate_proj" [label="Linear @ model.layers.1.mlp.experts.34.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.34.up_proj" [label="Linear @ model.layers.1.mlp.experts.34.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.35\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.35.act_fn" [label="SiLU @ model.layers.1.mlp.experts.35.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.35.down_proj" [label="Linear @ model.layers.1.mlp.experts.35.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.35.gate_proj" [label="Linear @ model.layers.1.mlp.experts.35.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.35.up_proj" [label="Linear @ model.layers.1.mlp.experts.35.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.36\nin [49, 1280] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.36.act_fn" [label="SiLU @ model.layers.1.mlp.experts.36.act_fn\nin [49, 896] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.36.down_proj" [label="Linear @ model.layers.1.mlp.experts.36.down_proj\nin [49, 896] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.36.gate_proj" [label="Linear @ model.layers.1.mlp.experts.36.gate_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.36.up_proj" [label="Linear @ model.layers.1.mlp.experts.36.up_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.37\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.37.act_fn" [label="SiLU @ model.layers.1.mlp.experts.37.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.37.down_proj" [label="Linear @ model.layers.1.mlp.experts.37.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.37.gate_proj" [label="Linear @ model.layers.1.mlp.experts.37.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.37.up_proj" [label="Linear @ model.layers.1.mlp.experts.37.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.38\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.38.act_fn" [label="SiLU @ model.layers.1.mlp.experts.38.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.38.down_proj" [label="Linear @ model.layers.1.mlp.experts.38.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.38.gate_proj" [label="Linear @ model.layers.1.mlp.experts.38.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.38.up_proj" [label="Linear @ model.layers.1.mlp.experts.38.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.39\nin [69, 1280] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.39.act_fn" [label="SiLU @ model.layers.1.mlp.experts.39.act_fn\nin [69, 896] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.39.down_proj" [label="Linear @ model.layers.1.mlp.experts.39.down_proj\nin [69, 896] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.39.gate_proj" [label="Linear @ model.layers.1.mlp.experts.39.gate_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.39.up_proj" [label="Linear @ model.layers.1.mlp.experts.39.up_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.4\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.4.act_fn" [label="SiLU @ model.layers.1.mlp.experts.4.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.4.down_proj" [label="Linear @ model.layers.1.mlp.experts.4.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.4.gate_proj" [label="Linear @ model.layers.1.mlp.experts.4.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.4.up_proj" [label="Linear @ model.layers.1.mlp.experts.4.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.40\nin [71, 1280] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.40.act_fn" [label="SiLU @ model.layers.1.mlp.experts.40.act_fn\nin [71, 896] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.40.down_proj" [label="Linear @ model.layers.1.mlp.experts.40.down_proj\nin [71, 896] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.40.gate_proj" [label="Linear @ model.layers.1.mlp.experts.40.gate_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.40.up_proj" [label="Linear @ model.layers.1.mlp.experts.40.up_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.41\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.41.act_fn" [label="SiLU @ model.layers.1.mlp.experts.41.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.41.down_proj" [label="Linear @ model.layers.1.mlp.experts.41.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.41.gate_proj" [label="Linear @ model.layers.1.mlp.experts.41.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.41.up_proj" [label="Linear @ model.layers.1.mlp.experts.41.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.42\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.42.act_fn" [label="SiLU @ model.layers.1.mlp.experts.42.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.42.down_proj" [label="Linear @ model.layers.1.mlp.experts.42.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.42.gate_proj" [label="Linear @ model.layers.1.mlp.experts.42.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.42.up_proj" [label="Linear @ model.layers.1.mlp.experts.42.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.43\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.43.act_fn" [label="SiLU @ model.layers.1.mlp.experts.43.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.43.down_proj" [label="Linear @ model.layers.1.mlp.experts.43.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.43.gate_proj" [label="Linear @ model.layers.1.mlp.experts.43.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.43.up_proj" [label="Linear @ model.layers.1.mlp.experts.43.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.44\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.44.act_fn" [label="SiLU @ model.layers.1.mlp.experts.44.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.44.down_proj" [label="Linear @ model.layers.1.mlp.experts.44.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.44.gate_proj" [label="Linear @ model.layers.1.mlp.experts.44.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.44.up_proj" [label="Linear @ model.layers.1.mlp.experts.44.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.45\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.45.act_fn" [label="SiLU @ model.layers.1.mlp.experts.45.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.45.down_proj" [label="Linear @ model.layers.1.mlp.experts.45.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.45.gate_proj" [label="Linear @ model.layers.1.mlp.experts.45.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.45.up_proj" [label="Linear @ model.layers.1.mlp.experts.45.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.46\nin [53, 1280] torch.bfloat16 | out [53, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.46.act_fn" [label="SiLU @ model.layers.1.mlp.experts.46.act_fn\nin [53, 896] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.46.down_proj" [label="Linear @ model.layers.1.mlp.experts.46.down_proj\nin [53, 896] torch.bfloat16 | out [53, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.46.gate_proj" [label="Linear @ model.layers.1.mlp.experts.46.gate_proj\nin [53, 1280] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.46.up_proj" [label="Linear @ model.layers.1.mlp.experts.46.up_proj\nin [53, 1280] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.47\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.47.act_fn" [label="SiLU @ model.layers.1.mlp.experts.47.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.47.down_proj" [label="Linear @ model.layers.1.mlp.experts.47.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.47.gate_proj" [label="Linear @ model.layers.1.mlp.experts.47.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.47.up_proj" [label="Linear @ model.layers.1.mlp.experts.47.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.48\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.48.act_fn" [label="SiLU @ model.layers.1.mlp.experts.48.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.48.down_proj" [label="Linear @ model.layers.1.mlp.experts.48.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.48.gate_proj" [label="Linear @ model.layers.1.mlp.experts.48.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.48.up_proj" [label="Linear @ model.layers.1.mlp.experts.48.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.49\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.49.act_fn" [label="SiLU @ model.layers.1.mlp.experts.49.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.49.down_proj" [label="Linear @ model.layers.1.mlp.experts.49.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.49.gate_proj" [label="Linear @ model.layers.1.mlp.experts.49.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.49.up_proj" [label="Linear @ model.layers.1.mlp.experts.49.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.5\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.5.act_fn" [label="SiLU @ model.layers.1.mlp.experts.5.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.5.down_proj" [label="Linear @ model.layers.1.mlp.experts.5.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.5.gate_proj" [label="Linear @ model.layers.1.mlp.experts.5.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.5.up_proj" [label="Linear @ model.layers.1.mlp.experts.5.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.51\nin [93, 1280] torch.bfloat16 | out [93, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.51.act_fn" [label="SiLU @ model.layers.1.mlp.experts.51.act_fn\nin [93, 896] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.51.down_proj" [label="Linear @ model.layers.1.mlp.experts.51.down_proj\nin [93, 896] torch.bfloat16 | out [93, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.51.gate_proj" [label="Linear @ model.layers.1.mlp.experts.51.gate_proj\nin [93, 1280] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.51.up_proj" [label="Linear @ model.layers.1.mlp.experts.51.up_proj\nin [93, 1280] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.52\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.52.act_fn" [label="SiLU @ model.layers.1.mlp.experts.52.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.52.down_proj" [label="Linear @ model.layers.1.mlp.experts.52.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.52.gate_proj" [label="Linear @ model.layers.1.mlp.experts.52.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.52.up_proj" [label="Linear @ model.layers.1.mlp.experts.52.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.53\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.53.act_fn" [label="SiLU @ model.layers.1.mlp.experts.53.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.53.down_proj" [label="Linear @ model.layers.1.mlp.experts.53.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.53.gate_proj" [label="Linear @ model.layers.1.mlp.experts.53.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.53.up_proj" [label="Linear @ model.layers.1.mlp.experts.53.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.55\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.55.act_fn" [label="SiLU @ model.layers.1.mlp.experts.55.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.55.down_proj" [label="Linear @ model.layers.1.mlp.experts.55.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.55.gate_proj" [label="Linear @ model.layers.1.mlp.experts.55.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.55.up_proj" [label="Linear @ model.layers.1.mlp.experts.55.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.56\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.56.act_fn" [label="SiLU @ model.layers.1.mlp.experts.56.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.56.down_proj" [label="Linear @ model.layers.1.mlp.experts.56.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.56.gate_proj" [label="Linear @ model.layers.1.mlp.experts.56.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.56.up_proj" [label="Linear @ model.layers.1.mlp.experts.56.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.57\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.57.act_fn" [label="SiLU @ model.layers.1.mlp.experts.57.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.57.down_proj" [label="Linear @ model.layers.1.mlp.experts.57.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.57.gate_proj" [label="Linear @ model.layers.1.mlp.experts.57.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.57.up_proj" [label="Linear @ model.layers.1.mlp.experts.57.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.58\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.58.act_fn" [label="SiLU @ model.layers.1.mlp.experts.58.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.58.down_proj" [label="Linear @ model.layers.1.mlp.experts.58.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.58.gate_proj" [label="Linear @ model.layers.1.mlp.experts.58.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.58.up_proj" [label="Linear @ model.layers.1.mlp.experts.58.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.59\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.59.act_fn" [label="SiLU @ model.layers.1.mlp.experts.59.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.59.down_proj" [label="Linear @ model.layers.1.mlp.experts.59.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.59.gate_proj" [label="Linear @ model.layers.1.mlp.experts.59.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.59.up_proj" [label="Linear @ model.layers.1.mlp.experts.59.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.6\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.6.act_fn" [label="SiLU @ model.layers.1.mlp.experts.6.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.6.down_proj" [label="Linear @ model.layers.1.mlp.experts.6.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.6.gate_proj" [label="Linear @ model.layers.1.mlp.experts.6.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.6.up_proj" [label="Linear @ model.layers.1.mlp.experts.6.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.60\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.60.act_fn" [label="SiLU @ model.layers.1.mlp.experts.60.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.60.down_proj" [label="Linear @ model.layers.1.mlp.experts.60.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.60.gate_proj" [label="Linear @ model.layers.1.mlp.experts.60.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.60.up_proj" [label="Linear @ model.layers.1.mlp.experts.60.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.61\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.61.act_fn" [label="SiLU @ model.layers.1.mlp.experts.61.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.61.down_proj" [label="Linear @ model.layers.1.mlp.experts.61.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.61.gate_proj" [label="Linear @ model.layers.1.mlp.experts.61.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.61.up_proj" [label="Linear @ model.layers.1.mlp.experts.61.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.62\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.62.act_fn" [label="SiLU @ model.layers.1.mlp.experts.62.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.62.down_proj" [label="Linear @ model.layers.1.mlp.experts.62.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.62.gate_proj" [label="Linear @ model.layers.1.mlp.experts.62.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.62.up_proj" [label="Linear @ model.layers.1.mlp.experts.62.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.63\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.63.act_fn" [label="SiLU @ model.layers.1.mlp.experts.63.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.63.down_proj" [label="Linear @ model.layers.1.mlp.experts.63.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.63.gate_proj" [label="Linear @ model.layers.1.mlp.experts.63.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.63.up_proj" [label="Linear @ model.layers.1.mlp.experts.63.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.7\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.7.act_fn" [label="SiLU @ model.layers.1.mlp.experts.7.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.7.down_proj" [label="Linear @ model.layers.1.mlp.experts.7.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.7.gate_proj" [label="Linear @ model.layers.1.mlp.experts.7.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.7.up_proj" [label="Linear @ model.layers.1.mlp.experts.7.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.8\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.8.act_fn" [label="SiLU @ model.layers.1.mlp.experts.8.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.8.down_proj" [label="Linear @ model.layers.1.mlp.experts.8.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.8.gate_proj" [label="Linear @ model.layers.1.mlp.experts.8.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.8.up_proj" [label="Linear @ model.layers.1.mlp.experts.8.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.1.mlp.experts.9\nin [67, 1280] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.9.act_fn" [label="SiLU @ model.layers.1.mlp.experts.9.act_fn\nin [67, 896] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.9.down_proj" [label="Linear @ model.layers.1.mlp.experts.9.down_proj\nin [67, 896] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.1.mlp.experts.9.gate_proj" [label="Linear @ model.layers.1.mlp.experts.9.gate_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.1.mlp.experts.9.up_proj" [label="Linear @ model.layers.1.mlp.experts.9.up_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.1.mlp.gate" [label="MoEGate @ model.layers.1.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.1.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.1.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.1.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.1.mlp.shared_experts.down_proj" [label="Linear @ model.layers.1.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.1.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.1.mlp.shared_experts.up_proj" [label="Linear @ model.layers.1.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.1.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.1.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.self_attn" [label="LlamaFlashAttention2 @ model.layers.1.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.self_attn.k_proj" [label="Linear @ model.layers.1.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.self_attn.o_proj" [label="Linear @ model.layers.1.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.self_attn.q_proj" [label="Linear @ model.layers.1.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.1.self_attn.v_proj" [label="Linear @ model.layers.1.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10" [label="DeepseekV2DecoderLayer @ model.layers.10\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.10.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.mlp" [label="DeepseekV2MoE @ model.layers.10.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.0\nin [70, 1280] torch.bfloat16 | out [70, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.0.act_fn" [label="SiLU @ model.layers.10.mlp.experts.0.act_fn\nin [70, 896] torch.bfloat16 | out [70, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.0.down_proj" [label="Linear @ model.layers.10.mlp.experts.0.down_proj\nin [70, 896] torch.bfloat16 | out [70, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.0.gate_proj" [label="Linear @ model.layers.10.mlp.experts.0.gate_proj\nin [70, 1280] torch.bfloat16 | out [70, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.0.up_proj" [label="Linear @ model.layers.10.mlp.experts.0.up_proj\nin [70, 1280] torch.bfloat16 | out [70, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.1\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.1.act_fn" [label="SiLU @ model.layers.10.mlp.experts.1.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.1.down_proj" [label="Linear @ model.layers.10.mlp.experts.1.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.1.gate_proj" [label="Linear @ model.layers.10.mlp.experts.1.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.1.up_proj" [label="Linear @ model.layers.10.mlp.experts.1.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.10\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.10.act_fn" [label="SiLU @ model.layers.10.mlp.experts.10.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.10.down_proj" [label="Linear @ model.layers.10.mlp.experts.10.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.10.gate_proj" [label="Linear @ model.layers.10.mlp.experts.10.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.10.up_proj" [label="Linear @ model.layers.10.mlp.experts.10.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.11\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.11.act_fn" [label="SiLU @ model.layers.10.mlp.experts.11.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.11.down_proj" [label="Linear @ model.layers.10.mlp.experts.11.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.11.gate_proj" [label="Linear @ model.layers.10.mlp.experts.11.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.11.up_proj" [label="Linear @ model.layers.10.mlp.experts.11.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.12\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.12.act_fn" [label="SiLU @ model.layers.10.mlp.experts.12.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.12.down_proj" [label="Linear @ model.layers.10.mlp.experts.12.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.12.gate_proj" [label="Linear @ model.layers.10.mlp.experts.12.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.12.up_proj" [label="Linear @ model.layers.10.mlp.experts.12.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.13\nin [69, 1280] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.13.act_fn" [label="SiLU @ model.layers.10.mlp.experts.13.act_fn\nin [69, 896] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.13.down_proj" [label="Linear @ model.layers.10.mlp.experts.13.down_proj\nin [69, 896] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.13.gate_proj" [label="Linear @ model.layers.10.mlp.experts.13.gate_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.13.up_proj" [label="Linear @ model.layers.10.mlp.experts.13.up_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.14\nin [68, 1280] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.14.act_fn" [label="SiLU @ model.layers.10.mlp.experts.14.act_fn\nin [68, 896] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.14.down_proj" [label="Linear @ model.layers.10.mlp.experts.14.down_proj\nin [68, 896] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.14.gate_proj" [label="Linear @ model.layers.10.mlp.experts.14.gate_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.14.up_proj" [label="Linear @ model.layers.10.mlp.experts.14.up_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.15\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.15.act_fn" [label="SiLU @ model.layers.10.mlp.experts.15.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.15.down_proj" [label="Linear @ model.layers.10.mlp.experts.15.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.15.gate_proj" [label="Linear @ model.layers.10.mlp.experts.15.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.15.up_proj" [label="Linear @ model.layers.10.mlp.experts.15.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.16\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.16.act_fn" [label="SiLU @ model.layers.10.mlp.experts.16.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.16.down_proj" [label="Linear @ model.layers.10.mlp.experts.16.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.16.gate_proj" [label="Linear @ model.layers.10.mlp.experts.16.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.16.up_proj" [label="Linear @ model.layers.10.mlp.experts.16.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.17\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.17.act_fn" [label="SiLU @ model.layers.10.mlp.experts.17.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.17.down_proj" [label="Linear @ model.layers.10.mlp.experts.17.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.17.gate_proj" [label="Linear @ model.layers.10.mlp.experts.17.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.17.up_proj" [label="Linear @ model.layers.10.mlp.experts.17.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.19\nin [57, 1280] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.19.act_fn" [label="SiLU @ model.layers.10.mlp.experts.19.act_fn\nin [57, 896] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.19.down_proj" [label="Linear @ model.layers.10.mlp.experts.19.down_proj\nin [57, 896] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.19.gate_proj" [label="Linear @ model.layers.10.mlp.experts.19.gate_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.19.up_proj" [label="Linear @ model.layers.10.mlp.experts.19.up_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.2\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.2.act_fn" [label="SiLU @ model.layers.10.mlp.experts.2.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.2.down_proj" [label="Linear @ model.layers.10.mlp.experts.2.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.2.gate_proj" [label="Linear @ model.layers.10.mlp.experts.2.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.2.up_proj" [label="Linear @ model.layers.10.mlp.experts.2.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.21\nin [36, 1280] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.21.act_fn" [label="SiLU @ model.layers.10.mlp.experts.21.act_fn\nin [36, 896] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.21.down_proj" [label="Linear @ model.layers.10.mlp.experts.21.down_proj\nin [36, 896] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.21.gate_proj" [label="Linear @ model.layers.10.mlp.experts.21.gate_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.21.up_proj" [label="Linear @ model.layers.10.mlp.experts.21.up_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.22\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.22.act_fn" [label="SiLU @ model.layers.10.mlp.experts.22.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.22.down_proj" [label="Linear @ model.layers.10.mlp.experts.22.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.22.gate_proj" [label="Linear @ model.layers.10.mlp.experts.22.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.22.up_proj" [label="Linear @ model.layers.10.mlp.experts.22.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.23\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.23.act_fn" [label="SiLU @ model.layers.10.mlp.experts.23.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.23.down_proj" [label="Linear @ model.layers.10.mlp.experts.23.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.23.gate_proj" [label="Linear @ model.layers.10.mlp.experts.23.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.23.up_proj" [label="Linear @ model.layers.10.mlp.experts.23.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.24\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.24.act_fn" [label="SiLU @ model.layers.10.mlp.experts.24.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.24.down_proj" [label="Linear @ model.layers.10.mlp.experts.24.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.24.gate_proj" [label="Linear @ model.layers.10.mlp.experts.24.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.24.up_proj" [label="Linear @ model.layers.10.mlp.experts.24.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.25\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.25.act_fn" [label="SiLU @ model.layers.10.mlp.experts.25.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.25.down_proj" [label="Linear @ model.layers.10.mlp.experts.25.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.25.gate_proj" [label="Linear @ model.layers.10.mlp.experts.25.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.25.up_proj" [label="Linear @ model.layers.10.mlp.experts.25.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.26\nin [44, 1280] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.26.act_fn" [label="SiLU @ model.layers.10.mlp.experts.26.act_fn\nin [44, 896] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.26.down_proj" [label="Linear @ model.layers.10.mlp.experts.26.down_proj\nin [44, 896] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.26.gate_proj" [label="Linear @ model.layers.10.mlp.experts.26.gate_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.26.up_proj" [label="Linear @ model.layers.10.mlp.experts.26.up_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.27\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.27.act_fn" [label="SiLU @ model.layers.10.mlp.experts.27.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.27.down_proj" [label="Linear @ model.layers.10.mlp.experts.27.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.27.gate_proj" [label="Linear @ model.layers.10.mlp.experts.27.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.27.up_proj" [label="Linear @ model.layers.10.mlp.experts.27.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.28\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.28.act_fn" [label="SiLU @ model.layers.10.mlp.experts.28.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.28.down_proj" [label="Linear @ model.layers.10.mlp.experts.28.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.28.gate_proj" [label="Linear @ model.layers.10.mlp.experts.28.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.28.up_proj" [label="Linear @ model.layers.10.mlp.experts.28.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.29\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.29.act_fn" [label="SiLU @ model.layers.10.mlp.experts.29.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.29.down_proj" [label="Linear @ model.layers.10.mlp.experts.29.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.29.gate_proj" [label="Linear @ model.layers.10.mlp.experts.29.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.29.up_proj" [label="Linear @ model.layers.10.mlp.experts.29.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.3\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.3.act_fn" [label="SiLU @ model.layers.10.mlp.experts.3.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.3.down_proj" [label="Linear @ model.layers.10.mlp.experts.3.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.3.gate_proj" [label="Linear @ model.layers.10.mlp.experts.3.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.3.up_proj" [label="Linear @ model.layers.10.mlp.experts.3.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.30\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.30.act_fn" [label="SiLU @ model.layers.10.mlp.experts.30.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.30.down_proj" [label="Linear @ model.layers.10.mlp.experts.30.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.30.gate_proj" [label="Linear @ model.layers.10.mlp.experts.30.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.30.up_proj" [label="Linear @ model.layers.10.mlp.experts.30.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.31\nin [47, 1280] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.31.act_fn" [label="SiLU @ model.layers.10.mlp.experts.31.act_fn\nin [47, 896] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.31.down_proj" [label="Linear @ model.layers.10.mlp.experts.31.down_proj\nin [47, 896] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.31.gate_proj" [label="Linear @ model.layers.10.mlp.experts.31.gate_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.31.up_proj" [label="Linear @ model.layers.10.mlp.experts.31.up_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.32\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.32.act_fn" [label="SiLU @ model.layers.10.mlp.experts.32.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.32.down_proj" [label="Linear @ model.layers.10.mlp.experts.32.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.32.gate_proj" [label="Linear @ model.layers.10.mlp.experts.32.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.32.up_proj" [label="Linear @ model.layers.10.mlp.experts.32.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.33\nin [33, 1280] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.33.act_fn" [label="SiLU @ model.layers.10.mlp.experts.33.act_fn\nin [33, 896] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.33.down_proj" [label="Linear @ model.layers.10.mlp.experts.33.down_proj\nin [33, 896] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.33.gate_proj" [label="Linear @ model.layers.10.mlp.experts.33.gate_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.33.up_proj" [label="Linear @ model.layers.10.mlp.experts.33.up_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.34\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.34.act_fn" [label="SiLU @ model.layers.10.mlp.experts.34.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.34.down_proj" [label="Linear @ model.layers.10.mlp.experts.34.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.34.gate_proj" [label="Linear @ model.layers.10.mlp.experts.34.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.34.up_proj" [label="Linear @ model.layers.10.mlp.experts.34.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.35\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.35.act_fn" [label="SiLU @ model.layers.10.mlp.experts.35.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.35.down_proj" [label="Linear @ model.layers.10.mlp.experts.35.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.35.gate_proj" [label="Linear @ model.layers.10.mlp.experts.35.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.35.up_proj" [label="Linear @ model.layers.10.mlp.experts.35.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.36\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.36.act_fn" [label="SiLU @ model.layers.10.mlp.experts.36.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.36.down_proj" [label="Linear @ model.layers.10.mlp.experts.36.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.36.gate_proj" [label="Linear @ model.layers.10.mlp.experts.36.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.36.up_proj" [label="Linear @ model.layers.10.mlp.experts.36.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.37\nin [80, 1280] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.37.act_fn" [label="SiLU @ model.layers.10.mlp.experts.37.act_fn\nin [80, 896] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.37.down_proj" [label="Linear @ model.layers.10.mlp.experts.37.down_proj\nin [80, 896] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.37.gate_proj" [label="Linear @ model.layers.10.mlp.experts.37.gate_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.37.up_proj" [label="Linear @ model.layers.10.mlp.experts.37.up_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.38\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.38.act_fn" [label="SiLU @ model.layers.10.mlp.experts.38.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.38.down_proj" [label="Linear @ model.layers.10.mlp.experts.38.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.38.gate_proj" [label="Linear @ model.layers.10.mlp.experts.38.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.38.up_proj" [label="Linear @ model.layers.10.mlp.experts.38.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.39\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.39.act_fn" [label="SiLU @ model.layers.10.mlp.experts.39.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.39.down_proj" [label="Linear @ model.layers.10.mlp.experts.39.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.39.gate_proj" [label="Linear @ model.layers.10.mlp.experts.39.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.39.up_proj" [label="Linear @ model.layers.10.mlp.experts.39.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.4\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.4.act_fn" [label="SiLU @ model.layers.10.mlp.experts.4.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.4.down_proj" [label="Linear @ model.layers.10.mlp.experts.4.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.4.gate_proj" [label="Linear @ model.layers.10.mlp.experts.4.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.4.up_proj" [label="Linear @ model.layers.10.mlp.experts.4.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.40\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.40.act_fn" [label="SiLU @ model.layers.10.mlp.experts.40.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.40.down_proj" [label="Linear @ model.layers.10.mlp.experts.40.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.40.gate_proj" [label="Linear @ model.layers.10.mlp.experts.40.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.40.up_proj" [label="Linear @ model.layers.10.mlp.experts.40.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.41\nin [64, 1280] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.41.act_fn" [label="SiLU @ model.layers.10.mlp.experts.41.act_fn\nin [64, 896] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.41.down_proj" [label="Linear @ model.layers.10.mlp.experts.41.down_proj\nin [64, 896] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.41.gate_proj" [label="Linear @ model.layers.10.mlp.experts.41.gate_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.41.up_proj" [label="Linear @ model.layers.10.mlp.experts.41.up_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.42\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.42.act_fn" [label="SiLU @ model.layers.10.mlp.experts.42.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.42.down_proj" [label="Linear @ model.layers.10.mlp.experts.42.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.42.gate_proj" [label="Linear @ model.layers.10.mlp.experts.42.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.42.up_proj" [label="Linear @ model.layers.10.mlp.experts.42.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.43\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.43.act_fn" [label="SiLU @ model.layers.10.mlp.experts.43.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.43.down_proj" [label="Linear @ model.layers.10.mlp.experts.43.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.43.gate_proj" [label="Linear @ model.layers.10.mlp.experts.43.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.43.up_proj" [label="Linear @ model.layers.10.mlp.experts.43.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.44\nin [69, 1280] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.44.act_fn" [label="SiLU @ model.layers.10.mlp.experts.44.act_fn\nin [69, 896] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.44.down_proj" [label="Linear @ model.layers.10.mlp.experts.44.down_proj\nin [69, 896] torch.bfloat16 | out [69, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.44.gate_proj" [label="Linear @ model.layers.10.mlp.experts.44.gate_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.44.up_proj" [label="Linear @ model.layers.10.mlp.experts.44.up_proj\nin [69, 1280] torch.bfloat16 | out [69, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.45\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.45.act_fn" [label="SiLU @ model.layers.10.mlp.experts.45.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.45.down_proj" [label="Linear @ model.layers.10.mlp.experts.45.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.45.gate_proj" [label="Linear @ model.layers.10.mlp.experts.45.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.45.up_proj" [label="Linear @ model.layers.10.mlp.experts.45.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.47\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.47.act_fn" [label="SiLU @ model.layers.10.mlp.experts.47.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.47.down_proj" [label="Linear @ model.layers.10.mlp.experts.47.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.47.gate_proj" [label="Linear @ model.layers.10.mlp.experts.47.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.47.up_proj" [label="Linear @ model.layers.10.mlp.experts.47.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.48\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.48.act_fn" [label="SiLU @ model.layers.10.mlp.experts.48.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.48.down_proj" [label="Linear @ model.layers.10.mlp.experts.48.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.48.gate_proj" [label="Linear @ model.layers.10.mlp.experts.48.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.48.up_proj" [label="Linear @ model.layers.10.mlp.experts.48.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.49\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.49.act_fn" [label="SiLU @ model.layers.10.mlp.experts.49.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.49.down_proj" [label="Linear @ model.layers.10.mlp.experts.49.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.49.gate_proj" [label="Linear @ model.layers.10.mlp.experts.49.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.49.up_proj" [label="Linear @ model.layers.10.mlp.experts.49.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.5\nin [61, 1280] torch.bfloat16 | out [61, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.5.act_fn" [label="SiLU @ model.layers.10.mlp.experts.5.act_fn\nin [61, 896] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.5.down_proj" [label="Linear @ model.layers.10.mlp.experts.5.down_proj\nin [61, 896] torch.bfloat16 | out [61, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.5.gate_proj" [label="Linear @ model.layers.10.mlp.experts.5.gate_proj\nin [61, 1280] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.5.up_proj" [label="Linear @ model.layers.10.mlp.experts.5.up_proj\nin [61, 1280] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.50\nin [129, 1280] torch.bfloat16 | out [129, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.50.act_fn" [label="SiLU @ model.layers.10.mlp.experts.50.act_fn\nin [129, 896] torch.bfloat16 | out [129, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.50.down_proj" [label="Linear @ model.layers.10.mlp.experts.50.down_proj\nin [129, 896] torch.bfloat16 | out [129, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.50.gate_proj" [label="Linear @ model.layers.10.mlp.experts.50.gate_proj\nin [129, 1280] torch.bfloat16 | out [129, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.50.up_proj" [label="Linear @ model.layers.10.mlp.experts.50.up_proj\nin [129, 1280] torch.bfloat16 | out [129, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.51\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.51.act_fn" [label="SiLU @ model.layers.10.mlp.experts.51.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.51.down_proj" [label="Linear @ model.layers.10.mlp.experts.51.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.51.gate_proj" [label="Linear @ model.layers.10.mlp.experts.51.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.51.up_proj" [label="Linear @ model.layers.10.mlp.experts.51.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.52\nin [58, 1280] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.52.act_fn" [label="SiLU @ model.layers.10.mlp.experts.52.act_fn\nin [58, 896] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.52.down_proj" [label="Linear @ model.layers.10.mlp.experts.52.down_proj\nin [58, 896] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.52.gate_proj" [label="Linear @ model.layers.10.mlp.experts.52.gate_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.52.up_proj" [label="Linear @ model.layers.10.mlp.experts.52.up_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.53\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.53.act_fn" [label="SiLU @ model.layers.10.mlp.experts.53.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.53.down_proj" [label="Linear @ model.layers.10.mlp.experts.53.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.53.gate_proj" [label="Linear @ model.layers.10.mlp.experts.53.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.53.up_proj" [label="Linear @ model.layers.10.mlp.experts.53.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.54\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.54.act_fn" [label="SiLU @ model.layers.10.mlp.experts.54.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.54.down_proj" [label="Linear @ model.layers.10.mlp.experts.54.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.54.gate_proj" [label="Linear @ model.layers.10.mlp.experts.54.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.54.up_proj" [label="Linear @ model.layers.10.mlp.experts.54.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.55\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.55.act_fn" [label="SiLU @ model.layers.10.mlp.experts.55.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.55.down_proj" [label="Linear @ model.layers.10.mlp.experts.55.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.55.gate_proj" [label="Linear @ model.layers.10.mlp.experts.55.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.55.up_proj" [label="Linear @ model.layers.10.mlp.experts.55.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.56\nin [6, 1280] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.56.act_fn" [label="SiLU @ model.layers.10.mlp.experts.56.act_fn\nin [6, 896] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.56.down_proj" [label="Linear @ model.layers.10.mlp.experts.56.down_proj\nin [6, 896] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.56.gate_proj" [label="Linear @ model.layers.10.mlp.experts.56.gate_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.56.up_proj" [label="Linear @ model.layers.10.mlp.experts.56.up_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.57\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.57.act_fn" [label="SiLU @ model.layers.10.mlp.experts.57.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.57.down_proj" [label="Linear @ model.layers.10.mlp.experts.57.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.57.gate_proj" [label="Linear @ model.layers.10.mlp.experts.57.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.57.up_proj" [label="Linear @ model.layers.10.mlp.experts.57.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.58\nin [60, 1280] torch.bfloat16 | out [60, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.58.act_fn" [label="SiLU @ model.layers.10.mlp.experts.58.act_fn\nin [60, 896] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.58.down_proj" [label="Linear @ model.layers.10.mlp.experts.58.down_proj\nin [60, 896] torch.bfloat16 | out [60, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.58.gate_proj" [label="Linear @ model.layers.10.mlp.experts.58.gate_proj\nin [60, 1280] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.58.up_proj" [label="Linear @ model.layers.10.mlp.experts.58.up_proj\nin [60, 1280] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.59\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.59.act_fn" [label="SiLU @ model.layers.10.mlp.experts.59.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.59.down_proj" [label="Linear @ model.layers.10.mlp.experts.59.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.59.gate_proj" [label="Linear @ model.layers.10.mlp.experts.59.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.59.up_proj" [label="Linear @ model.layers.10.mlp.experts.59.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.6\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.6.act_fn" [label="SiLU @ model.layers.10.mlp.experts.6.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.6.down_proj" [label="Linear @ model.layers.10.mlp.experts.6.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.6.gate_proj" [label="Linear @ model.layers.10.mlp.experts.6.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.6.up_proj" [label="Linear @ model.layers.10.mlp.experts.6.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.60\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.60.act_fn" [label="SiLU @ model.layers.10.mlp.experts.60.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.60.down_proj" [label="Linear @ model.layers.10.mlp.experts.60.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.60.gate_proj" [label="Linear @ model.layers.10.mlp.experts.60.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.60.up_proj" [label="Linear @ model.layers.10.mlp.experts.60.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.61\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.61.act_fn" [label="SiLU @ model.layers.10.mlp.experts.61.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.61.down_proj" [label="Linear @ model.layers.10.mlp.experts.61.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.61.gate_proj" [label="Linear @ model.layers.10.mlp.experts.61.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.61.up_proj" [label="Linear @ model.layers.10.mlp.experts.61.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.62\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.62.act_fn" [label="SiLU @ model.layers.10.mlp.experts.62.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.62.down_proj" [label="Linear @ model.layers.10.mlp.experts.62.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.62.gate_proj" [label="Linear @ model.layers.10.mlp.experts.62.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.62.up_proj" [label="Linear @ model.layers.10.mlp.experts.62.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.63\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.63.act_fn" [label="SiLU @ model.layers.10.mlp.experts.63.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.63.down_proj" [label="Linear @ model.layers.10.mlp.experts.63.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.63.gate_proj" [label="Linear @ model.layers.10.mlp.experts.63.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.63.up_proj" [label="Linear @ model.layers.10.mlp.experts.63.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.7\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.7.act_fn" [label="SiLU @ model.layers.10.mlp.experts.7.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.7.down_proj" [label="Linear @ model.layers.10.mlp.experts.7.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.7.gate_proj" [label="Linear @ model.layers.10.mlp.experts.7.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.7.up_proj" [label="Linear @ model.layers.10.mlp.experts.7.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.8\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.8.act_fn" [label="SiLU @ model.layers.10.mlp.experts.8.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.8.down_proj" [label="Linear @ model.layers.10.mlp.experts.8.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.8.gate_proj" [label="Linear @ model.layers.10.mlp.experts.8.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.8.up_proj" [label="Linear @ model.layers.10.mlp.experts.8.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.10.mlp.experts.9\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.9.act_fn" [label="SiLU @ model.layers.10.mlp.experts.9.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.9.down_proj" [label="Linear @ model.layers.10.mlp.experts.9.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.10.mlp.experts.9.gate_proj" [label="Linear @ model.layers.10.mlp.experts.9.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.experts.9.up_proj" [label="Linear @ model.layers.10.mlp.experts.9.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.10.mlp.gate" [label="MoEGate @ model.layers.10.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.10.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.10.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.10.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.10.mlp.shared_experts.down_proj" [label="Linear @ model.layers.10.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.10.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.10.mlp.shared_experts.up_proj" [label="Linear @ model.layers.10.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.10.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.10.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.self_attn" [label="LlamaFlashAttention2 @ model.layers.10.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.self_attn.k_proj" [label="Linear @ model.layers.10.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.self_attn.o_proj" [label="Linear @ model.layers.10.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.self_attn.q_proj" [label="Linear @ model.layers.10.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.10.self_attn.v_proj" [label="Linear @ model.layers.10.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11" [label="DeepseekV2DecoderLayer @ model.layers.11\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.11.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.mlp" [label="DeepseekV2MoE @ model.layers.11.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.0\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.0.act_fn" [label="SiLU @ model.layers.11.mlp.experts.0.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.0.down_proj" [label="Linear @ model.layers.11.mlp.experts.0.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.0.gate_proj" [label="Linear @ model.layers.11.mlp.experts.0.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.0.up_proj" [label="Linear @ model.layers.11.mlp.experts.0.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.1\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.1.act_fn" [label="SiLU @ model.layers.11.mlp.experts.1.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.1.down_proj" [label="Linear @ model.layers.11.mlp.experts.1.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.1.gate_proj" [label="Linear @ model.layers.11.mlp.experts.1.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.1.up_proj" [label="Linear @ model.layers.11.mlp.experts.1.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.10\nin [75, 1280] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.10.act_fn" [label="SiLU @ model.layers.11.mlp.experts.10.act_fn\nin [75, 896] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.10.down_proj" [label="Linear @ model.layers.11.mlp.experts.10.down_proj\nin [75, 896] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.10.gate_proj" [label="Linear @ model.layers.11.mlp.experts.10.gate_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.10.up_proj" [label="Linear @ model.layers.11.mlp.experts.10.up_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.11\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.11.act_fn" [label="SiLU @ model.layers.11.mlp.experts.11.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.11.down_proj" [label="Linear @ model.layers.11.mlp.experts.11.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.11.gate_proj" [label="Linear @ model.layers.11.mlp.experts.11.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.11.up_proj" [label="Linear @ model.layers.11.mlp.experts.11.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.12\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.12.act_fn" [label="SiLU @ model.layers.11.mlp.experts.12.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.12.down_proj" [label="Linear @ model.layers.11.mlp.experts.12.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.12.gate_proj" [label="Linear @ model.layers.11.mlp.experts.12.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.12.up_proj" [label="Linear @ model.layers.11.mlp.experts.12.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.13\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.13.act_fn" [label="SiLU @ model.layers.11.mlp.experts.13.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.13.down_proj" [label="Linear @ model.layers.11.mlp.experts.13.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.13.gate_proj" [label="Linear @ model.layers.11.mlp.experts.13.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.13.up_proj" [label="Linear @ model.layers.11.mlp.experts.13.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.14\nin [53, 1280] torch.bfloat16 | out [53, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.14.act_fn" [label="SiLU @ model.layers.11.mlp.experts.14.act_fn\nin [53, 896] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.14.down_proj" [label="Linear @ model.layers.11.mlp.experts.14.down_proj\nin [53, 896] torch.bfloat16 | out [53, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.14.gate_proj" [label="Linear @ model.layers.11.mlp.experts.14.gate_proj\nin [53, 1280] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.14.up_proj" [label="Linear @ model.layers.11.mlp.experts.14.up_proj\nin [53, 1280] torch.bfloat16 | out [53, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.15\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.15.act_fn" [label="SiLU @ model.layers.11.mlp.experts.15.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.15.down_proj" [label="Linear @ model.layers.11.mlp.experts.15.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.15.gate_proj" [label="Linear @ model.layers.11.mlp.experts.15.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.15.up_proj" [label="Linear @ model.layers.11.mlp.experts.15.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.16\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.16.act_fn" [label="SiLU @ model.layers.11.mlp.experts.16.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.16.down_proj" [label="Linear @ model.layers.11.mlp.experts.16.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.16.gate_proj" [label="Linear @ model.layers.11.mlp.experts.16.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.16.up_proj" [label="Linear @ model.layers.11.mlp.experts.16.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.17\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.17.act_fn" [label="SiLU @ model.layers.11.mlp.experts.17.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.17.down_proj" [label="Linear @ model.layers.11.mlp.experts.17.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.17.gate_proj" [label="Linear @ model.layers.11.mlp.experts.17.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.17.up_proj" [label="Linear @ model.layers.11.mlp.experts.17.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.18\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.18.act_fn" [label="SiLU @ model.layers.11.mlp.experts.18.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.18.down_proj" [label="Linear @ model.layers.11.mlp.experts.18.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.18.gate_proj" [label="Linear @ model.layers.11.mlp.experts.18.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.18.up_proj" [label="Linear @ model.layers.11.mlp.experts.18.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.19\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.19.act_fn" [label="SiLU @ model.layers.11.mlp.experts.19.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.19.down_proj" [label="Linear @ model.layers.11.mlp.experts.19.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.19.gate_proj" [label="Linear @ model.layers.11.mlp.experts.19.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.19.up_proj" [label="Linear @ model.layers.11.mlp.experts.19.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.2\nin [132, 1280] torch.bfloat16 | out [132, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.2.act_fn" [label="SiLU @ model.layers.11.mlp.experts.2.act_fn\nin [132, 896] torch.bfloat16 | out [132, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.2.down_proj" [label="Linear @ model.layers.11.mlp.experts.2.down_proj\nin [132, 896] torch.bfloat16 | out [132, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.2.gate_proj" [label="Linear @ model.layers.11.mlp.experts.2.gate_proj\nin [132, 1280] torch.bfloat16 | out [132, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.2.up_proj" [label="Linear @ model.layers.11.mlp.experts.2.up_proj\nin [132, 1280] torch.bfloat16 | out [132, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.20\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.20.act_fn" [label="SiLU @ model.layers.11.mlp.experts.20.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.20.down_proj" [label="Linear @ model.layers.11.mlp.experts.20.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.20.gate_proj" [label="Linear @ model.layers.11.mlp.experts.20.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.20.up_proj" [label="Linear @ model.layers.11.mlp.experts.20.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.21\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.21.act_fn" [label="SiLU @ model.layers.11.mlp.experts.21.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.21.down_proj" [label="Linear @ model.layers.11.mlp.experts.21.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.21.gate_proj" [label="Linear @ model.layers.11.mlp.experts.21.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.21.up_proj" [label="Linear @ model.layers.11.mlp.experts.21.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.22\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.22.act_fn" [label="SiLU @ model.layers.11.mlp.experts.22.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.22.down_proj" [label="Linear @ model.layers.11.mlp.experts.22.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.22.gate_proj" [label="Linear @ model.layers.11.mlp.experts.22.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.22.up_proj" [label="Linear @ model.layers.11.mlp.experts.22.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.23\nin [133, 1280] torch.bfloat16 | out [133, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.23.act_fn" [label="SiLU @ model.layers.11.mlp.experts.23.act_fn\nin [133, 896] torch.bfloat16 | out [133, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.23.down_proj" [label="Linear @ model.layers.11.mlp.experts.23.down_proj\nin [133, 896] torch.bfloat16 | out [133, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.23.gate_proj" [label="Linear @ model.layers.11.mlp.experts.23.gate_proj\nin [133, 1280] torch.bfloat16 | out [133, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.23.up_proj" [label="Linear @ model.layers.11.mlp.experts.23.up_proj\nin [133, 1280] torch.bfloat16 | out [133, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.24\nin [6, 1280] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.24.act_fn" [label="SiLU @ model.layers.11.mlp.experts.24.act_fn\nin [6, 896] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.24.down_proj" [label="Linear @ model.layers.11.mlp.experts.24.down_proj\nin [6, 896] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.24.gate_proj" [label="Linear @ model.layers.11.mlp.experts.24.gate_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.24.up_proj" [label="Linear @ model.layers.11.mlp.experts.24.up_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.25\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.25.act_fn" [label="SiLU @ model.layers.11.mlp.experts.25.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.25.down_proj" [label="Linear @ model.layers.11.mlp.experts.25.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.25.gate_proj" [label="Linear @ model.layers.11.mlp.experts.25.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.25.up_proj" [label="Linear @ model.layers.11.mlp.experts.25.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.26\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.26.act_fn" [label="SiLU @ model.layers.11.mlp.experts.26.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.26.down_proj" [label="Linear @ model.layers.11.mlp.experts.26.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.26.gate_proj" [label="Linear @ model.layers.11.mlp.experts.26.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.26.up_proj" [label="Linear @ model.layers.11.mlp.experts.26.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.27\nin [72, 1280] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.27.act_fn" [label="SiLU @ model.layers.11.mlp.experts.27.act_fn\nin [72, 896] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.27.down_proj" [label="Linear @ model.layers.11.mlp.experts.27.down_proj\nin [72, 896] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.27.gate_proj" [label="Linear @ model.layers.11.mlp.experts.27.gate_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.27.up_proj" [label="Linear @ model.layers.11.mlp.experts.27.up_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.28\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.28.act_fn" [label="SiLU @ model.layers.11.mlp.experts.28.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.28.down_proj" [label="Linear @ model.layers.11.mlp.experts.28.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.28.gate_proj" [label="Linear @ model.layers.11.mlp.experts.28.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.28.up_proj" [label="Linear @ model.layers.11.mlp.experts.28.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.29\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.29.act_fn" [label="SiLU @ model.layers.11.mlp.experts.29.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.29.down_proj" [label="Linear @ model.layers.11.mlp.experts.29.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.29.gate_proj" [label="Linear @ model.layers.11.mlp.experts.29.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.29.up_proj" [label="Linear @ model.layers.11.mlp.experts.29.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.3\nin [44, 1280] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.3.act_fn" [label="SiLU @ model.layers.11.mlp.experts.3.act_fn\nin [44, 896] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.3.down_proj" [label="Linear @ model.layers.11.mlp.experts.3.down_proj\nin [44, 896] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.3.gate_proj" [label="Linear @ model.layers.11.mlp.experts.3.gate_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.3.up_proj" [label="Linear @ model.layers.11.mlp.experts.3.up_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.30\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.30.act_fn" [label="SiLU @ model.layers.11.mlp.experts.30.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.30.down_proj" [label="Linear @ model.layers.11.mlp.experts.30.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.30.gate_proj" [label="Linear @ model.layers.11.mlp.experts.30.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.30.up_proj" [label="Linear @ model.layers.11.mlp.experts.30.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.31\nin [54, 1280] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.31.act_fn" [label="SiLU @ model.layers.11.mlp.experts.31.act_fn\nin [54, 896] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.31.down_proj" [label="Linear @ model.layers.11.mlp.experts.31.down_proj\nin [54, 896] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.31.gate_proj" [label="Linear @ model.layers.11.mlp.experts.31.gate_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.31.up_proj" [label="Linear @ model.layers.11.mlp.experts.31.up_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.32\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.32.act_fn" [label="SiLU @ model.layers.11.mlp.experts.32.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.32.down_proj" [label="Linear @ model.layers.11.mlp.experts.32.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.32.gate_proj" [label="Linear @ model.layers.11.mlp.experts.32.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.32.up_proj" [label="Linear @ model.layers.11.mlp.experts.32.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.33\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.33.act_fn" [label="SiLU @ model.layers.11.mlp.experts.33.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.33.down_proj" [label="Linear @ model.layers.11.mlp.experts.33.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.33.gate_proj" [label="Linear @ model.layers.11.mlp.experts.33.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.33.up_proj" [label="Linear @ model.layers.11.mlp.experts.33.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.34\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.34.act_fn" [label="SiLU @ model.layers.11.mlp.experts.34.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.34.down_proj" [label="Linear @ model.layers.11.mlp.experts.34.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.34.gate_proj" [label="Linear @ model.layers.11.mlp.experts.34.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.34.up_proj" [label="Linear @ model.layers.11.mlp.experts.34.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.35\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.35.act_fn" [label="SiLU @ model.layers.11.mlp.experts.35.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.35.down_proj" [label="Linear @ model.layers.11.mlp.experts.35.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.35.gate_proj" [label="Linear @ model.layers.11.mlp.experts.35.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.35.up_proj" [label="Linear @ model.layers.11.mlp.experts.35.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.36\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.36.act_fn" [label="SiLU @ model.layers.11.mlp.experts.36.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.36.down_proj" [label="Linear @ model.layers.11.mlp.experts.36.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.36.gate_proj" [label="Linear @ model.layers.11.mlp.experts.36.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.36.up_proj" [label="Linear @ model.layers.11.mlp.experts.36.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.37\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.37.act_fn" [label="SiLU @ model.layers.11.mlp.experts.37.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.37.down_proj" [label="Linear @ model.layers.11.mlp.experts.37.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.37.gate_proj" [label="Linear @ model.layers.11.mlp.experts.37.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.37.up_proj" [label="Linear @ model.layers.11.mlp.experts.37.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.38\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.38.act_fn" [label="SiLU @ model.layers.11.mlp.experts.38.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.38.down_proj" [label="Linear @ model.layers.11.mlp.experts.38.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.38.gate_proj" [label="Linear @ model.layers.11.mlp.experts.38.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.38.up_proj" [label="Linear @ model.layers.11.mlp.experts.38.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.39\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.39.act_fn" [label="SiLU @ model.layers.11.mlp.experts.39.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.39.down_proj" [label="Linear @ model.layers.11.mlp.experts.39.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.39.gate_proj" [label="Linear @ model.layers.11.mlp.experts.39.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.39.up_proj" [label="Linear @ model.layers.11.mlp.experts.39.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.4\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.4.act_fn" [label="SiLU @ model.layers.11.mlp.experts.4.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.4.down_proj" [label="Linear @ model.layers.11.mlp.experts.4.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.4.gate_proj" [label="Linear @ model.layers.11.mlp.experts.4.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.4.up_proj" [label="Linear @ model.layers.11.mlp.experts.4.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.40\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.40.act_fn" [label="SiLU @ model.layers.11.mlp.experts.40.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.40.down_proj" [label="Linear @ model.layers.11.mlp.experts.40.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.40.gate_proj" [label="Linear @ model.layers.11.mlp.experts.40.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.40.up_proj" [label="Linear @ model.layers.11.mlp.experts.40.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.41\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.41.act_fn" [label="SiLU @ model.layers.11.mlp.experts.41.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.41.down_proj" [label="Linear @ model.layers.11.mlp.experts.41.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.41.gate_proj" [label="Linear @ model.layers.11.mlp.experts.41.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.41.up_proj" [label="Linear @ model.layers.11.mlp.experts.41.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.42\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.42.act_fn" [label="SiLU @ model.layers.11.mlp.experts.42.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.42.down_proj" [label="Linear @ model.layers.11.mlp.experts.42.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.42.gate_proj" [label="Linear @ model.layers.11.mlp.experts.42.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.42.up_proj" [label="Linear @ model.layers.11.mlp.experts.42.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.43\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.43.act_fn" [label="SiLU @ model.layers.11.mlp.experts.43.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.43.down_proj" [label="Linear @ model.layers.11.mlp.experts.43.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.43.gate_proj" [label="Linear @ model.layers.11.mlp.experts.43.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.43.up_proj" [label="Linear @ model.layers.11.mlp.experts.43.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.44\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.44.act_fn" [label="SiLU @ model.layers.11.mlp.experts.44.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.44.down_proj" [label="Linear @ model.layers.11.mlp.experts.44.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.44.gate_proj" [label="Linear @ model.layers.11.mlp.experts.44.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.44.up_proj" [label="Linear @ model.layers.11.mlp.experts.44.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.45\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.45.act_fn" [label="SiLU @ model.layers.11.mlp.experts.45.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.45.down_proj" [label="Linear @ model.layers.11.mlp.experts.45.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.45.gate_proj" [label="Linear @ model.layers.11.mlp.experts.45.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.45.up_proj" [label="Linear @ model.layers.11.mlp.experts.45.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.46\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.46.act_fn" [label="SiLU @ model.layers.11.mlp.experts.46.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.46.down_proj" [label="Linear @ model.layers.11.mlp.experts.46.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.46.gate_proj" [label="Linear @ model.layers.11.mlp.experts.46.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.46.up_proj" [label="Linear @ model.layers.11.mlp.experts.46.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.47\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.47.act_fn" [label="SiLU @ model.layers.11.mlp.experts.47.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.47.down_proj" [label="Linear @ model.layers.11.mlp.experts.47.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.47.gate_proj" [label="Linear @ model.layers.11.mlp.experts.47.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.47.up_proj" [label="Linear @ model.layers.11.mlp.experts.47.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.48\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.48.act_fn" [label="SiLU @ model.layers.11.mlp.experts.48.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.48.down_proj" [label="Linear @ model.layers.11.mlp.experts.48.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.48.gate_proj" [label="Linear @ model.layers.11.mlp.experts.48.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.48.up_proj" [label="Linear @ model.layers.11.mlp.experts.48.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.49\nin [79, 1280] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.49.act_fn" [label="SiLU @ model.layers.11.mlp.experts.49.act_fn\nin [79, 896] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.49.down_proj" [label="Linear @ model.layers.11.mlp.experts.49.down_proj\nin [79, 896] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.49.gate_proj" [label="Linear @ model.layers.11.mlp.experts.49.gate_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.49.up_proj" [label="Linear @ model.layers.11.mlp.experts.49.up_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.5\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.5.act_fn" [label="SiLU @ model.layers.11.mlp.experts.5.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.5.down_proj" [label="Linear @ model.layers.11.mlp.experts.5.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.5.gate_proj" [label="Linear @ model.layers.11.mlp.experts.5.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.5.up_proj" [label="Linear @ model.layers.11.mlp.experts.5.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.50\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.50.act_fn" [label="SiLU @ model.layers.11.mlp.experts.50.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.50.down_proj" [label="Linear @ model.layers.11.mlp.experts.50.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.50.gate_proj" [label="Linear @ model.layers.11.mlp.experts.50.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.50.up_proj" [label="Linear @ model.layers.11.mlp.experts.50.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.51\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.51.act_fn" [label="SiLU @ model.layers.11.mlp.experts.51.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.51.down_proj" [label="Linear @ model.layers.11.mlp.experts.51.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.51.gate_proj" [label="Linear @ model.layers.11.mlp.experts.51.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.51.up_proj" [label="Linear @ model.layers.11.mlp.experts.51.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.52\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.52.act_fn" [label="SiLU @ model.layers.11.mlp.experts.52.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.52.down_proj" [label="Linear @ model.layers.11.mlp.experts.52.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.52.gate_proj" [label="Linear @ model.layers.11.mlp.experts.52.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.52.up_proj" [label="Linear @ model.layers.11.mlp.experts.52.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.53\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.53.act_fn" [label="SiLU @ model.layers.11.mlp.experts.53.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.53.down_proj" [label="Linear @ model.layers.11.mlp.experts.53.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.53.gate_proj" [label="Linear @ model.layers.11.mlp.experts.53.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.53.up_proj" [label="Linear @ model.layers.11.mlp.experts.53.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.54\nin [33, 1280] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.54.act_fn" [label="SiLU @ model.layers.11.mlp.experts.54.act_fn\nin [33, 896] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.54.down_proj" [label="Linear @ model.layers.11.mlp.experts.54.down_proj\nin [33, 896] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.54.gate_proj" [label="Linear @ model.layers.11.mlp.experts.54.gate_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.54.up_proj" [label="Linear @ model.layers.11.mlp.experts.54.up_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.55\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.55.act_fn" [label="SiLU @ model.layers.11.mlp.experts.55.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.55.down_proj" [label="Linear @ model.layers.11.mlp.experts.55.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.55.gate_proj" [label="Linear @ model.layers.11.mlp.experts.55.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.55.up_proj" [label="Linear @ model.layers.11.mlp.experts.55.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.56\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.56.act_fn" [label="SiLU @ model.layers.11.mlp.experts.56.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.56.down_proj" [label="Linear @ model.layers.11.mlp.experts.56.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.56.gate_proj" [label="Linear @ model.layers.11.mlp.experts.56.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.56.up_proj" [label="Linear @ model.layers.11.mlp.experts.56.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.57\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.57.act_fn" [label="SiLU @ model.layers.11.mlp.experts.57.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.57.down_proj" [label="Linear @ model.layers.11.mlp.experts.57.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.57.gate_proj" [label="Linear @ model.layers.11.mlp.experts.57.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.57.up_proj" [label="Linear @ model.layers.11.mlp.experts.57.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.58\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.58.act_fn" [label="SiLU @ model.layers.11.mlp.experts.58.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.58.down_proj" [label="Linear @ model.layers.11.mlp.experts.58.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.58.gate_proj" [label="Linear @ model.layers.11.mlp.experts.58.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.58.up_proj" [label="Linear @ model.layers.11.mlp.experts.58.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.59\nin [72, 1280] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.59.act_fn" [label="SiLU @ model.layers.11.mlp.experts.59.act_fn\nin [72, 896] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.59.down_proj" [label="Linear @ model.layers.11.mlp.experts.59.down_proj\nin [72, 896] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.59.gate_proj" [label="Linear @ model.layers.11.mlp.experts.59.gate_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.59.up_proj" [label="Linear @ model.layers.11.mlp.experts.59.up_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.6\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.6.act_fn" [label="SiLU @ model.layers.11.mlp.experts.6.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.6.down_proj" [label="Linear @ model.layers.11.mlp.experts.6.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.6.gate_proj" [label="Linear @ model.layers.11.mlp.experts.6.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.6.up_proj" [label="Linear @ model.layers.11.mlp.experts.6.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.60\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.60.act_fn" [label="SiLU @ model.layers.11.mlp.experts.60.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.60.down_proj" [label="Linear @ model.layers.11.mlp.experts.60.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.60.gate_proj" [label="Linear @ model.layers.11.mlp.experts.60.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.60.up_proj" [label="Linear @ model.layers.11.mlp.experts.60.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.61\nin [60, 1280] torch.bfloat16 | out [60, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.61.act_fn" [label="SiLU @ model.layers.11.mlp.experts.61.act_fn\nin [60, 896] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.61.down_proj" [label="Linear @ model.layers.11.mlp.experts.61.down_proj\nin [60, 896] torch.bfloat16 | out [60, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.61.gate_proj" [label="Linear @ model.layers.11.mlp.experts.61.gate_proj\nin [60, 1280] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.61.up_proj" [label="Linear @ model.layers.11.mlp.experts.61.up_proj\nin [60, 1280] torch.bfloat16 | out [60, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.62\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.62.act_fn" [label="SiLU @ model.layers.11.mlp.experts.62.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.62.down_proj" [label="Linear @ model.layers.11.mlp.experts.62.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.62.gate_proj" [label="Linear @ model.layers.11.mlp.experts.62.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.62.up_proj" [label="Linear @ model.layers.11.mlp.experts.62.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.63\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.63.act_fn" [label="SiLU @ model.layers.11.mlp.experts.63.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.63.down_proj" [label="Linear @ model.layers.11.mlp.experts.63.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.63.gate_proj" [label="Linear @ model.layers.11.mlp.experts.63.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.63.up_proj" [label="Linear @ model.layers.11.mlp.experts.63.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.7\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.7.act_fn" [label="SiLU @ model.layers.11.mlp.experts.7.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.7.down_proj" [label="Linear @ model.layers.11.mlp.experts.7.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.7.gate_proj" [label="Linear @ model.layers.11.mlp.experts.7.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.7.up_proj" [label="Linear @ model.layers.11.mlp.experts.7.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.8\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.8.act_fn" [label="SiLU @ model.layers.11.mlp.experts.8.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.8.down_proj" [label="Linear @ model.layers.11.mlp.experts.8.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.8.gate_proj" [label="Linear @ model.layers.11.mlp.experts.8.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.8.up_proj" [label="Linear @ model.layers.11.mlp.experts.8.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.11.mlp.experts.9\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.9.act_fn" [label="SiLU @ model.layers.11.mlp.experts.9.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.9.down_proj" [label="Linear @ model.layers.11.mlp.experts.9.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.11.mlp.experts.9.gate_proj" [label="Linear @ model.layers.11.mlp.experts.9.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.experts.9.up_proj" [label="Linear @ model.layers.11.mlp.experts.9.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.11.mlp.gate" [label="MoEGate @ model.layers.11.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.11.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.11.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.11.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.11.mlp.shared_experts.down_proj" [label="Linear @ model.layers.11.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.11.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.11.mlp.shared_experts.up_proj" [label="Linear @ model.layers.11.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.11.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.11.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.self_attn" [label="LlamaFlashAttention2 @ model.layers.11.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.self_attn.k_proj" [label="Linear @ model.layers.11.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.self_attn.o_proj" [label="Linear @ model.layers.11.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.self_attn.q_proj" [label="Linear @ model.layers.11.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.11.self_attn.v_proj" [label="Linear @ model.layers.11.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2" [label="DeepseekV2DecoderLayer @ model.layers.2\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.2.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.mlp" [label="DeepseekV2MoE @ model.layers.2.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.0\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.0.act_fn" [label="SiLU @ model.layers.2.mlp.experts.0.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.0.down_proj" [label="Linear @ model.layers.2.mlp.experts.0.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.0.gate_proj" [label="Linear @ model.layers.2.mlp.experts.0.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.0.up_proj" [label="Linear @ model.layers.2.mlp.experts.0.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.1\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.1.act_fn" [label="SiLU @ model.layers.2.mlp.experts.1.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.1.down_proj" [label="Linear @ model.layers.2.mlp.experts.1.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.1.gate_proj" [label="Linear @ model.layers.2.mlp.experts.1.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.1.up_proj" [label="Linear @ model.layers.2.mlp.experts.1.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.10\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.10.act_fn" [label="SiLU @ model.layers.2.mlp.experts.10.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.10.down_proj" [label="Linear @ model.layers.2.mlp.experts.10.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.10.gate_proj" [label="Linear @ model.layers.2.mlp.experts.10.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.10.up_proj" [label="Linear @ model.layers.2.mlp.experts.10.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.11\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.11.act_fn" [label="SiLU @ model.layers.2.mlp.experts.11.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.11.down_proj" [label="Linear @ model.layers.2.mlp.experts.11.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.11.gate_proj" [label="Linear @ model.layers.2.mlp.experts.11.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.11.up_proj" [label="Linear @ model.layers.2.mlp.experts.11.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.12\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.12.act_fn" [label="SiLU @ model.layers.2.mlp.experts.12.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.12.down_proj" [label="Linear @ model.layers.2.mlp.experts.12.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.12.gate_proj" [label="Linear @ model.layers.2.mlp.experts.12.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.12.up_proj" [label="Linear @ model.layers.2.mlp.experts.12.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.14\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.14.act_fn" [label="SiLU @ model.layers.2.mlp.experts.14.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.14.down_proj" [label="Linear @ model.layers.2.mlp.experts.14.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.14.gate_proj" [label="Linear @ model.layers.2.mlp.experts.14.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.14.up_proj" [label="Linear @ model.layers.2.mlp.experts.14.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.15\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.15.act_fn" [label="SiLU @ model.layers.2.mlp.experts.15.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.15.down_proj" [label="Linear @ model.layers.2.mlp.experts.15.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.15.gate_proj" [label="Linear @ model.layers.2.mlp.experts.15.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.15.up_proj" [label="Linear @ model.layers.2.mlp.experts.15.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.16\nin [57, 1280] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.16.act_fn" [label="SiLU @ model.layers.2.mlp.experts.16.act_fn\nin [57, 896] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.16.down_proj" [label="Linear @ model.layers.2.mlp.experts.16.down_proj\nin [57, 896] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.16.gate_proj" [label="Linear @ model.layers.2.mlp.experts.16.gate_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.16.up_proj" [label="Linear @ model.layers.2.mlp.experts.16.up_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.17\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.17.act_fn" [label="SiLU @ model.layers.2.mlp.experts.17.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.17.down_proj" [label="Linear @ model.layers.2.mlp.experts.17.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.17.gate_proj" [label="Linear @ model.layers.2.mlp.experts.17.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.17.up_proj" [label="Linear @ model.layers.2.mlp.experts.17.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.18\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.18.act_fn" [label="SiLU @ model.layers.2.mlp.experts.18.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.18.down_proj" [label="Linear @ model.layers.2.mlp.experts.18.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.18.gate_proj" [label="Linear @ model.layers.2.mlp.experts.18.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.18.up_proj" [label="Linear @ model.layers.2.mlp.experts.18.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.2\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.2.act_fn" [label="SiLU @ model.layers.2.mlp.experts.2.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.2.down_proj" [label="Linear @ model.layers.2.mlp.experts.2.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.2.gate_proj" [label="Linear @ model.layers.2.mlp.experts.2.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.2.up_proj" [label="Linear @ model.layers.2.mlp.experts.2.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.20\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.20.act_fn" [label="SiLU @ model.layers.2.mlp.experts.20.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.20.down_proj" [label="Linear @ model.layers.2.mlp.experts.20.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.20.gate_proj" [label="Linear @ model.layers.2.mlp.experts.20.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.20.up_proj" [label="Linear @ model.layers.2.mlp.experts.20.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.21\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.21.act_fn" [label="SiLU @ model.layers.2.mlp.experts.21.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.21.down_proj" [label="Linear @ model.layers.2.mlp.experts.21.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.21.gate_proj" [label="Linear @ model.layers.2.mlp.experts.21.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.21.up_proj" [label="Linear @ model.layers.2.mlp.experts.21.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.22\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.22.act_fn" [label="SiLU @ model.layers.2.mlp.experts.22.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.22.down_proj" [label="Linear @ model.layers.2.mlp.experts.22.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.22.gate_proj" [label="Linear @ model.layers.2.mlp.experts.22.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.22.up_proj" [label="Linear @ model.layers.2.mlp.experts.22.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.23\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.23.act_fn" [label="SiLU @ model.layers.2.mlp.experts.23.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.23.down_proj" [label="Linear @ model.layers.2.mlp.experts.23.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.23.gate_proj" [label="Linear @ model.layers.2.mlp.experts.23.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.23.up_proj" [label="Linear @ model.layers.2.mlp.experts.23.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.24\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.24.act_fn" [label="SiLU @ model.layers.2.mlp.experts.24.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.24.down_proj" [label="Linear @ model.layers.2.mlp.experts.24.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.24.gate_proj" [label="Linear @ model.layers.2.mlp.experts.24.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.24.up_proj" [label="Linear @ model.layers.2.mlp.experts.24.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.25\nin [65, 1280] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.25.act_fn" [label="SiLU @ model.layers.2.mlp.experts.25.act_fn\nin [65, 896] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.25.down_proj" [label="Linear @ model.layers.2.mlp.experts.25.down_proj\nin [65, 896] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.25.gate_proj" [label="Linear @ model.layers.2.mlp.experts.25.gate_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.25.up_proj" [label="Linear @ model.layers.2.mlp.experts.25.up_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.26\nin [43, 1280] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.26.act_fn" [label="SiLU @ model.layers.2.mlp.experts.26.act_fn\nin [43, 896] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.26.down_proj" [label="Linear @ model.layers.2.mlp.experts.26.down_proj\nin [43, 896] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.26.gate_proj" [label="Linear @ model.layers.2.mlp.experts.26.gate_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.26.up_proj" [label="Linear @ model.layers.2.mlp.experts.26.up_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.27\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.27.act_fn" [label="SiLU @ model.layers.2.mlp.experts.27.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.27.down_proj" [label="Linear @ model.layers.2.mlp.experts.27.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.27.gate_proj" [label="Linear @ model.layers.2.mlp.experts.27.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.27.up_proj" [label="Linear @ model.layers.2.mlp.experts.27.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.28\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.28.act_fn" [label="SiLU @ model.layers.2.mlp.experts.28.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.28.down_proj" [label="Linear @ model.layers.2.mlp.experts.28.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.28.gate_proj" [label="Linear @ model.layers.2.mlp.experts.28.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.28.up_proj" [label="Linear @ model.layers.2.mlp.experts.28.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.29\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.29.act_fn" [label="SiLU @ model.layers.2.mlp.experts.29.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.29.down_proj" [label="Linear @ model.layers.2.mlp.experts.29.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.29.gate_proj" [label="Linear @ model.layers.2.mlp.experts.29.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.29.up_proj" [label="Linear @ model.layers.2.mlp.experts.29.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.3\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.3.act_fn" [label="SiLU @ model.layers.2.mlp.experts.3.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.3.down_proj" [label="Linear @ model.layers.2.mlp.experts.3.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.3.gate_proj" [label="Linear @ model.layers.2.mlp.experts.3.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.3.up_proj" [label="Linear @ model.layers.2.mlp.experts.3.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.30\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.30.act_fn" [label="SiLU @ model.layers.2.mlp.experts.30.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.30.down_proj" [label="Linear @ model.layers.2.mlp.experts.30.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.30.gate_proj" [label="Linear @ model.layers.2.mlp.experts.30.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.30.up_proj" [label="Linear @ model.layers.2.mlp.experts.30.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.31\nin [62, 1280] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.31.act_fn" [label="SiLU @ model.layers.2.mlp.experts.31.act_fn\nin [62, 896] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.31.down_proj" [label="Linear @ model.layers.2.mlp.experts.31.down_proj\nin [62, 896] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.31.gate_proj" [label="Linear @ model.layers.2.mlp.experts.31.gate_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.31.up_proj" [label="Linear @ model.layers.2.mlp.experts.31.up_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.32\nin [95, 1280] torch.bfloat16 | out [95, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.32.act_fn" [label="SiLU @ model.layers.2.mlp.experts.32.act_fn\nin [95, 896] torch.bfloat16 | out [95, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.32.down_proj" [label="Linear @ model.layers.2.mlp.experts.32.down_proj\nin [95, 896] torch.bfloat16 | out [95, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.32.gate_proj" [label="Linear @ model.layers.2.mlp.experts.32.gate_proj\nin [95, 1280] torch.bfloat16 | out [95, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.32.up_proj" [label="Linear @ model.layers.2.mlp.experts.32.up_proj\nin [95, 1280] torch.bfloat16 | out [95, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.33\nin [121, 1280] torch.bfloat16 | out [121, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.33.act_fn" [label="SiLU @ model.layers.2.mlp.experts.33.act_fn\nin [121, 896] torch.bfloat16 | out [121, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.33.down_proj" [label="Linear @ model.layers.2.mlp.experts.33.down_proj\nin [121, 896] torch.bfloat16 | out [121, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.33.gate_proj" [label="Linear @ model.layers.2.mlp.experts.33.gate_proj\nin [121, 1280] torch.bfloat16 | out [121, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.33.up_proj" [label="Linear @ model.layers.2.mlp.experts.33.up_proj\nin [121, 1280] torch.bfloat16 | out [121, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.34\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.34.act_fn" [label="SiLU @ model.layers.2.mlp.experts.34.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.34.down_proj" [label="Linear @ model.layers.2.mlp.experts.34.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.34.gate_proj" [label="Linear @ model.layers.2.mlp.experts.34.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.34.up_proj" [label="Linear @ model.layers.2.mlp.experts.34.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.35\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.35.act_fn" [label="SiLU @ model.layers.2.mlp.experts.35.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.35.down_proj" [label="Linear @ model.layers.2.mlp.experts.35.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.35.gate_proj" [label="Linear @ model.layers.2.mlp.experts.35.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.35.up_proj" [label="Linear @ model.layers.2.mlp.experts.35.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.36\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.36.act_fn" [label="SiLU @ model.layers.2.mlp.experts.36.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.36.down_proj" [label="Linear @ model.layers.2.mlp.experts.36.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.36.gate_proj" [label="Linear @ model.layers.2.mlp.experts.36.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.36.up_proj" [label="Linear @ model.layers.2.mlp.experts.36.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.37\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.37.act_fn" [label="SiLU @ model.layers.2.mlp.experts.37.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.37.down_proj" [label="Linear @ model.layers.2.mlp.experts.37.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.37.gate_proj" [label="Linear @ model.layers.2.mlp.experts.37.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.37.up_proj" [label="Linear @ model.layers.2.mlp.experts.37.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.38\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.38.act_fn" [label="SiLU @ model.layers.2.mlp.experts.38.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.38.down_proj" [label="Linear @ model.layers.2.mlp.experts.38.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.38.gate_proj" [label="Linear @ model.layers.2.mlp.experts.38.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.38.up_proj" [label="Linear @ model.layers.2.mlp.experts.38.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.39\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.39.act_fn" [label="SiLU @ model.layers.2.mlp.experts.39.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.39.down_proj" [label="Linear @ model.layers.2.mlp.experts.39.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.39.gate_proj" [label="Linear @ model.layers.2.mlp.experts.39.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.39.up_proj" [label="Linear @ model.layers.2.mlp.experts.39.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.4\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.4.act_fn" [label="SiLU @ model.layers.2.mlp.experts.4.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.4.down_proj" [label="Linear @ model.layers.2.mlp.experts.4.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.4.gate_proj" [label="Linear @ model.layers.2.mlp.experts.4.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.4.up_proj" [label="Linear @ model.layers.2.mlp.experts.4.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.40\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.40.act_fn" [label="SiLU @ model.layers.2.mlp.experts.40.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.40.down_proj" [label="Linear @ model.layers.2.mlp.experts.40.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.40.gate_proj" [label="Linear @ model.layers.2.mlp.experts.40.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.40.up_proj" [label="Linear @ model.layers.2.mlp.experts.40.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.41\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.41.act_fn" [label="SiLU @ model.layers.2.mlp.experts.41.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.41.down_proj" [label="Linear @ model.layers.2.mlp.experts.41.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.41.gate_proj" [label="Linear @ model.layers.2.mlp.experts.41.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.41.up_proj" [label="Linear @ model.layers.2.mlp.experts.41.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.42\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.42.act_fn" [label="SiLU @ model.layers.2.mlp.experts.42.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.42.down_proj" [label="Linear @ model.layers.2.mlp.experts.42.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.42.gate_proj" [label="Linear @ model.layers.2.mlp.experts.42.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.42.up_proj" [label="Linear @ model.layers.2.mlp.experts.42.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.43\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.43.act_fn" [label="SiLU @ model.layers.2.mlp.experts.43.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.43.down_proj" [label="Linear @ model.layers.2.mlp.experts.43.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.43.gate_proj" [label="Linear @ model.layers.2.mlp.experts.43.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.43.up_proj" [label="Linear @ model.layers.2.mlp.experts.43.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.44\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.44.act_fn" [label="SiLU @ model.layers.2.mlp.experts.44.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.44.down_proj" [label="Linear @ model.layers.2.mlp.experts.44.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.44.gate_proj" [label="Linear @ model.layers.2.mlp.experts.44.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.44.up_proj" [label="Linear @ model.layers.2.mlp.experts.44.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.45\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.45.act_fn" [label="SiLU @ model.layers.2.mlp.experts.45.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.45.down_proj" [label="Linear @ model.layers.2.mlp.experts.45.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.45.gate_proj" [label="Linear @ model.layers.2.mlp.experts.45.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.45.up_proj" [label="Linear @ model.layers.2.mlp.experts.45.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.46\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.46.act_fn" [label="SiLU @ model.layers.2.mlp.experts.46.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.46.down_proj" [label="Linear @ model.layers.2.mlp.experts.46.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.46.gate_proj" [label="Linear @ model.layers.2.mlp.experts.46.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.46.up_proj" [label="Linear @ model.layers.2.mlp.experts.46.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.47\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.47.act_fn" [label="SiLU @ model.layers.2.mlp.experts.47.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.47.down_proj" [label="Linear @ model.layers.2.mlp.experts.47.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.47.gate_proj" [label="Linear @ model.layers.2.mlp.experts.47.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.47.up_proj" [label="Linear @ model.layers.2.mlp.experts.47.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.48\nin [73, 1280] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.48.act_fn" [label="SiLU @ model.layers.2.mlp.experts.48.act_fn\nin [73, 896] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.48.down_proj" [label="Linear @ model.layers.2.mlp.experts.48.down_proj\nin [73, 896] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.48.gate_proj" [label="Linear @ model.layers.2.mlp.experts.48.gate_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.48.up_proj" [label="Linear @ model.layers.2.mlp.experts.48.up_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.49\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.49.act_fn" [label="SiLU @ model.layers.2.mlp.experts.49.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.49.down_proj" [label="Linear @ model.layers.2.mlp.experts.49.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.49.gate_proj" [label="Linear @ model.layers.2.mlp.experts.49.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.49.up_proj" [label="Linear @ model.layers.2.mlp.experts.49.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.50\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.50.act_fn" [label="SiLU @ model.layers.2.mlp.experts.50.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.50.down_proj" [label="Linear @ model.layers.2.mlp.experts.50.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.50.gate_proj" [label="Linear @ model.layers.2.mlp.experts.50.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.50.up_proj" [label="Linear @ model.layers.2.mlp.experts.50.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.51\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.51.act_fn" [label="SiLU @ model.layers.2.mlp.experts.51.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.51.down_proj" [label="Linear @ model.layers.2.mlp.experts.51.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.51.gate_proj" [label="Linear @ model.layers.2.mlp.experts.51.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.51.up_proj" [label="Linear @ model.layers.2.mlp.experts.51.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.52\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.52.act_fn" [label="SiLU @ model.layers.2.mlp.experts.52.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.52.down_proj" [label="Linear @ model.layers.2.mlp.experts.52.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.52.gate_proj" [label="Linear @ model.layers.2.mlp.experts.52.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.52.up_proj" [label="Linear @ model.layers.2.mlp.experts.52.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.53\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.53.act_fn" [label="SiLU @ model.layers.2.mlp.experts.53.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.53.down_proj" [label="Linear @ model.layers.2.mlp.experts.53.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.53.gate_proj" [label="Linear @ model.layers.2.mlp.experts.53.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.53.up_proj" [label="Linear @ model.layers.2.mlp.experts.53.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.54\nin [113, 1280] torch.bfloat16 | out [113, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.54.act_fn" [label="SiLU @ model.layers.2.mlp.experts.54.act_fn\nin [113, 896] torch.bfloat16 | out [113, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.54.down_proj" [label="Linear @ model.layers.2.mlp.experts.54.down_proj\nin [113, 896] torch.bfloat16 | out [113, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.54.gate_proj" [label="Linear @ model.layers.2.mlp.experts.54.gate_proj\nin [113, 1280] torch.bfloat16 | out [113, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.54.up_proj" [label="Linear @ model.layers.2.mlp.experts.54.up_proj\nin [113, 1280] torch.bfloat16 | out [113, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.55\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.55.act_fn" [label="SiLU @ model.layers.2.mlp.experts.55.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.55.down_proj" [label="Linear @ model.layers.2.mlp.experts.55.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.55.gate_proj" [label="Linear @ model.layers.2.mlp.experts.55.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.55.up_proj" [label="Linear @ model.layers.2.mlp.experts.55.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.56\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.56.act_fn" [label="SiLU @ model.layers.2.mlp.experts.56.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.56.down_proj" [label="Linear @ model.layers.2.mlp.experts.56.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.56.gate_proj" [label="Linear @ model.layers.2.mlp.experts.56.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.56.up_proj" [label="Linear @ model.layers.2.mlp.experts.56.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.57\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.57.act_fn" [label="SiLU @ model.layers.2.mlp.experts.57.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.57.down_proj" [label="Linear @ model.layers.2.mlp.experts.57.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.57.gate_proj" [label="Linear @ model.layers.2.mlp.experts.57.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.57.up_proj" [label="Linear @ model.layers.2.mlp.experts.57.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.59\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.59.act_fn" [label="SiLU @ model.layers.2.mlp.experts.59.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.59.down_proj" [label="Linear @ model.layers.2.mlp.experts.59.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.59.gate_proj" [label="Linear @ model.layers.2.mlp.experts.59.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.59.up_proj" [label="Linear @ model.layers.2.mlp.experts.59.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.6\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.6.act_fn" [label="SiLU @ model.layers.2.mlp.experts.6.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.6.down_proj" [label="Linear @ model.layers.2.mlp.experts.6.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.6.gate_proj" [label="Linear @ model.layers.2.mlp.experts.6.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.6.up_proj" [label="Linear @ model.layers.2.mlp.experts.6.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.60\nin [84, 1280] torch.bfloat16 | out [84, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.60.act_fn" [label="SiLU @ model.layers.2.mlp.experts.60.act_fn\nin [84, 896] torch.bfloat16 | out [84, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.60.down_proj" [label="Linear @ model.layers.2.mlp.experts.60.down_proj\nin [84, 896] torch.bfloat16 | out [84, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.60.gate_proj" [label="Linear @ model.layers.2.mlp.experts.60.gate_proj\nin [84, 1280] torch.bfloat16 | out [84, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.60.up_proj" [label="Linear @ model.layers.2.mlp.experts.60.up_proj\nin [84, 1280] torch.bfloat16 | out [84, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.61\nin [93, 1280] torch.bfloat16 | out [93, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.61.act_fn" [label="SiLU @ model.layers.2.mlp.experts.61.act_fn\nin [93, 896] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.61.down_proj" [label="Linear @ model.layers.2.mlp.experts.61.down_proj\nin [93, 896] torch.bfloat16 | out [93, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.61.gate_proj" [label="Linear @ model.layers.2.mlp.experts.61.gate_proj\nin [93, 1280] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.61.up_proj" [label="Linear @ model.layers.2.mlp.experts.61.up_proj\nin [93, 1280] torch.bfloat16 | out [93, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.62\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.62.act_fn" [label="SiLU @ model.layers.2.mlp.experts.62.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.62.down_proj" [label="Linear @ model.layers.2.mlp.experts.62.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.62.gate_proj" [label="Linear @ model.layers.2.mlp.experts.62.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.62.up_proj" [label="Linear @ model.layers.2.mlp.experts.62.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.63\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.63.act_fn" [label="SiLU @ model.layers.2.mlp.experts.63.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.63.down_proj" [label="Linear @ model.layers.2.mlp.experts.63.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.63.gate_proj" [label="Linear @ model.layers.2.mlp.experts.63.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.63.up_proj" [label="Linear @ model.layers.2.mlp.experts.63.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.7\nin [73, 1280] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.7.act_fn" [label="SiLU @ model.layers.2.mlp.experts.7.act_fn\nin [73, 896] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.7.down_proj" [label="Linear @ model.layers.2.mlp.experts.7.down_proj\nin [73, 896] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.7.gate_proj" [label="Linear @ model.layers.2.mlp.experts.7.gate_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.7.up_proj" [label="Linear @ model.layers.2.mlp.experts.7.up_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.8\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.8.act_fn" [label="SiLU @ model.layers.2.mlp.experts.8.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.8.down_proj" [label="Linear @ model.layers.2.mlp.experts.8.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.8.gate_proj" [label="Linear @ model.layers.2.mlp.experts.8.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.8.up_proj" [label="Linear @ model.layers.2.mlp.experts.8.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.2.mlp.experts.9\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.9.act_fn" [label="SiLU @ model.layers.2.mlp.experts.9.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.9.down_proj" [label="Linear @ model.layers.2.mlp.experts.9.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.2.mlp.experts.9.gate_proj" [label="Linear @ model.layers.2.mlp.experts.9.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.experts.9.up_proj" [label="Linear @ model.layers.2.mlp.experts.9.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.2.mlp.gate" [label="MoEGate @ model.layers.2.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.2.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.2.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.2.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.2.mlp.shared_experts.down_proj" [label="Linear @ model.layers.2.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.2.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.2.mlp.shared_experts.up_proj" [label="Linear @ model.layers.2.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.2.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.2.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.self_attn" [label="LlamaFlashAttention2 @ model.layers.2.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.self_attn.k_proj" [label="Linear @ model.layers.2.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.self_attn.o_proj" [label="Linear @ model.layers.2.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.self_attn.q_proj" [label="Linear @ model.layers.2.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.2.self_attn.v_proj" [label="Linear @ model.layers.2.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3" [label="DeepseekV2DecoderLayer @ model.layers.3\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.3.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.mlp" [label="DeepseekV2MoE @ model.layers.3.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.0\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.0.act_fn" [label="SiLU @ model.layers.3.mlp.experts.0.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.0.down_proj" [label="Linear @ model.layers.3.mlp.experts.0.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.0.gate_proj" [label="Linear @ model.layers.3.mlp.experts.0.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.0.up_proj" [label="Linear @ model.layers.3.mlp.experts.0.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.1\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.1.act_fn" [label="SiLU @ model.layers.3.mlp.experts.1.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.1.down_proj" [label="Linear @ model.layers.3.mlp.experts.1.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.1.gate_proj" [label="Linear @ model.layers.3.mlp.experts.1.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.1.up_proj" [label="Linear @ model.layers.3.mlp.experts.1.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.10\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.10.act_fn" [label="SiLU @ model.layers.3.mlp.experts.10.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.10.down_proj" [label="Linear @ model.layers.3.mlp.experts.10.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.10.gate_proj" [label="Linear @ model.layers.3.mlp.experts.10.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.10.up_proj" [label="Linear @ model.layers.3.mlp.experts.10.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.11\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.11.act_fn" [label="SiLU @ model.layers.3.mlp.experts.11.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.11.down_proj" [label="Linear @ model.layers.3.mlp.experts.11.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.11.gate_proj" [label="Linear @ model.layers.3.mlp.experts.11.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.11.up_proj" [label="Linear @ model.layers.3.mlp.experts.11.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.12\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.12.act_fn" [label="SiLU @ model.layers.3.mlp.experts.12.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.12.down_proj" [label="Linear @ model.layers.3.mlp.experts.12.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.12.gate_proj" [label="Linear @ model.layers.3.mlp.experts.12.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.12.up_proj" [label="Linear @ model.layers.3.mlp.experts.12.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.13\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.13.act_fn" [label="SiLU @ model.layers.3.mlp.experts.13.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.13.down_proj" [label="Linear @ model.layers.3.mlp.experts.13.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.13.gate_proj" [label="Linear @ model.layers.3.mlp.experts.13.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.13.up_proj" [label="Linear @ model.layers.3.mlp.experts.13.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.14\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.14.act_fn" [label="SiLU @ model.layers.3.mlp.experts.14.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.14.down_proj" [label="Linear @ model.layers.3.mlp.experts.14.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.14.gate_proj" [label="Linear @ model.layers.3.mlp.experts.14.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.14.up_proj" [label="Linear @ model.layers.3.mlp.experts.14.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.15\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.15.act_fn" [label="SiLU @ model.layers.3.mlp.experts.15.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.15.down_proj" [label="Linear @ model.layers.3.mlp.experts.15.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.15.gate_proj" [label="Linear @ model.layers.3.mlp.experts.15.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.15.up_proj" [label="Linear @ model.layers.3.mlp.experts.15.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.16\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.16.act_fn" [label="SiLU @ model.layers.3.mlp.experts.16.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.16.down_proj" [label="Linear @ model.layers.3.mlp.experts.16.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.16.gate_proj" [label="Linear @ model.layers.3.mlp.experts.16.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.16.up_proj" [label="Linear @ model.layers.3.mlp.experts.16.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.17\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.17.act_fn" [label="SiLU @ model.layers.3.mlp.experts.17.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.17.down_proj" [label="Linear @ model.layers.3.mlp.experts.17.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.17.gate_proj" [label="Linear @ model.layers.3.mlp.experts.17.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.17.up_proj" [label="Linear @ model.layers.3.mlp.experts.17.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.18\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.18.act_fn" [label="SiLU @ model.layers.3.mlp.experts.18.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.18.down_proj" [label="Linear @ model.layers.3.mlp.experts.18.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.18.gate_proj" [label="Linear @ model.layers.3.mlp.experts.18.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.18.up_proj" [label="Linear @ model.layers.3.mlp.experts.18.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.2\nin [77, 1280] torch.bfloat16 | out [77, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.2.act_fn" [label="SiLU @ model.layers.3.mlp.experts.2.act_fn\nin [77, 896] torch.bfloat16 | out [77, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.2.down_proj" [label="Linear @ model.layers.3.mlp.experts.2.down_proj\nin [77, 896] torch.bfloat16 | out [77, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.2.gate_proj" [label="Linear @ model.layers.3.mlp.experts.2.gate_proj\nin [77, 1280] torch.bfloat16 | out [77, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.2.up_proj" [label="Linear @ model.layers.3.mlp.experts.2.up_proj\nin [77, 1280] torch.bfloat16 | out [77, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.20\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.20.act_fn" [label="SiLU @ model.layers.3.mlp.experts.20.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.20.down_proj" [label="Linear @ model.layers.3.mlp.experts.20.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.20.gate_proj" [label="Linear @ model.layers.3.mlp.experts.20.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.20.up_proj" [label="Linear @ model.layers.3.mlp.experts.20.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.21\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.21.act_fn" [label="SiLU @ model.layers.3.mlp.experts.21.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.21.down_proj" [label="Linear @ model.layers.3.mlp.experts.21.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.21.gate_proj" [label="Linear @ model.layers.3.mlp.experts.21.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.21.up_proj" [label="Linear @ model.layers.3.mlp.experts.21.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.22\nin [103, 1280] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.22.act_fn" [label="SiLU @ model.layers.3.mlp.experts.22.act_fn\nin [103, 896] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.22.down_proj" [label="Linear @ model.layers.3.mlp.experts.22.down_proj\nin [103, 896] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.22.gate_proj" [label="Linear @ model.layers.3.mlp.experts.22.gate_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.22.up_proj" [label="Linear @ model.layers.3.mlp.experts.22.up_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.23\nin [76, 1280] torch.bfloat16 | out [76, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.23.act_fn" [label="SiLU @ model.layers.3.mlp.experts.23.act_fn\nin [76, 896] torch.bfloat16 | out [76, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.23.down_proj" [label="Linear @ model.layers.3.mlp.experts.23.down_proj\nin [76, 896] torch.bfloat16 | out [76, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.23.gate_proj" [label="Linear @ model.layers.3.mlp.experts.23.gate_proj\nin [76, 1280] torch.bfloat16 | out [76, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.23.up_proj" [label="Linear @ model.layers.3.mlp.experts.23.up_proj\nin [76, 1280] torch.bfloat16 | out [76, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.24\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.24.act_fn" [label="SiLU @ model.layers.3.mlp.experts.24.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.24.down_proj" [label="Linear @ model.layers.3.mlp.experts.24.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.24.gate_proj" [label="Linear @ model.layers.3.mlp.experts.24.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.24.up_proj" [label="Linear @ model.layers.3.mlp.experts.24.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.25\nin [62, 1280] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.25.act_fn" [label="SiLU @ model.layers.3.mlp.experts.25.act_fn\nin [62, 896] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.25.down_proj" [label="Linear @ model.layers.3.mlp.experts.25.down_proj\nin [62, 896] torch.bfloat16 | out [62, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.25.gate_proj" [label="Linear @ model.layers.3.mlp.experts.25.gate_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.25.up_proj" [label="Linear @ model.layers.3.mlp.experts.25.up_proj\nin [62, 1280] torch.bfloat16 | out [62, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.26\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.26.act_fn" [label="SiLU @ model.layers.3.mlp.experts.26.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.26.down_proj" [label="Linear @ model.layers.3.mlp.experts.26.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.26.gate_proj" [label="Linear @ model.layers.3.mlp.experts.26.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.26.up_proj" [label="Linear @ model.layers.3.mlp.experts.26.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.27\nin [50, 1280] torch.bfloat16 | out [50, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.27.act_fn" [label="SiLU @ model.layers.3.mlp.experts.27.act_fn\nin [50, 896] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.27.down_proj" [label="Linear @ model.layers.3.mlp.experts.27.down_proj\nin [50, 896] torch.bfloat16 | out [50, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.27.gate_proj" [label="Linear @ model.layers.3.mlp.experts.27.gate_proj\nin [50, 1280] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.27.up_proj" [label="Linear @ model.layers.3.mlp.experts.27.up_proj\nin [50, 1280] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.28\nin [58, 1280] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.28.act_fn" [label="SiLU @ model.layers.3.mlp.experts.28.act_fn\nin [58, 896] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.28.down_proj" [label="Linear @ model.layers.3.mlp.experts.28.down_proj\nin [58, 896] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.28.gate_proj" [label="Linear @ model.layers.3.mlp.experts.28.gate_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.28.up_proj" [label="Linear @ model.layers.3.mlp.experts.28.up_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.29\nin [64, 1280] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.29.act_fn" [label="SiLU @ model.layers.3.mlp.experts.29.act_fn\nin [64, 896] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.29.down_proj" [label="Linear @ model.layers.3.mlp.experts.29.down_proj\nin [64, 896] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.29.gate_proj" [label="Linear @ model.layers.3.mlp.experts.29.gate_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.29.up_proj" [label="Linear @ model.layers.3.mlp.experts.29.up_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.3\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.3.act_fn" [label="SiLU @ model.layers.3.mlp.experts.3.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.3.down_proj" [label="Linear @ model.layers.3.mlp.experts.3.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.3.gate_proj" [label="Linear @ model.layers.3.mlp.experts.3.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.3.up_proj" [label="Linear @ model.layers.3.mlp.experts.3.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.30\nin [55, 1280] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.30.act_fn" [label="SiLU @ model.layers.3.mlp.experts.30.act_fn\nin [55, 896] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.30.down_proj" [label="Linear @ model.layers.3.mlp.experts.30.down_proj\nin [55, 896] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.30.gate_proj" [label="Linear @ model.layers.3.mlp.experts.30.gate_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.30.up_proj" [label="Linear @ model.layers.3.mlp.experts.30.up_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.31\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.31.act_fn" [label="SiLU @ model.layers.3.mlp.experts.31.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.31.down_proj" [label="Linear @ model.layers.3.mlp.experts.31.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.31.gate_proj" [label="Linear @ model.layers.3.mlp.experts.31.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.31.up_proj" [label="Linear @ model.layers.3.mlp.experts.31.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.32\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.32.act_fn" [label="SiLU @ model.layers.3.mlp.experts.32.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.32.down_proj" [label="Linear @ model.layers.3.mlp.experts.32.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.32.gate_proj" [label="Linear @ model.layers.3.mlp.experts.32.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.32.up_proj" [label="Linear @ model.layers.3.mlp.experts.32.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.33\nin [49, 1280] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.33.act_fn" [label="SiLU @ model.layers.3.mlp.experts.33.act_fn\nin [49, 896] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.33.down_proj" [label="Linear @ model.layers.3.mlp.experts.33.down_proj\nin [49, 896] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.33.gate_proj" [label="Linear @ model.layers.3.mlp.experts.33.gate_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.33.up_proj" [label="Linear @ model.layers.3.mlp.experts.33.up_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.34\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.34.act_fn" [label="SiLU @ model.layers.3.mlp.experts.34.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.34.down_proj" [label="Linear @ model.layers.3.mlp.experts.34.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.34.gate_proj" [label="Linear @ model.layers.3.mlp.experts.34.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.34.up_proj" [label="Linear @ model.layers.3.mlp.experts.34.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.35\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.35.act_fn" [label="SiLU @ model.layers.3.mlp.experts.35.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.35.down_proj" [label="Linear @ model.layers.3.mlp.experts.35.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.35.gate_proj" [label="Linear @ model.layers.3.mlp.experts.35.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.35.up_proj" [label="Linear @ model.layers.3.mlp.experts.35.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.36\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.36.act_fn" [label="SiLU @ model.layers.3.mlp.experts.36.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.36.down_proj" [label="Linear @ model.layers.3.mlp.experts.36.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.36.gate_proj" [label="Linear @ model.layers.3.mlp.experts.36.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.36.up_proj" [label="Linear @ model.layers.3.mlp.experts.36.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.37\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.37.act_fn" [label="SiLU @ model.layers.3.mlp.experts.37.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.37.down_proj" [label="Linear @ model.layers.3.mlp.experts.37.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.37.gate_proj" [label="Linear @ model.layers.3.mlp.experts.37.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.37.up_proj" [label="Linear @ model.layers.3.mlp.experts.37.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.38\nin [118, 1280] torch.bfloat16 | out [118, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.38.act_fn" [label="SiLU @ model.layers.3.mlp.experts.38.act_fn\nin [118, 896] torch.bfloat16 | out [118, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.38.down_proj" [label="Linear @ model.layers.3.mlp.experts.38.down_proj\nin [118, 896] torch.bfloat16 | out [118, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.38.gate_proj" [label="Linear @ model.layers.3.mlp.experts.38.gate_proj\nin [118, 1280] torch.bfloat16 | out [118, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.38.up_proj" [label="Linear @ model.layers.3.mlp.experts.38.up_proj\nin [118, 1280] torch.bfloat16 | out [118, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.39\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.39.act_fn" [label="SiLU @ model.layers.3.mlp.experts.39.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.39.down_proj" [label="Linear @ model.layers.3.mlp.experts.39.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.39.gate_proj" [label="Linear @ model.layers.3.mlp.experts.39.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.39.up_proj" [label="Linear @ model.layers.3.mlp.experts.39.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.4\nin [154, 1280] torch.bfloat16 | out [154, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.4.act_fn" [label="SiLU @ model.layers.3.mlp.experts.4.act_fn\nin [154, 896] torch.bfloat16 | out [154, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.4.down_proj" [label="Linear @ model.layers.3.mlp.experts.4.down_proj\nin [154, 896] torch.bfloat16 | out [154, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.4.gate_proj" [label="Linear @ model.layers.3.mlp.experts.4.gate_proj\nin [154, 1280] torch.bfloat16 | out [154, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.4.up_proj" [label="Linear @ model.layers.3.mlp.experts.4.up_proj\nin [154, 1280] torch.bfloat16 | out [154, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.40\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.40.act_fn" [label="SiLU @ model.layers.3.mlp.experts.40.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.40.down_proj" [label="Linear @ model.layers.3.mlp.experts.40.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.40.gate_proj" [label="Linear @ model.layers.3.mlp.experts.40.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.40.up_proj" [label="Linear @ model.layers.3.mlp.experts.40.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.41\nin [38, 1280] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.41.act_fn" [label="SiLU @ model.layers.3.mlp.experts.41.act_fn\nin [38, 896] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.41.down_proj" [label="Linear @ model.layers.3.mlp.experts.41.down_proj\nin [38, 896] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.41.gate_proj" [label="Linear @ model.layers.3.mlp.experts.41.gate_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.41.up_proj" [label="Linear @ model.layers.3.mlp.experts.41.up_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.42\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.42.act_fn" [label="SiLU @ model.layers.3.mlp.experts.42.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.42.down_proj" [label="Linear @ model.layers.3.mlp.experts.42.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.42.gate_proj" [label="Linear @ model.layers.3.mlp.experts.42.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.42.up_proj" [label="Linear @ model.layers.3.mlp.experts.42.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.43\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.43.act_fn" [label="SiLU @ model.layers.3.mlp.experts.43.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.43.down_proj" [label="Linear @ model.layers.3.mlp.experts.43.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.43.gate_proj" [label="Linear @ model.layers.3.mlp.experts.43.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.43.up_proj" [label="Linear @ model.layers.3.mlp.experts.43.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.44\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.44.act_fn" [label="SiLU @ model.layers.3.mlp.experts.44.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.44.down_proj" [label="Linear @ model.layers.3.mlp.experts.44.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.44.gate_proj" [label="Linear @ model.layers.3.mlp.experts.44.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.44.up_proj" [label="Linear @ model.layers.3.mlp.experts.44.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.45\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.45.act_fn" [label="SiLU @ model.layers.3.mlp.experts.45.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.45.down_proj" [label="Linear @ model.layers.3.mlp.experts.45.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.45.gate_proj" [label="Linear @ model.layers.3.mlp.experts.45.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.45.up_proj" [label="Linear @ model.layers.3.mlp.experts.45.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.46\nin [75, 1280] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.46.act_fn" [label="SiLU @ model.layers.3.mlp.experts.46.act_fn\nin [75, 896] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.46.down_proj" [label="Linear @ model.layers.3.mlp.experts.46.down_proj\nin [75, 896] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.46.gate_proj" [label="Linear @ model.layers.3.mlp.experts.46.gate_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.46.up_proj" [label="Linear @ model.layers.3.mlp.experts.46.up_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.47\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.47.act_fn" [label="SiLU @ model.layers.3.mlp.experts.47.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.47.down_proj" [label="Linear @ model.layers.3.mlp.experts.47.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.47.gate_proj" [label="Linear @ model.layers.3.mlp.experts.47.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.47.up_proj" [label="Linear @ model.layers.3.mlp.experts.47.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.48\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.48.act_fn" [label="SiLU @ model.layers.3.mlp.experts.48.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.48.down_proj" [label="Linear @ model.layers.3.mlp.experts.48.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.48.gate_proj" [label="Linear @ model.layers.3.mlp.experts.48.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.48.up_proj" [label="Linear @ model.layers.3.mlp.experts.48.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.49\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.49.act_fn" [label="SiLU @ model.layers.3.mlp.experts.49.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.49.down_proj" [label="Linear @ model.layers.3.mlp.experts.49.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.49.gate_proj" [label="Linear @ model.layers.3.mlp.experts.49.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.49.up_proj" [label="Linear @ model.layers.3.mlp.experts.49.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.5\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.5.act_fn" [label="SiLU @ model.layers.3.mlp.experts.5.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.5.down_proj" [label="Linear @ model.layers.3.mlp.experts.5.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.5.gate_proj" [label="Linear @ model.layers.3.mlp.experts.5.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.5.up_proj" [label="Linear @ model.layers.3.mlp.experts.5.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.50\nin [36, 1280] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.50.act_fn" [label="SiLU @ model.layers.3.mlp.experts.50.act_fn\nin [36, 896] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.50.down_proj" [label="Linear @ model.layers.3.mlp.experts.50.down_proj\nin [36, 896] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.50.gate_proj" [label="Linear @ model.layers.3.mlp.experts.50.gate_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.50.up_proj" [label="Linear @ model.layers.3.mlp.experts.50.up_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.51\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.51.act_fn" [label="SiLU @ model.layers.3.mlp.experts.51.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.51.down_proj" [label="Linear @ model.layers.3.mlp.experts.51.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.51.gate_proj" [label="Linear @ model.layers.3.mlp.experts.51.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.51.up_proj" [label="Linear @ model.layers.3.mlp.experts.51.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.52\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.52.act_fn" [label="SiLU @ model.layers.3.mlp.experts.52.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.52.down_proj" [label="Linear @ model.layers.3.mlp.experts.52.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.52.gate_proj" [label="Linear @ model.layers.3.mlp.experts.52.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.52.up_proj" [label="Linear @ model.layers.3.mlp.experts.52.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.54\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.54.act_fn" [label="SiLU @ model.layers.3.mlp.experts.54.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.54.down_proj" [label="Linear @ model.layers.3.mlp.experts.54.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.54.gate_proj" [label="Linear @ model.layers.3.mlp.experts.54.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.54.up_proj" [label="Linear @ model.layers.3.mlp.experts.54.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.55\nin [80, 1280] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.55.act_fn" [label="SiLU @ model.layers.3.mlp.experts.55.act_fn\nin [80, 896] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.55.down_proj" [label="Linear @ model.layers.3.mlp.experts.55.down_proj\nin [80, 896] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.55.gate_proj" [label="Linear @ model.layers.3.mlp.experts.55.gate_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.55.up_proj" [label="Linear @ model.layers.3.mlp.experts.55.up_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.58\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.58.act_fn" [label="SiLU @ model.layers.3.mlp.experts.58.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.58.down_proj" [label="Linear @ model.layers.3.mlp.experts.58.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.58.gate_proj" [label="Linear @ model.layers.3.mlp.experts.58.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.58.up_proj" [label="Linear @ model.layers.3.mlp.experts.58.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.59\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.59.act_fn" [label="SiLU @ model.layers.3.mlp.experts.59.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.59.down_proj" [label="Linear @ model.layers.3.mlp.experts.59.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.59.gate_proj" [label="Linear @ model.layers.3.mlp.experts.59.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.59.up_proj" [label="Linear @ model.layers.3.mlp.experts.59.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.6\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.6.act_fn" [label="SiLU @ model.layers.3.mlp.experts.6.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.6.down_proj" [label="Linear @ model.layers.3.mlp.experts.6.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.6.gate_proj" [label="Linear @ model.layers.3.mlp.experts.6.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.6.up_proj" [label="Linear @ model.layers.3.mlp.experts.6.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.60\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.60.act_fn" [label="SiLU @ model.layers.3.mlp.experts.60.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.60.down_proj" [label="Linear @ model.layers.3.mlp.experts.60.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.60.gate_proj" [label="Linear @ model.layers.3.mlp.experts.60.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.60.up_proj" [label="Linear @ model.layers.3.mlp.experts.60.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.62\nin [64, 1280] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.62.act_fn" [label="SiLU @ model.layers.3.mlp.experts.62.act_fn\nin [64, 896] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.62.down_proj" [label="Linear @ model.layers.3.mlp.experts.62.down_proj\nin [64, 896] torch.bfloat16 | out [64, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.62.gate_proj" [label="Linear @ model.layers.3.mlp.experts.62.gate_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.62.up_proj" [label="Linear @ model.layers.3.mlp.experts.62.up_proj\nin [64, 1280] torch.bfloat16 | out [64, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.63\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.63.act_fn" [label="SiLU @ model.layers.3.mlp.experts.63.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.63.down_proj" [label="Linear @ model.layers.3.mlp.experts.63.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.63.gate_proj" [label="Linear @ model.layers.3.mlp.experts.63.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.63.up_proj" [label="Linear @ model.layers.3.mlp.experts.63.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.8\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.8.act_fn" [label="SiLU @ model.layers.3.mlp.experts.8.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.8.down_proj" [label="Linear @ model.layers.3.mlp.experts.8.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.8.gate_proj" [label="Linear @ model.layers.3.mlp.experts.8.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.8.up_proj" [label="Linear @ model.layers.3.mlp.experts.8.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.3.mlp.experts.9\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.9.act_fn" [label="SiLU @ model.layers.3.mlp.experts.9.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.9.down_proj" [label="Linear @ model.layers.3.mlp.experts.9.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.3.mlp.experts.9.gate_proj" [label="Linear @ model.layers.3.mlp.experts.9.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.experts.9.up_proj" [label="Linear @ model.layers.3.mlp.experts.9.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.3.mlp.gate" [label="MoEGate @ model.layers.3.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.3.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.3.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.3.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.3.mlp.shared_experts.down_proj" [label="Linear @ model.layers.3.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.3.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.3.mlp.shared_experts.up_proj" [label="Linear @ model.layers.3.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.3.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.3.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.self_attn" [label="LlamaFlashAttention2 @ model.layers.3.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.self_attn.k_proj" [label="Linear @ model.layers.3.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.self_attn.o_proj" [label="Linear @ model.layers.3.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.self_attn.q_proj" [label="Linear @ model.layers.3.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.3.self_attn.v_proj" [label="Linear @ model.layers.3.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4" [label="DeepseekV2DecoderLayer @ model.layers.4\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.4.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.mlp" [label="DeepseekV2MoE @ model.layers.4.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.0\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.0.act_fn" [label="SiLU @ model.layers.4.mlp.experts.0.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.0.down_proj" [label="Linear @ model.layers.4.mlp.experts.0.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.0.gate_proj" [label="Linear @ model.layers.4.mlp.experts.0.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.0.up_proj" [label="Linear @ model.layers.4.mlp.experts.0.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.1\nin [90, 1280] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.1.act_fn" [label="SiLU @ model.layers.4.mlp.experts.1.act_fn\nin [90, 896] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.1.down_proj" [label="Linear @ model.layers.4.mlp.experts.1.down_proj\nin [90, 896] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.1.gate_proj" [label="Linear @ model.layers.4.mlp.experts.1.gate_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.1.up_proj" [label="Linear @ model.layers.4.mlp.experts.1.up_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.10\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.10.act_fn" [label="SiLU @ model.layers.4.mlp.experts.10.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.10.down_proj" [label="Linear @ model.layers.4.mlp.experts.10.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.10.gate_proj" [label="Linear @ model.layers.4.mlp.experts.10.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.10.up_proj" [label="Linear @ model.layers.4.mlp.experts.10.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.11\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.11.act_fn" [label="SiLU @ model.layers.4.mlp.experts.11.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.11.down_proj" [label="Linear @ model.layers.4.mlp.experts.11.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.11.gate_proj" [label="Linear @ model.layers.4.mlp.experts.11.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.11.up_proj" [label="Linear @ model.layers.4.mlp.experts.11.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.12\nin [47, 1280] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.12.act_fn" [label="SiLU @ model.layers.4.mlp.experts.12.act_fn\nin [47, 896] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.12.down_proj" [label="Linear @ model.layers.4.mlp.experts.12.down_proj\nin [47, 896] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.12.gate_proj" [label="Linear @ model.layers.4.mlp.experts.12.gate_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.12.up_proj" [label="Linear @ model.layers.4.mlp.experts.12.up_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.13\nin [43, 1280] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.13.act_fn" [label="SiLU @ model.layers.4.mlp.experts.13.act_fn\nin [43, 896] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.13.down_proj" [label="Linear @ model.layers.4.mlp.experts.13.down_proj\nin [43, 896] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.13.gate_proj" [label="Linear @ model.layers.4.mlp.experts.13.gate_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.13.up_proj" [label="Linear @ model.layers.4.mlp.experts.13.up_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.14\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.14.act_fn" [label="SiLU @ model.layers.4.mlp.experts.14.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.14.down_proj" [label="Linear @ model.layers.4.mlp.experts.14.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.14.gate_proj" [label="Linear @ model.layers.4.mlp.experts.14.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.14.up_proj" [label="Linear @ model.layers.4.mlp.experts.14.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.15\nin [44, 1280] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.15.act_fn" [label="SiLU @ model.layers.4.mlp.experts.15.act_fn\nin [44, 896] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.15.down_proj" [label="Linear @ model.layers.4.mlp.experts.15.down_proj\nin [44, 896] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.15.gate_proj" [label="Linear @ model.layers.4.mlp.experts.15.gate_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.15.up_proj" [label="Linear @ model.layers.4.mlp.experts.15.up_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.16\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.16.act_fn" [label="SiLU @ model.layers.4.mlp.experts.16.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.16.down_proj" [label="Linear @ model.layers.4.mlp.experts.16.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.16.gate_proj" [label="Linear @ model.layers.4.mlp.experts.16.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.16.up_proj" [label="Linear @ model.layers.4.mlp.experts.16.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.17\nin [90, 1280] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.17.act_fn" [label="SiLU @ model.layers.4.mlp.experts.17.act_fn\nin [90, 896] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.17.down_proj" [label="Linear @ model.layers.4.mlp.experts.17.down_proj\nin [90, 896] torch.bfloat16 | out [90, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.17.gate_proj" [label="Linear @ model.layers.4.mlp.experts.17.gate_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.17.up_proj" [label="Linear @ model.layers.4.mlp.experts.17.up_proj\nin [90, 1280] torch.bfloat16 | out [90, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.18\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.18.act_fn" [label="SiLU @ model.layers.4.mlp.experts.18.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.18.down_proj" [label="Linear @ model.layers.4.mlp.experts.18.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.18.gate_proj" [label="Linear @ model.layers.4.mlp.experts.18.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.18.up_proj" [label="Linear @ model.layers.4.mlp.experts.18.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.19\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.19.act_fn" [label="SiLU @ model.layers.4.mlp.experts.19.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.19.down_proj" [label="Linear @ model.layers.4.mlp.experts.19.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.19.gate_proj" [label="Linear @ model.layers.4.mlp.experts.19.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.19.up_proj" [label="Linear @ model.layers.4.mlp.experts.19.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.2\nin [82, 1280] torch.bfloat16 | out [82, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.2.act_fn" [label="SiLU @ model.layers.4.mlp.experts.2.act_fn\nin [82, 896] torch.bfloat16 | out [82, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.2.down_proj" [label="Linear @ model.layers.4.mlp.experts.2.down_proj\nin [82, 896] torch.bfloat16 | out [82, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.2.gate_proj" [label="Linear @ model.layers.4.mlp.experts.2.gate_proj\nin [82, 1280] torch.bfloat16 | out [82, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.2.up_proj" [label="Linear @ model.layers.4.mlp.experts.2.up_proj\nin [82, 1280] torch.bfloat16 | out [82, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.20\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.20.act_fn" [label="SiLU @ model.layers.4.mlp.experts.20.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.20.down_proj" [label="Linear @ model.layers.4.mlp.experts.20.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.20.gate_proj" [label="Linear @ model.layers.4.mlp.experts.20.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.20.up_proj" [label="Linear @ model.layers.4.mlp.experts.20.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.21\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.21.act_fn" [label="SiLU @ model.layers.4.mlp.experts.21.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.21.down_proj" [label="Linear @ model.layers.4.mlp.experts.21.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.21.gate_proj" [label="Linear @ model.layers.4.mlp.experts.21.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.21.up_proj" [label="Linear @ model.layers.4.mlp.experts.21.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.22\nin [103, 1280] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.22.act_fn" [label="SiLU @ model.layers.4.mlp.experts.22.act_fn\nin [103, 896] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.22.down_proj" [label="Linear @ model.layers.4.mlp.experts.22.down_proj\nin [103, 896] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.22.gate_proj" [label="Linear @ model.layers.4.mlp.experts.22.gate_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.22.up_proj" [label="Linear @ model.layers.4.mlp.experts.22.up_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.23\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.23.act_fn" [label="SiLU @ model.layers.4.mlp.experts.23.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.23.down_proj" [label="Linear @ model.layers.4.mlp.experts.23.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.23.gate_proj" [label="Linear @ model.layers.4.mlp.experts.23.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.23.up_proj" [label="Linear @ model.layers.4.mlp.experts.23.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.24\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.24.act_fn" [label="SiLU @ model.layers.4.mlp.experts.24.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.24.down_proj" [label="Linear @ model.layers.4.mlp.experts.24.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.24.gate_proj" [label="Linear @ model.layers.4.mlp.experts.24.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.24.up_proj" [label="Linear @ model.layers.4.mlp.experts.24.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.25\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.25.act_fn" [label="SiLU @ model.layers.4.mlp.experts.25.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.25.down_proj" [label="Linear @ model.layers.4.mlp.experts.25.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.25.gate_proj" [label="Linear @ model.layers.4.mlp.experts.25.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.25.up_proj" [label="Linear @ model.layers.4.mlp.experts.25.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.26\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.26.act_fn" [label="SiLU @ model.layers.4.mlp.experts.26.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.26.down_proj" [label="Linear @ model.layers.4.mlp.experts.26.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.26.gate_proj" [label="Linear @ model.layers.4.mlp.experts.26.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.26.up_proj" [label="Linear @ model.layers.4.mlp.experts.26.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.27\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.27.act_fn" [label="SiLU @ model.layers.4.mlp.experts.27.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.27.down_proj" [label="Linear @ model.layers.4.mlp.experts.27.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.27.gate_proj" [label="Linear @ model.layers.4.mlp.experts.27.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.27.up_proj" [label="Linear @ model.layers.4.mlp.experts.27.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.28\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.28.act_fn" [label="SiLU @ model.layers.4.mlp.experts.28.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.28.down_proj" [label="Linear @ model.layers.4.mlp.experts.28.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.28.gate_proj" [label="Linear @ model.layers.4.mlp.experts.28.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.28.up_proj" [label="Linear @ model.layers.4.mlp.experts.28.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.3\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.3.act_fn" [label="SiLU @ model.layers.4.mlp.experts.3.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.3.down_proj" [label="Linear @ model.layers.4.mlp.experts.3.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.3.gate_proj" [label="Linear @ model.layers.4.mlp.experts.3.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.3.up_proj" [label="Linear @ model.layers.4.mlp.experts.3.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.30\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.30.act_fn" [label="SiLU @ model.layers.4.mlp.experts.30.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.30.down_proj" [label="Linear @ model.layers.4.mlp.experts.30.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.30.gate_proj" [label="Linear @ model.layers.4.mlp.experts.30.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.30.up_proj" [label="Linear @ model.layers.4.mlp.experts.30.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.31\nin [63, 1280] torch.bfloat16 | out [63, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.31.act_fn" [label="SiLU @ model.layers.4.mlp.experts.31.act_fn\nin [63, 896] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.31.down_proj" [label="Linear @ model.layers.4.mlp.experts.31.down_proj\nin [63, 896] torch.bfloat16 | out [63, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.31.gate_proj" [label="Linear @ model.layers.4.mlp.experts.31.gate_proj\nin [63, 1280] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.31.up_proj" [label="Linear @ model.layers.4.mlp.experts.31.up_proj\nin [63, 1280] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.32\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.32.act_fn" [label="SiLU @ model.layers.4.mlp.experts.32.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.32.down_proj" [label="Linear @ model.layers.4.mlp.experts.32.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.32.gate_proj" [label="Linear @ model.layers.4.mlp.experts.32.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.32.up_proj" [label="Linear @ model.layers.4.mlp.experts.32.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.33\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.33.act_fn" [label="SiLU @ model.layers.4.mlp.experts.33.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.33.down_proj" [label="Linear @ model.layers.4.mlp.experts.33.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.33.gate_proj" [label="Linear @ model.layers.4.mlp.experts.33.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.33.up_proj" [label="Linear @ model.layers.4.mlp.experts.33.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.34\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.34.act_fn" [label="SiLU @ model.layers.4.mlp.experts.34.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.34.down_proj" [label="Linear @ model.layers.4.mlp.experts.34.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.34.gate_proj" [label="Linear @ model.layers.4.mlp.experts.34.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.34.up_proj" [label="Linear @ model.layers.4.mlp.experts.34.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.35\nin [65, 1280] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.35.act_fn" [label="SiLU @ model.layers.4.mlp.experts.35.act_fn\nin [65, 896] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.35.down_proj" [label="Linear @ model.layers.4.mlp.experts.35.down_proj\nin [65, 896] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.35.gate_proj" [label="Linear @ model.layers.4.mlp.experts.35.gate_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.35.up_proj" [label="Linear @ model.layers.4.mlp.experts.35.up_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.36\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.36.act_fn" [label="SiLU @ model.layers.4.mlp.experts.36.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.36.down_proj" [label="Linear @ model.layers.4.mlp.experts.36.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.36.gate_proj" [label="Linear @ model.layers.4.mlp.experts.36.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.36.up_proj" [label="Linear @ model.layers.4.mlp.experts.36.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.37\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.37.act_fn" [label="SiLU @ model.layers.4.mlp.experts.37.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.37.down_proj" [label="Linear @ model.layers.4.mlp.experts.37.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.37.gate_proj" [label="Linear @ model.layers.4.mlp.experts.37.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.37.up_proj" [label="Linear @ model.layers.4.mlp.experts.37.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.39\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.39.act_fn" [label="SiLU @ model.layers.4.mlp.experts.39.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.39.down_proj" [label="Linear @ model.layers.4.mlp.experts.39.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.39.gate_proj" [label="Linear @ model.layers.4.mlp.experts.39.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.39.up_proj" [label="Linear @ model.layers.4.mlp.experts.39.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.4\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.4.act_fn" [label="SiLU @ model.layers.4.mlp.experts.4.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.4.down_proj" [label="Linear @ model.layers.4.mlp.experts.4.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.4.gate_proj" [label="Linear @ model.layers.4.mlp.experts.4.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.4.up_proj" [label="Linear @ model.layers.4.mlp.experts.4.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.40\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.40.act_fn" [label="SiLU @ model.layers.4.mlp.experts.40.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.40.down_proj" [label="Linear @ model.layers.4.mlp.experts.40.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.40.gate_proj" [label="Linear @ model.layers.4.mlp.experts.40.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.40.up_proj" [label="Linear @ model.layers.4.mlp.experts.40.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.41\nin [123, 1280] torch.bfloat16 | out [123, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.41.act_fn" [label="SiLU @ model.layers.4.mlp.experts.41.act_fn\nin [123, 896] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.41.down_proj" [label="Linear @ model.layers.4.mlp.experts.41.down_proj\nin [123, 896] torch.bfloat16 | out [123, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.41.gate_proj" [label="Linear @ model.layers.4.mlp.experts.41.gate_proj\nin [123, 1280] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.41.up_proj" [label="Linear @ model.layers.4.mlp.experts.41.up_proj\nin [123, 1280] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.42\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.42.act_fn" [label="SiLU @ model.layers.4.mlp.experts.42.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.42.down_proj" [label="Linear @ model.layers.4.mlp.experts.42.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.42.gate_proj" [label="Linear @ model.layers.4.mlp.experts.42.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.42.up_proj" [label="Linear @ model.layers.4.mlp.experts.42.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.44\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.44.act_fn" [label="SiLU @ model.layers.4.mlp.experts.44.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.44.down_proj" [label="Linear @ model.layers.4.mlp.experts.44.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.44.gate_proj" [label="Linear @ model.layers.4.mlp.experts.44.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.44.up_proj" [label="Linear @ model.layers.4.mlp.experts.44.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.45\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.45.act_fn" [label="SiLU @ model.layers.4.mlp.experts.45.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.45.down_proj" [label="Linear @ model.layers.4.mlp.experts.45.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.45.gate_proj" [label="Linear @ model.layers.4.mlp.experts.45.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.45.up_proj" [label="Linear @ model.layers.4.mlp.experts.45.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.46\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.46.act_fn" [label="SiLU @ model.layers.4.mlp.experts.46.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.46.down_proj" [label="Linear @ model.layers.4.mlp.experts.46.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.46.gate_proj" [label="Linear @ model.layers.4.mlp.experts.46.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.46.up_proj" [label="Linear @ model.layers.4.mlp.experts.46.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.47\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.47.act_fn" [label="SiLU @ model.layers.4.mlp.experts.47.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.47.down_proj" [label="Linear @ model.layers.4.mlp.experts.47.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.47.gate_proj" [label="Linear @ model.layers.4.mlp.experts.47.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.47.up_proj" [label="Linear @ model.layers.4.mlp.experts.47.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.48\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.48.act_fn" [label="SiLU @ model.layers.4.mlp.experts.48.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.48.down_proj" [label="Linear @ model.layers.4.mlp.experts.48.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.48.gate_proj" [label="Linear @ model.layers.4.mlp.experts.48.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.48.up_proj" [label="Linear @ model.layers.4.mlp.experts.48.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.49\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.49.act_fn" [label="SiLU @ model.layers.4.mlp.experts.49.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.49.down_proj" [label="Linear @ model.layers.4.mlp.experts.49.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.49.gate_proj" [label="Linear @ model.layers.4.mlp.experts.49.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.49.up_proj" [label="Linear @ model.layers.4.mlp.experts.49.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.5\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.5.act_fn" [label="SiLU @ model.layers.4.mlp.experts.5.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.5.down_proj" [label="Linear @ model.layers.4.mlp.experts.5.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.5.gate_proj" [label="Linear @ model.layers.4.mlp.experts.5.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.5.up_proj" [label="Linear @ model.layers.4.mlp.experts.5.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.51\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.51.act_fn" [label="SiLU @ model.layers.4.mlp.experts.51.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.51.down_proj" [label="Linear @ model.layers.4.mlp.experts.51.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.51.gate_proj" [label="Linear @ model.layers.4.mlp.experts.51.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.51.up_proj" [label="Linear @ model.layers.4.mlp.experts.51.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.52\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.52.act_fn" [label="SiLU @ model.layers.4.mlp.experts.52.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.52.down_proj" [label="Linear @ model.layers.4.mlp.experts.52.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.52.gate_proj" [label="Linear @ model.layers.4.mlp.experts.52.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.52.up_proj" [label="Linear @ model.layers.4.mlp.experts.52.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.53\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.53.act_fn" [label="SiLU @ model.layers.4.mlp.experts.53.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.53.down_proj" [label="Linear @ model.layers.4.mlp.experts.53.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.53.gate_proj" [label="Linear @ model.layers.4.mlp.experts.53.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.53.up_proj" [label="Linear @ model.layers.4.mlp.experts.53.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.54\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.54.act_fn" [label="SiLU @ model.layers.4.mlp.experts.54.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.54.down_proj" [label="Linear @ model.layers.4.mlp.experts.54.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.54.gate_proj" [label="Linear @ model.layers.4.mlp.experts.54.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.54.up_proj" [label="Linear @ model.layers.4.mlp.experts.54.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.56\nin [71, 1280] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.56.act_fn" [label="SiLU @ model.layers.4.mlp.experts.56.act_fn\nin [71, 896] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.56.down_proj" [label="Linear @ model.layers.4.mlp.experts.56.down_proj\nin [71, 896] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.56.gate_proj" [label="Linear @ model.layers.4.mlp.experts.56.gate_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.56.up_proj" [label="Linear @ model.layers.4.mlp.experts.56.up_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.58\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.58.act_fn" [label="SiLU @ model.layers.4.mlp.experts.58.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.58.down_proj" [label="Linear @ model.layers.4.mlp.experts.58.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.58.gate_proj" [label="Linear @ model.layers.4.mlp.experts.58.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.58.up_proj" [label="Linear @ model.layers.4.mlp.experts.58.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.59\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.59.act_fn" [label="SiLU @ model.layers.4.mlp.experts.59.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.59.down_proj" [label="Linear @ model.layers.4.mlp.experts.59.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.59.gate_proj" [label="Linear @ model.layers.4.mlp.experts.59.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.59.up_proj" [label="Linear @ model.layers.4.mlp.experts.59.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.6\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.6.act_fn" [label="SiLU @ model.layers.4.mlp.experts.6.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.6.down_proj" [label="Linear @ model.layers.4.mlp.experts.6.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.6.gate_proj" [label="Linear @ model.layers.4.mlp.experts.6.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.6.up_proj" [label="Linear @ model.layers.4.mlp.experts.6.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.60\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.60.act_fn" [label="SiLU @ model.layers.4.mlp.experts.60.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.60.down_proj" [label="Linear @ model.layers.4.mlp.experts.60.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.60.gate_proj" [label="Linear @ model.layers.4.mlp.experts.60.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.60.up_proj" [label="Linear @ model.layers.4.mlp.experts.60.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.61\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.61.act_fn" [label="SiLU @ model.layers.4.mlp.experts.61.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.61.down_proj" [label="Linear @ model.layers.4.mlp.experts.61.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.61.gate_proj" [label="Linear @ model.layers.4.mlp.experts.61.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.61.up_proj" [label="Linear @ model.layers.4.mlp.experts.61.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.62\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.62.act_fn" [label="SiLU @ model.layers.4.mlp.experts.62.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.62.down_proj" [label="Linear @ model.layers.4.mlp.experts.62.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.62.gate_proj" [label="Linear @ model.layers.4.mlp.experts.62.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.62.up_proj" [label="Linear @ model.layers.4.mlp.experts.62.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.63\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.63.act_fn" [label="SiLU @ model.layers.4.mlp.experts.63.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.63.down_proj" [label="Linear @ model.layers.4.mlp.experts.63.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.63.gate_proj" [label="Linear @ model.layers.4.mlp.experts.63.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.63.up_proj" [label="Linear @ model.layers.4.mlp.experts.63.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.7\nin [104, 1280] torch.bfloat16 | out [104, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.7.act_fn" [label="SiLU @ model.layers.4.mlp.experts.7.act_fn\nin [104, 896] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.7.down_proj" [label="Linear @ model.layers.4.mlp.experts.7.down_proj\nin [104, 896] torch.bfloat16 | out [104, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.7.gate_proj" [label="Linear @ model.layers.4.mlp.experts.7.gate_proj\nin [104, 1280] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.7.up_proj" [label="Linear @ model.layers.4.mlp.experts.7.up_proj\nin [104, 1280] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.8\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.8.act_fn" [label="SiLU @ model.layers.4.mlp.experts.8.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.8.down_proj" [label="Linear @ model.layers.4.mlp.experts.8.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.8.gate_proj" [label="Linear @ model.layers.4.mlp.experts.8.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.8.up_proj" [label="Linear @ model.layers.4.mlp.experts.8.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.4.mlp.experts.9\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.9.act_fn" [label="SiLU @ model.layers.4.mlp.experts.9.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.9.down_proj" [label="Linear @ model.layers.4.mlp.experts.9.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.4.mlp.experts.9.gate_proj" [label="Linear @ model.layers.4.mlp.experts.9.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.4.mlp.experts.9.up_proj" [label="Linear @ model.layers.4.mlp.experts.9.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.4.mlp.gate" [label="MoEGate @ model.layers.4.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.4.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.4.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.4.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.4.mlp.shared_experts.down_proj" [label="Linear @ model.layers.4.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.4.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.4.mlp.shared_experts.up_proj" [label="Linear @ model.layers.4.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.4.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.4.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.self_attn" [label="LlamaFlashAttention2 @ model.layers.4.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.self_attn.k_proj" [label="Linear @ model.layers.4.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.self_attn.o_proj" [label="Linear @ model.layers.4.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.self_attn.q_proj" [label="Linear @ model.layers.4.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.4.self_attn.v_proj" [label="Linear @ model.layers.4.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5" [label="DeepseekV2DecoderLayer @ model.layers.5\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.5.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.mlp" [label="DeepseekV2MoE @ model.layers.5.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.0\nin [86, 1280] torch.bfloat16 | out [86, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.0.act_fn" [label="SiLU @ model.layers.5.mlp.experts.0.act_fn\nin [86, 896] torch.bfloat16 | out [86, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.0.down_proj" [label="Linear @ model.layers.5.mlp.experts.0.down_proj\nin [86, 896] torch.bfloat16 | out [86, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.0.gate_proj" [label="Linear @ model.layers.5.mlp.experts.0.gate_proj\nin [86, 1280] torch.bfloat16 | out [86, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.0.up_proj" [label="Linear @ model.layers.5.mlp.experts.0.up_proj\nin [86, 1280] torch.bfloat16 | out [86, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.1\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.1.act_fn" [label="SiLU @ model.layers.5.mlp.experts.1.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.1.down_proj" [label="Linear @ model.layers.5.mlp.experts.1.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.1.gate_proj" [label="Linear @ model.layers.5.mlp.experts.1.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.1.up_proj" [label="Linear @ model.layers.5.mlp.experts.1.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.10\nin [130, 1280] torch.bfloat16 | out [130, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.10.act_fn" [label="SiLU @ model.layers.5.mlp.experts.10.act_fn\nin [130, 896] torch.bfloat16 | out [130, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.10.down_proj" [label="Linear @ model.layers.5.mlp.experts.10.down_proj\nin [130, 896] torch.bfloat16 | out [130, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.10.gate_proj" [label="Linear @ model.layers.5.mlp.experts.10.gate_proj\nin [130, 1280] torch.bfloat16 | out [130, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.10.up_proj" [label="Linear @ model.layers.5.mlp.experts.10.up_proj\nin [130, 1280] torch.bfloat16 | out [130, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.12\nin [97, 1280] torch.bfloat16 | out [97, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.12.act_fn" [label="SiLU @ model.layers.5.mlp.experts.12.act_fn\nin [97, 896] torch.bfloat16 | out [97, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.12.down_proj" [label="Linear @ model.layers.5.mlp.experts.12.down_proj\nin [97, 896] torch.bfloat16 | out [97, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.12.gate_proj" [label="Linear @ model.layers.5.mlp.experts.12.gate_proj\nin [97, 1280] torch.bfloat16 | out [97, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.12.up_proj" [label="Linear @ model.layers.5.mlp.experts.12.up_proj\nin [97, 1280] torch.bfloat16 | out [97, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.13\nin [55, 1280] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.13.act_fn" [label="SiLU @ model.layers.5.mlp.experts.13.act_fn\nin [55, 896] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.13.down_proj" [label="Linear @ model.layers.5.mlp.experts.13.down_proj\nin [55, 896] torch.bfloat16 | out [55, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.13.gate_proj" [label="Linear @ model.layers.5.mlp.experts.13.gate_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.13.up_proj" [label="Linear @ model.layers.5.mlp.experts.13.up_proj\nin [55, 1280] torch.bfloat16 | out [55, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.14\nin [38, 1280] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.14.act_fn" [label="SiLU @ model.layers.5.mlp.experts.14.act_fn\nin [38, 896] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.14.down_proj" [label="Linear @ model.layers.5.mlp.experts.14.down_proj\nin [38, 896] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.14.gate_proj" [label="Linear @ model.layers.5.mlp.experts.14.gate_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.14.up_proj" [label="Linear @ model.layers.5.mlp.experts.14.up_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.15\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.15.act_fn" [label="SiLU @ model.layers.5.mlp.experts.15.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.15.down_proj" [label="Linear @ model.layers.5.mlp.experts.15.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.15.gate_proj" [label="Linear @ model.layers.5.mlp.experts.15.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.15.up_proj" [label="Linear @ model.layers.5.mlp.experts.15.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.16\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.16.act_fn" [label="SiLU @ model.layers.5.mlp.experts.16.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.16.down_proj" [label="Linear @ model.layers.5.mlp.experts.16.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.16.gate_proj" [label="Linear @ model.layers.5.mlp.experts.16.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.16.up_proj" [label="Linear @ model.layers.5.mlp.experts.16.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.17\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.17.act_fn" [label="SiLU @ model.layers.5.mlp.experts.17.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.17.down_proj" [label="Linear @ model.layers.5.mlp.experts.17.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.17.gate_proj" [label="Linear @ model.layers.5.mlp.experts.17.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.17.up_proj" [label="Linear @ model.layers.5.mlp.experts.17.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.18\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.18.act_fn" [label="SiLU @ model.layers.5.mlp.experts.18.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.18.down_proj" [label="Linear @ model.layers.5.mlp.experts.18.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.18.gate_proj" [label="Linear @ model.layers.5.mlp.experts.18.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.18.up_proj" [label="Linear @ model.layers.5.mlp.experts.18.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.19\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.19.act_fn" [label="SiLU @ model.layers.5.mlp.experts.19.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.19.down_proj" [label="Linear @ model.layers.5.mlp.experts.19.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.19.gate_proj" [label="Linear @ model.layers.5.mlp.experts.19.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.19.up_proj" [label="Linear @ model.layers.5.mlp.experts.19.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.2\nin [37, 1280] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.2.act_fn" [label="SiLU @ model.layers.5.mlp.experts.2.act_fn\nin [37, 896] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.2.down_proj" [label="Linear @ model.layers.5.mlp.experts.2.down_proj\nin [37, 896] torch.bfloat16 | out [37, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.2.gate_proj" [label="Linear @ model.layers.5.mlp.experts.2.gate_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.2.up_proj" [label="Linear @ model.layers.5.mlp.experts.2.up_proj\nin [37, 1280] torch.bfloat16 | out [37, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.20\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.20.act_fn" [label="SiLU @ model.layers.5.mlp.experts.20.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.20.down_proj" [label="Linear @ model.layers.5.mlp.experts.20.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.20.gate_proj" [label="Linear @ model.layers.5.mlp.experts.20.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.20.up_proj" [label="Linear @ model.layers.5.mlp.experts.20.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.21\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.21.act_fn" [label="SiLU @ model.layers.5.mlp.experts.21.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.21.down_proj" [label="Linear @ model.layers.5.mlp.experts.21.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.21.gate_proj" [label="Linear @ model.layers.5.mlp.experts.21.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.21.up_proj" [label="Linear @ model.layers.5.mlp.experts.21.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.22\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.22.act_fn" [label="SiLU @ model.layers.5.mlp.experts.22.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.22.down_proj" [label="Linear @ model.layers.5.mlp.experts.22.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.22.gate_proj" [label="Linear @ model.layers.5.mlp.experts.22.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.22.up_proj" [label="Linear @ model.layers.5.mlp.experts.22.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.23\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.23.act_fn" [label="SiLU @ model.layers.5.mlp.experts.23.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.23.down_proj" [label="Linear @ model.layers.5.mlp.experts.23.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.23.gate_proj" [label="Linear @ model.layers.5.mlp.experts.23.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.23.up_proj" [label="Linear @ model.layers.5.mlp.experts.23.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.24\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.24.act_fn" [label="SiLU @ model.layers.5.mlp.experts.24.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.24.down_proj" [label="Linear @ model.layers.5.mlp.experts.24.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.24.gate_proj" [label="Linear @ model.layers.5.mlp.experts.24.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.24.up_proj" [label="Linear @ model.layers.5.mlp.experts.24.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.25\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.25.act_fn" [label="SiLU @ model.layers.5.mlp.experts.25.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.25.down_proj" [label="Linear @ model.layers.5.mlp.experts.25.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.25.gate_proj" [label="Linear @ model.layers.5.mlp.experts.25.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.25.up_proj" [label="Linear @ model.layers.5.mlp.experts.25.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.27\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.27.act_fn" [label="SiLU @ model.layers.5.mlp.experts.27.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.27.down_proj" [label="Linear @ model.layers.5.mlp.experts.27.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.27.gate_proj" [label="Linear @ model.layers.5.mlp.experts.27.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.27.up_proj" [label="Linear @ model.layers.5.mlp.experts.27.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.29\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.29.act_fn" [label="SiLU @ model.layers.5.mlp.experts.29.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.29.down_proj" [label="Linear @ model.layers.5.mlp.experts.29.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.29.gate_proj" [label="Linear @ model.layers.5.mlp.experts.29.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.29.up_proj" [label="Linear @ model.layers.5.mlp.experts.29.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.3\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.3.act_fn" [label="SiLU @ model.layers.5.mlp.experts.3.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.3.down_proj" [label="Linear @ model.layers.5.mlp.experts.3.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.3.gate_proj" [label="Linear @ model.layers.5.mlp.experts.3.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.3.up_proj" [label="Linear @ model.layers.5.mlp.experts.3.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.30\nin [68, 1280] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.30.act_fn" [label="SiLU @ model.layers.5.mlp.experts.30.act_fn\nin [68, 896] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.30.down_proj" [label="Linear @ model.layers.5.mlp.experts.30.down_proj\nin [68, 896] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.30.gate_proj" [label="Linear @ model.layers.5.mlp.experts.30.gate_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.30.up_proj" [label="Linear @ model.layers.5.mlp.experts.30.up_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.31\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.31.act_fn" [label="SiLU @ model.layers.5.mlp.experts.31.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.31.down_proj" [label="Linear @ model.layers.5.mlp.experts.31.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.31.gate_proj" [label="Linear @ model.layers.5.mlp.experts.31.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.31.up_proj" [label="Linear @ model.layers.5.mlp.experts.31.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.32\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.32.act_fn" [label="SiLU @ model.layers.5.mlp.experts.32.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.32.down_proj" [label="Linear @ model.layers.5.mlp.experts.32.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.32.gate_proj" [label="Linear @ model.layers.5.mlp.experts.32.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.32.up_proj" [label="Linear @ model.layers.5.mlp.experts.32.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.33\nin [38, 1280] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.33.act_fn" [label="SiLU @ model.layers.5.mlp.experts.33.act_fn\nin [38, 896] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.33.down_proj" [label="Linear @ model.layers.5.mlp.experts.33.down_proj\nin [38, 896] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.33.gate_proj" [label="Linear @ model.layers.5.mlp.experts.33.gate_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.33.up_proj" [label="Linear @ model.layers.5.mlp.experts.33.up_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.34\nin [125, 1280] torch.bfloat16 | out [125, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.34.act_fn" [label="SiLU @ model.layers.5.mlp.experts.34.act_fn\nin [125, 896] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.34.down_proj" [label="Linear @ model.layers.5.mlp.experts.34.down_proj\nin [125, 896] torch.bfloat16 | out [125, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.34.gate_proj" [label="Linear @ model.layers.5.mlp.experts.34.gate_proj\nin [125, 1280] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.34.up_proj" [label="Linear @ model.layers.5.mlp.experts.34.up_proj\nin [125, 1280] torch.bfloat16 | out [125, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.35\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.35.act_fn" [label="SiLU @ model.layers.5.mlp.experts.35.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.35.down_proj" [label="Linear @ model.layers.5.mlp.experts.35.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.35.gate_proj" [label="Linear @ model.layers.5.mlp.experts.35.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.35.up_proj" [label="Linear @ model.layers.5.mlp.experts.35.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.36\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.36.act_fn" [label="SiLU @ model.layers.5.mlp.experts.36.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.36.down_proj" [label="Linear @ model.layers.5.mlp.experts.36.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.36.gate_proj" [label="Linear @ model.layers.5.mlp.experts.36.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.36.up_proj" [label="Linear @ model.layers.5.mlp.experts.36.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.37\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.37.act_fn" [label="SiLU @ model.layers.5.mlp.experts.37.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.37.down_proj" [label="Linear @ model.layers.5.mlp.experts.37.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.37.gate_proj" [label="Linear @ model.layers.5.mlp.experts.37.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.37.up_proj" [label="Linear @ model.layers.5.mlp.experts.37.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.38\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.38.act_fn" [label="SiLU @ model.layers.5.mlp.experts.38.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.38.down_proj" [label="Linear @ model.layers.5.mlp.experts.38.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.38.gate_proj" [label="Linear @ model.layers.5.mlp.experts.38.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.38.up_proj" [label="Linear @ model.layers.5.mlp.experts.38.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.39\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.39.act_fn" [label="SiLU @ model.layers.5.mlp.experts.39.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.39.down_proj" [label="Linear @ model.layers.5.mlp.experts.39.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.39.gate_proj" [label="Linear @ model.layers.5.mlp.experts.39.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.39.up_proj" [label="Linear @ model.layers.5.mlp.experts.39.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.4\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.4.act_fn" [label="SiLU @ model.layers.5.mlp.experts.4.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.4.down_proj" [label="Linear @ model.layers.5.mlp.experts.4.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.4.gate_proj" [label="Linear @ model.layers.5.mlp.experts.4.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.4.up_proj" [label="Linear @ model.layers.5.mlp.experts.4.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.40\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.40.act_fn" [label="SiLU @ model.layers.5.mlp.experts.40.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.40.down_proj" [label="Linear @ model.layers.5.mlp.experts.40.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.40.gate_proj" [label="Linear @ model.layers.5.mlp.experts.40.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.40.up_proj" [label="Linear @ model.layers.5.mlp.experts.40.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.41\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.41.act_fn" [label="SiLU @ model.layers.5.mlp.experts.41.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.41.down_proj" [label="Linear @ model.layers.5.mlp.experts.41.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.41.gate_proj" [label="Linear @ model.layers.5.mlp.experts.41.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.41.up_proj" [label="Linear @ model.layers.5.mlp.experts.41.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.43\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.43.act_fn" [label="SiLU @ model.layers.5.mlp.experts.43.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.43.down_proj" [label="Linear @ model.layers.5.mlp.experts.43.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.43.gate_proj" [label="Linear @ model.layers.5.mlp.experts.43.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.43.up_proj" [label="Linear @ model.layers.5.mlp.experts.43.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.44\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.44.act_fn" [label="SiLU @ model.layers.5.mlp.experts.44.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.44.down_proj" [label="Linear @ model.layers.5.mlp.experts.44.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.44.gate_proj" [label="Linear @ model.layers.5.mlp.experts.44.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.44.up_proj" [label="Linear @ model.layers.5.mlp.experts.44.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.45\nin [135, 1280] torch.bfloat16 | out [135, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.45.act_fn" [label="SiLU @ model.layers.5.mlp.experts.45.act_fn\nin [135, 896] torch.bfloat16 | out [135, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.45.down_proj" [label="Linear @ model.layers.5.mlp.experts.45.down_proj\nin [135, 896] torch.bfloat16 | out [135, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.45.gate_proj" [label="Linear @ model.layers.5.mlp.experts.45.gate_proj\nin [135, 1280] torch.bfloat16 | out [135, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.45.up_proj" [label="Linear @ model.layers.5.mlp.experts.45.up_proj\nin [135, 1280] torch.bfloat16 | out [135, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.46\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.46.act_fn" [label="SiLU @ model.layers.5.mlp.experts.46.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.46.down_proj" [label="Linear @ model.layers.5.mlp.experts.46.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.46.gate_proj" [label="Linear @ model.layers.5.mlp.experts.46.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.46.up_proj" [label="Linear @ model.layers.5.mlp.experts.46.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.47\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.47.act_fn" [label="SiLU @ model.layers.5.mlp.experts.47.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.47.down_proj" [label="Linear @ model.layers.5.mlp.experts.47.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.47.gate_proj" [label="Linear @ model.layers.5.mlp.experts.47.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.47.up_proj" [label="Linear @ model.layers.5.mlp.experts.47.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.48\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.48.act_fn" [label="SiLU @ model.layers.5.mlp.experts.48.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.48.down_proj" [label="Linear @ model.layers.5.mlp.experts.48.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.48.gate_proj" [label="Linear @ model.layers.5.mlp.experts.48.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.48.up_proj" [label="Linear @ model.layers.5.mlp.experts.48.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.49\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.49.act_fn" [label="SiLU @ model.layers.5.mlp.experts.49.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.49.down_proj" [label="Linear @ model.layers.5.mlp.experts.49.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.49.gate_proj" [label="Linear @ model.layers.5.mlp.experts.49.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.49.up_proj" [label="Linear @ model.layers.5.mlp.experts.49.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.5\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.5.act_fn" [label="SiLU @ model.layers.5.mlp.experts.5.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.5.down_proj" [label="Linear @ model.layers.5.mlp.experts.5.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.5.gate_proj" [label="Linear @ model.layers.5.mlp.experts.5.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.5.up_proj" [label="Linear @ model.layers.5.mlp.experts.5.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.50\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.50.act_fn" [label="SiLU @ model.layers.5.mlp.experts.50.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.50.down_proj" [label="Linear @ model.layers.5.mlp.experts.50.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.50.gate_proj" [label="Linear @ model.layers.5.mlp.experts.50.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.50.up_proj" [label="Linear @ model.layers.5.mlp.experts.50.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.51\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.51.act_fn" [label="SiLU @ model.layers.5.mlp.experts.51.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.51.down_proj" [label="Linear @ model.layers.5.mlp.experts.51.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.51.gate_proj" [label="Linear @ model.layers.5.mlp.experts.51.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.51.up_proj" [label="Linear @ model.layers.5.mlp.experts.51.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.53\nin [152, 1280] torch.bfloat16 | out [152, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.53.act_fn" [label="SiLU @ model.layers.5.mlp.experts.53.act_fn\nin [152, 896] torch.bfloat16 | out [152, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.53.down_proj" [label="Linear @ model.layers.5.mlp.experts.53.down_proj\nin [152, 896] torch.bfloat16 | out [152, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.53.gate_proj" [label="Linear @ model.layers.5.mlp.experts.53.gate_proj\nin [152, 1280] torch.bfloat16 | out [152, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.53.up_proj" [label="Linear @ model.layers.5.mlp.experts.53.up_proj\nin [152, 1280] torch.bfloat16 | out [152, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.54\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.54.act_fn" [label="SiLU @ model.layers.5.mlp.experts.54.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.54.down_proj" [label="Linear @ model.layers.5.mlp.experts.54.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.54.gate_proj" [label="Linear @ model.layers.5.mlp.experts.54.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.54.up_proj" [label="Linear @ model.layers.5.mlp.experts.54.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.55\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.55.act_fn" [label="SiLU @ model.layers.5.mlp.experts.55.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.55.down_proj" [label="Linear @ model.layers.5.mlp.experts.55.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.55.gate_proj" [label="Linear @ model.layers.5.mlp.experts.55.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.55.up_proj" [label="Linear @ model.layers.5.mlp.experts.55.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.57\nin [54, 1280] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.57.act_fn" [label="SiLU @ model.layers.5.mlp.experts.57.act_fn\nin [54, 896] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.57.down_proj" [label="Linear @ model.layers.5.mlp.experts.57.down_proj\nin [54, 896] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.57.gate_proj" [label="Linear @ model.layers.5.mlp.experts.57.gate_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.57.up_proj" [label="Linear @ model.layers.5.mlp.experts.57.up_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.58\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.58.act_fn" [label="SiLU @ model.layers.5.mlp.experts.58.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.58.down_proj" [label="Linear @ model.layers.5.mlp.experts.58.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.58.gate_proj" [label="Linear @ model.layers.5.mlp.experts.58.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.58.up_proj" [label="Linear @ model.layers.5.mlp.experts.58.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.59\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.59.act_fn" [label="SiLU @ model.layers.5.mlp.experts.59.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.59.down_proj" [label="Linear @ model.layers.5.mlp.experts.59.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.59.gate_proj" [label="Linear @ model.layers.5.mlp.experts.59.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.59.up_proj" [label="Linear @ model.layers.5.mlp.experts.59.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.6\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.6.act_fn" [label="SiLU @ model.layers.5.mlp.experts.6.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.6.down_proj" [label="Linear @ model.layers.5.mlp.experts.6.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.6.gate_proj" [label="Linear @ model.layers.5.mlp.experts.6.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.6.up_proj" [label="Linear @ model.layers.5.mlp.experts.6.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.60\nin [71, 1280] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.60.act_fn" [label="SiLU @ model.layers.5.mlp.experts.60.act_fn\nin [71, 896] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.60.down_proj" [label="Linear @ model.layers.5.mlp.experts.60.down_proj\nin [71, 896] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.60.gate_proj" [label="Linear @ model.layers.5.mlp.experts.60.gate_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.60.up_proj" [label="Linear @ model.layers.5.mlp.experts.60.up_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.61\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.61.act_fn" [label="SiLU @ model.layers.5.mlp.experts.61.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.61.down_proj" [label="Linear @ model.layers.5.mlp.experts.61.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.61.gate_proj" [label="Linear @ model.layers.5.mlp.experts.61.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.61.up_proj" [label="Linear @ model.layers.5.mlp.experts.61.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.62\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.62.act_fn" [label="SiLU @ model.layers.5.mlp.experts.62.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.62.down_proj" [label="Linear @ model.layers.5.mlp.experts.62.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.62.gate_proj" [label="Linear @ model.layers.5.mlp.experts.62.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.62.up_proj" [label="Linear @ model.layers.5.mlp.experts.62.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.63\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.63.act_fn" [label="SiLU @ model.layers.5.mlp.experts.63.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.63.down_proj" [label="Linear @ model.layers.5.mlp.experts.63.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.63.gate_proj" [label="Linear @ model.layers.5.mlp.experts.63.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.63.up_proj" [label="Linear @ model.layers.5.mlp.experts.63.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.8\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.8.act_fn" [label="SiLU @ model.layers.5.mlp.experts.8.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.8.down_proj" [label="Linear @ model.layers.5.mlp.experts.8.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.8.gate_proj" [label="Linear @ model.layers.5.mlp.experts.8.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.8.up_proj" [label="Linear @ model.layers.5.mlp.experts.8.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.5.mlp.experts.9\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.9.act_fn" [label="SiLU @ model.layers.5.mlp.experts.9.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.9.down_proj" [label="Linear @ model.layers.5.mlp.experts.9.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.5.mlp.experts.9.gate_proj" [label="Linear @ model.layers.5.mlp.experts.9.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.experts.9.up_proj" [label="Linear @ model.layers.5.mlp.experts.9.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.5.mlp.gate" [label="MoEGate @ model.layers.5.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.5.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.5.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.5.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.5.mlp.shared_experts.down_proj" [label="Linear @ model.layers.5.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.5.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.5.mlp.shared_experts.up_proj" [label="Linear @ model.layers.5.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.5.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.5.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.self_attn" [label="LlamaFlashAttention2 @ model.layers.5.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.self_attn.k_proj" [label="Linear @ model.layers.5.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.self_attn.o_proj" [label="Linear @ model.layers.5.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.self_attn.q_proj" [label="Linear @ model.layers.5.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.5.self_attn.v_proj" [label="Linear @ model.layers.5.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6" [label="DeepseekV2DecoderLayer @ model.layers.6\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.6.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.mlp" [label="DeepseekV2MoE @ model.layers.6.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.0\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.0.act_fn" [label="SiLU @ model.layers.6.mlp.experts.0.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.0.down_proj" [label="Linear @ model.layers.6.mlp.experts.0.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.0.gate_proj" [label="Linear @ model.layers.6.mlp.experts.0.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.0.up_proj" [label="Linear @ model.layers.6.mlp.experts.0.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.1\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.1.act_fn" [label="SiLU @ model.layers.6.mlp.experts.1.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.1.down_proj" [label="Linear @ model.layers.6.mlp.experts.1.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.1.gate_proj" [label="Linear @ model.layers.6.mlp.experts.1.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.1.up_proj" [label="Linear @ model.layers.6.mlp.experts.1.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.10\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.10.act_fn" [label="SiLU @ model.layers.6.mlp.experts.10.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.10.down_proj" [label="Linear @ model.layers.6.mlp.experts.10.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.10.gate_proj" [label="Linear @ model.layers.6.mlp.experts.10.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.10.up_proj" [label="Linear @ model.layers.6.mlp.experts.10.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.11\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.11.act_fn" [label="SiLU @ model.layers.6.mlp.experts.11.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.11.down_proj" [label="Linear @ model.layers.6.mlp.experts.11.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.11.gate_proj" [label="Linear @ model.layers.6.mlp.experts.11.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.11.up_proj" [label="Linear @ model.layers.6.mlp.experts.11.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.12\nin [87, 1280] torch.bfloat16 | out [87, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.12.act_fn" [label="SiLU @ model.layers.6.mlp.experts.12.act_fn\nin [87, 896] torch.bfloat16 | out [87, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.12.down_proj" [label="Linear @ model.layers.6.mlp.experts.12.down_proj\nin [87, 896] torch.bfloat16 | out [87, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.12.gate_proj" [label="Linear @ model.layers.6.mlp.experts.12.gate_proj\nin [87, 1280] torch.bfloat16 | out [87, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.12.up_proj" [label="Linear @ model.layers.6.mlp.experts.12.up_proj\nin [87, 1280] torch.bfloat16 | out [87, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.14\nin [32, 1280] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.14.act_fn" [label="SiLU @ model.layers.6.mlp.experts.14.act_fn\nin [32, 896] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.14.down_proj" [label="Linear @ model.layers.6.mlp.experts.14.down_proj\nin [32, 896] torch.bfloat16 | out [32, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.14.gate_proj" [label="Linear @ model.layers.6.mlp.experts.14.gate_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.14.up_proj" [label="Linear @ model.layers.6.mlp.experts.14.up_proj\nin [32, 1280] torch.bfloat16 | out [32, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.15\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.15.act_fn" [label="SiLU @ model.layers.6.mlp.experts.15.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.15.down_proj" [label="Linear @ model.layers.6.mlp.experts.15.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.15.gate_proj" [label="Linear @ model.layers.6.mlp.experts.15.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.15.up_proj" [label="Linear @ model.layers.6.mlp.experts.15.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.16\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.16.act_fn" [label="SiLU @ model.layers.6.mlp.experts.16.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.16.down_proj" [label="Linear @ model.layers.6.mlp.experts.16.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.16.gate_proj" [label="Linear @ model.layers.6.mlp.experts.16.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.16.up_proj" [label="Linear @ model.layers.6.mlp.experts.16.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.17\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.17.act_fn" [label="SiLU @ model.layers.6.mlp.experts.17.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.17.down_proj" [label="Linear @ model.layers.6.mlp.experts.17.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.17.gate_proj" [label="Linear @ model.layers.6.mlp.experts.17.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.17.up_proj" [label="Linear @ model.layers.6.mlp.experts.17.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.18\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.18.act_fn" [label="SiLU @ model.layers.6.mlp.experts.18.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.18.down_proj" [label="Linear @ model.layers.6.mlp.experts.18.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.18.gate_proj" [label="Linear @ model.layers.6.mlp.experts.18.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.18.up_proj" [label="Linear @ model.layers.6.mlp.experts.18.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.19\nin [33, 1280] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.19.act_fn" [label="SiLU @ model.layers.6.mlp.experts.19.act_fn\nin [33, 896] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.19.down_proj" [label="Linear @ model.layers.6.mlp.experts.19.down_proj\nin [33, 896] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.19.gate_proj" [label="Linear @ model.layers.6.mlp.experts.19.gate_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.19.up_proj" [label="Linear @ model.layers.6.mlp.experts.19.up_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.2\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.2.act_fn" [label="SiLU @ model.layers.6.mlp.experts.2.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.2.down_proj" [label="Linear @ model.layers.6.mlp.experts.2.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.2.gate_proj" [label="Linear @ model.layers.6.mlp.experts.2.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.2.up_proj" [label="Linear @ model.layers.6.mlp.experts.2.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.20\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.20.act_fn" [label="SiLU @ model.layers.6.mlp.experts.20.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.20.down_proj" [label="Linear @ model.layers.6.mlp.experts.20.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.20.gate_proj" [label="Linear @ model.layers.6.mlp.experts.20.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.20.up_proj" [label="Linear @ model.layers.6.mlp.experts.20.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.21\nin [109, 1280] torch.bfloat16 | out [109, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.21.act_fn" [label="SiLU @ model.layers.6.mlp.experts.21.act_fn\nin [109, 896] torch.bfloat16 | out [109, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.21.down_proj" [label="Linear @ model.layers.6.mlp.experts.21.down_proj\nin [109, 896] torch.bfloat16 | out [109, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.21.gate_proj" [label="Linear @ model.layers.6.mlp.experts.21.gate_proj\nin [109, 1280] torch.bfloat16 | out [109, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.21.up_proj" [label="Linear @ model.layers.6.mlp.experts.21.up_proj\nin [109, 1280] torch.bfloat16 | out [109, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.22\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.22.act_fn" [label="SiLU @ model.layers.6.mlp.experts.22.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.22.down_proj" [label="Linear @ model.layers.6.mlp.experts.22.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.22.gate_proj" [label="Linear @ model.layers.6.mlp.experts.22.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.22.up_proj" [label="Linear @ model.layers.6.mlp.experts.22.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.23\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.23.act_fn" [label="SiLU @ model.layers.6.mlp.experts.23.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.23.down_proj" [label="Linear @ model.layers.6.mlp.experts.23.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.23.gate_proj" [label="Linear @ model.layers.6.mlp.experts.23.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.23.up_proj" [label="Linear @ model.layers.6.mlp.experts.23.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.24\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.24.act_fn" [label="SiLU @ model.layers.6.mlp.experts.24.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.24.down_proj" [label="Linear @ model.layers.6.mlp.experts.24.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.24.gate_proj" [label="Linear @ model.layers.6.mlp.experts.24.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.24.up_proj" [label="Linear @ model.layers.6.mlp.experts.24.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.25\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.25.act_fn" [label="SiLU @ model.layers.6.mlp.experts.25.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.25.down_proj" [label="Linear @ model.layers.6.mlp.experts.25.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.25.gate_proj" [label="Linear @ model.layers.6.mlp.experts.25.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.25.up_proj" [label="Linear @ model.layers.6.mlp.experts.25.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.26\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.26.act_fn" [label="SiLU @ model.layers.6.mlp.experts.26.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.26.down_proj" [label="Linear @ model.layers.6.mlp.experts.26.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.26.gate_proj" [label="Linear @ model.layers.6.mlp.experts.26.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.26.up_proj" [label="Linear @ model.layers.6.mlp.experts.26.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.27\nin [72, 1280] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.27.act_fn" [label="SiLU @ model.layers.6.mlp.experts.27.act_fn\nin [72, 896] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.27.down_proj" [label="Linear @ model.layers.6.mlp.experts.27.down_proj\nin [72, 896] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.27.gate_proj" [label="Linear @ model.layers.6.mlp.experts.27.gate_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.27.up_proj" [label="Linear @ model.layers.6.mlp.experts.27.up_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.28\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.28.act_fn" [label="SiLU @ model.layers.6.mlp.experts.28.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.28.down_proj" [label="Linear @ model.layers.6.mlp.experts.28.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.28.gate_proj" [label="Linear @ model.layers.6.mlp.experts.28.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.28.up_proj" [label="Linear @ model.layers.6.mlp.experts.28.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.29\nin [49, 1280] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.29.act_fn" [label="SiLU @ model.layers.6.mlp.experts.29.act_fn\nin [49, 896] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.29.down_proj" [label="Linear @ model.layers.6.mlp.experts.29.down_proj\nin [49, 896] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.29.gate_proj" [label="Linear @ model.layers.6.mlp.experts.29.gate_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.29.up_proj" [label="Linear @ model.layers.6.mlp.experts.29.up_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.3\nin [72, 1280] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.3.act_fn" [label="SiLU @ model.layers.6.mlp.experts.3.act_fn\nin [72, 896] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.3.down_proj" [label="Linear @ model.layers.6.mlp.experts.3.down_proj\nin [72, 896] torch.bfloat16 | out [72, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.3.gate_proj" [label="Linear @ model.layers.6.mlp.experts.3.gate_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.3.up_proj" [label="Linear @ model.layers.6.mlp.experts.3.up_proj\nin [72, 1280] torch.bfloat16 | out [72, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.30\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.30.act_fn" [label="SiLU @ model.layers.6.mlp.experts.30.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.30.down_proj" [label="Linear @ model.layers.6.mlp.experts.30.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.30.gate_proj" [label="Linear @ model.layers.6.mlp.experts.30.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.30.up_proj" [label="Linear @ model.layers.6.mlp.experts.30.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.31\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.31.act_fn" [label="SiLU @ model.layers.6.mlp.experts.31.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.31.down_proj" [label="Linear @ model.layers.6.mlp.experts.31.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.31.gate_proj" [label="Linear @ model.layers.6.mlp.experts.31.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.31.up_proj" [label="Linear @ model.layers.6.mlp.experts.31.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.32\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.32.act_fn" [label="SiLU @ model.layers.6.mlp.experts.32.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.32.down_proj" [label="Linear @ model.layers.6.mlp.experts.32.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.32.gate_proj" [label="Linear @ model.layers.6.mlp.experts.32.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.32.up_proj" [label="Linear @ model.layers.6.mlp.experts.32.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.33\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.33.act_fn" [label="SiLU @ model.layers.6.mlp.experts.33.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.33.down_proj" [label="Linear @ model.layers.6.mlp.experts.33.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.33.gate_proj" [label="Linear @ model.layers.6.mlp.experts.33.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.33.up_proj" [label="Linear @ model.layers.6.mlp.experts.33.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.34\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.34.act_fn" [label="SiLU @ model.layers.6.mlp.experts.34.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.34.down_proj" [label="Linear @ model.layers.6.mlp.experts.34.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.34.gate_proj" [label="Linear @ model.layers.6.mlp.experts.34.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.34.up_proj" [label="Linear @ model.layers.6.mlp.experts.34.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.35\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.35.act_fn" [label="SiLU @ model.layers.6.mlp.experts.35.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.35.down_proj" [label="Linear @ model.layers.6.mlp.experts.35.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.35.gate_proj" [label="Linear @ model.layers.6.mlp.experts.35.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.35.up_proj" [label="Linear @ model.layers.6.mlp.experts.35.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.36\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.36.act_fn" [label="SiLU @ model.layers.6.mlp.experts.36.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.36.down_proj" [label="Linear @ model.layers.6.mlp.experts.36.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.36.gate_proj" [label="Linear @ model.layers.6.mlp.experts.36.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.36.up_proj" [label="Linear @ model.layers.6.mlp.experts.36.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.37\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.37.act_fn" [label="SiLU @ model.layers.6.mlp.experts.37.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.37.down_proj" [label="Linear @ model.layers.6.mlp.experts.37.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.37.gate_proj" [label="Linear @ model.layers.6.mlp.experts.37.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.37.up_proj" [label="Linear @ model.layers.6.mlp.experts.37.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.38\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.38.act_fn" [label="SiLU @ model.layers.6.mlp.experts.38.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.38.down_proj" [label="Linear @ model.layers.6.mlp.experts.38.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.38.gate_proj" [label="Linear @ model.layers.6.mlp.experts.38.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.38.up_proj" [label="Linear @ model.layers.6.mlp.experts.38.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.39\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.39.act_fn" [label="SiLU @ model.layers.6.mlp.experts.39.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.39.down_proj" [label="Linear @ model.layers.6.mlp.experts.39.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.39.gate_proj" [label="Linear @ model.layers.6.mlp.experts.39.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.39.up_proj" [label="Linear @ model.layers.6.mlp.experts.39.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.4\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.4.act_fn" [label="SiLU @ model.layers.6.mlp.experts.4.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.4.down_proj" [label="Linear @ model.layers.6.mlp.experts.4.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.4.gate_proj" [label="Linear @ model.layers.6.mlp.experts.4.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.4.up_proj" [label="Linear @ model.layers.6.mlp.experts.4.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.40\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.40.act_fn" [label="SiLU @ model.layers.6.mlp.experts.40.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.40.down_proj" [label="Linear @ model.layers.6.mlp.experts.40.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.40.gate_proj" [label="Linear @ model.layers.6.mlp.experts.40.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.40.up_proj" [label="Linear @ model.layers.6.mlp.experts.40.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.41\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.41.act_fn" [label="SiLU @ model.layers.6.mlp.experts.41.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.41.down_proj" [label="Linear @ model.layers.6.mlp.experts.41.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.41.gate_proj" [label="Linear @ model.layers.6.mlp.experts.41.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.41.up_proj" [label="Linear @ model.layers.6.mlp.experts.41.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.42\nin [36, 1280] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.42.act_fn" [label="SiLU @ model.layers.6.mlp.experts.42.act_fn\nin [36, 896] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.42.down_proj" [label="Linear @ model.layers.6.mlp.experts.42.down_proj\nin [36, 896] torch.bfloat16 | out [36, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.42.gate_proj" [label="Linear @ model.layers.6.mlp.experts.42.gate_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.42.up_proj" [label="Linear @ model.layers.6.mlp.experts.42.up_proj\nin [36, 1280] torch.bfloat16 | out [36, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.43\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.43.act_fn" [label="SiLU @ model.layers.6.mlp.experts.43.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.43.down_proj" [label="Linear @ model.layers.6.mlp.experts.43.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.43.gate_proj" [label="Linear @ model.layers.6.mlp.experts.43.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.43.up_proj" [label="Linear @ model.layers.6.mlp.experts.43.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.44\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.44.act_fn" [label="SiLU @ model.layers.6.mlp.experts.44.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.44.down_proj" [label="Linear @ model.layers.6.mlp.experts.44.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.44.gate_proj" [label="Linear @ model.layers.6.mlp.experts.44.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.44.up_proj" [label="Linear @ model.layers.6.mlp.experts.44.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.45\nin [47, 1280] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.45.act_fn" [label="SiLU @ model.layers.6.mlp.experts.45.act_fn\nin [47, 896] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.45.down_proj" [label="Linear @ model.layers.6.mlp.experts.45.down_proj\nin [47, 896] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.45.gate_proj" [label="Linear @ model.layers.6.mlp.experts.45.gate_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.45.up_proj" [label="Linear @ model.layers.6.mlp.experts.45.up_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.46\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.46.act_fn" [label="SiLU @ model.layers.6.mlp.experts.46.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.46.down_proj" [label="Linear @ model.layers.6.mlp.experts.46.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.46.gate_proj" [label="Linear @ model.layers.6.mlp.experts.46.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.46.up_proj" [label="Linear @ model.layers.6.mlp.experts.46.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.47\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.47.act_fn" [label="SiLU @ model.layers.6.mlp.experts.47.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.47.down_proj" [label="Linear @ model.layers.6.mlp.experts.47.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.47.gate_proj" [label="Linear @ model.layers.6.mlp.experts.47.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.47.up_proj" [label="Linear @ model.layers.6.mlp.experts.47.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.48\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.48.act_fn" [label="SiLU @ model.layers.6.mlp.experts.48.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.48.down_proj" [label="Linear @ model.layers.6.mlp.experts.48.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.48.gate_proj" [label="Linear @ model.layers.6.mlp.experts.48.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.48.up_proj" [label="Linear @ model.layers.6.mlp.experts.48.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.49\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.49.act_fn" [label="SiLU @ model.layers.6.mlp.experts.49.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.49.down_proj" [label="Linear @ model.layers.6.mlp.experts.49.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.49.gate_proj" [label="Linear @ model.layers.6.mlp.experts.49.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.49.up_proj" [label="Linear @ model.layers.6.mlp.experts.49.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.5\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.5.act_fn" [label="SiLU @ model.layers.6.mlp.experts.5.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.5.down_proj" [label="Linear @ model.layers.6.mlp.experts.5.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.5.gate_proj" [label="Linear @ model.layers.6.mlp.experts.5.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.5.up_proj" [label="Linear @ model.layers.6.mlp.experts.5.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.50\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.50.act_fn" [label="SiLU @ model.layers.6.mlp.experts.50.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.50.down_proj" [label="Linear @ model.layers.6.mlp.experts.50.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.50.gate_proj" [label="Linear @ model.layers.6.mlp.experts.50.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.50.up_proj" [label="Linear @ model.layers.6.mlp.experts.50.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.51\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.51.act_fn" [label="SiLU @ model.layers.6.mlp.experts.51.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.51.down_proj" [label="Linear @ model.layers.6.mlp.experts.51.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.51.gate_proj" [label="Linear @ model.layers.6.mlp.experts.51.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.51.up_proj" [label="Linear @ model.layers.6.mlp.experts.51.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.52\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.52.act_fn" [label="SiLU @ model.layers.6.mlp.experts.52.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.52.down_proj" [label="Linear @ model.layers.6.mlp.experts.52.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.52.gate_proj" [label="Linear @ model.layers.6.mlp.experts.52.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.52.up_proj" [label="Linear @ model.layers.6.mlp.experts.52.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.53\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.53.act_fn" [label="SiLU @ model.layers.6.mlp.experts.53.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.53.down_proj" [label="Linear @ model.layers.6.mlp.experts.53.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.53.gate_proj" [label="Linear @ model.layers.6.mlp.experts.53.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.53.up_proj" [label="Linear @ model.layers.6.mlp.experts.53.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.54\nin [78, 1280] torch.bfloat16 | out [78, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.54.act_fn" [label="SiLU @ model.layers.6.mlp.experts.54.act_fn\nin [78, 896] torch.bfloat16 | out [78, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.54.down_proj" [label="Linear @ model.layers.6.mlp.experts.54.down_proj\nin [78, 896] torch.bfloat16 | out [78, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.54.gate_proj" [label="Linear @ model.layers.6.mlp.experts.54.gate_proj\nin [78, 1280] torch.bfloat16 | out [78, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.54.up_proj" [label="Linear @ model.layers.6.mlp.experts.54.up_proj\nin [78, 1280] torch.bfloat16 | out [78, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.55\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.55.act_fn" [label="SiLU @ model.layers.6.mlp.experts.55.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.55.down_proj" [label="Linear @ model.layers.6.mlp.experts.55.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.55.gate_proj" [label="Linear @ model.layers.6.mlp.experts.55.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.55.up_proj" [label="Linear @ model.layers.6.mlp.experts.55.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.56\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.56.act_fn" [label="SiLU @ model.layers.6.mlp.experts.56.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.56.down_proj" [label="Linear @ model.layers.6.mlp.experts.56.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.56.gate_proj" [label="Linear @ model.layers.6.mlp.experts.56.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.56.up_proj" [label="Linear @ model.layers.6.mlp.experts.56.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.57\nin [168, 1280] torch.bfloat16 | out [168, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.57.act_fn" [label="SiLU @ model.layers.6.mlp.experts.57.act_fn\nin [168, 896] torch.bfloat16 | out [168, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.57.down_proj" [label="Linear @ model.layers.6.mlp.experts.57.down_proj\nin [168, 896] torch.bfloat16 | out [168, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.57.gate_proj" [label="Linear @ model.layers.6.mlp.experts.57.gate_proj\nin [168, 1280] torch.bfloat16 | out [168, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.57.up_proj" [label="Linear @ model.layers.6.mlp.experts.57.up_proj\nin [168, 1280] torch.bfloat16 | out [168, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.58\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.58.act_fn" [label="SiLU @ model.layers.6.mlp.experts.58.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.58.down_proj" [label="Linear @ model.layers.6.mlp.experts.58.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.58.gate_proj" [label="Linear @ model.layers.6.mlp.experts.58.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.58.up_proj" [label="Linear @ model.layers.6.mlp.experts.58.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.59\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.59.act_fn" [label="SiLU @ model.layers.6.mlp.experts.59.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.59.down_proj" [label="Linear @ model.layers.6.mlp.experts.59.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.59.gate_proj" [label="Linear @ model.layers.6.mlp.experts.59.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.59.up_proj" [label="Linear @ model.layers.6.mlp.experts.59.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.6\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.6.act_fn" [label="SiLU @ model.layers.6.mlp.experts.6.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.6.down_proj" [label="Linear @ model.layers.6.mlp.experts.6.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.6.gate_proj" [label="Linear @ model.layers.6.mlp.experts.6.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.6.up_proj" [label="Linear @ model.layers.6.mlp.experts.6.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.60\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.60.act_fn" [label="SiLU @ model.layers.6.mlp.experts.60.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.60.down_proj" [label="Linear @ model.layers.6.mlp.experts.60.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.60.gate_proj" [label="Linear @ model.layers.6.mlp.experts.60.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.60.up_proj" [label="Linear @ model.layers.6.mlp.experts.60.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.61\nin [122, 1280] torch.bfloat16 | out [122, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.61.act_fn" [label="SiLU @ model.layers.6.mlp.experts.61.act_fn\nin [122, 896] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.61.down_proj" [label="Linear @ model.layers.6.mlp.experts.61.down_proj\nin [122, 896] torch.bfloat16 | out [122, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.61.gate_proj" [label="Linear @ model.layers.6.mlp.experts.61.gate_proj\nin [122, 1280] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.61.up_proj" [label="Linear @ model.layers.6.mlp.experts.61.up_proj\nin [122, 1280] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.62\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.62.act_fn" [label="SiLU @ model.layers.6.mlp.experts.62.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.62.down_proj" [label="Linear @ model.layers.6.mlp.experts.62.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.62.gate_proj" [label="Linear @ model.layers.6.mlp.experts.62.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.62.up_proj" [label="Linear @ model.layers.6.mlp.experts.62.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.63\nin [79, 1280] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.63.act_fn" [label="SiLU @ model.layers.6.mlp.experts.63.act_fn\nin [79, 896] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.63.down_proj" [label="Linear @ model.layers.6.mlp.experts.63.down_proj\nin [79, 896] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.63.gate_proj" [label="Linear @ model.layers.6.mlp.experts.63.gate_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.63.up_proj" [label="Linear @ model.layers.6.mlp.experts.63.up_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.7\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.7.act_fn" [label="SiLU @ model.layers.6.mlp.experts.7.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.7.down_proj" [label="Linear @ model.layers.6.mlp.experts.7.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.7.gate_proj" [label="Linear @ model.layers.6.mlp.experts.7.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.7.up_proj" [label="Linear @ model.layers.6.mlp.experts.7.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.8\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.8.act_fn" [label="SiLU @ model.layers.6.mlp.experts.8.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.8.down_proj" [label="Linear @ model.layers.6.mlp.experts.8.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.8.gate_proj" [label="Linear @ model.layers.6.mlp.experts.8.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.8.up_proj" [label="Linear @ model.layers.6.mlp.experts.8.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.6.mlp.experts.9\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.9.act_fn" [label="SiLU @ model.layers.6.mlp.experts.9.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.9.down_proj" [label="Linear @ model.layers.6.mlp.experts.9.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.6.mlp.experts.9.gate_proj" [label="Linear @ model.layers.6.mlp.experts.9.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.experts.9.up_proj" [label="Linear @ model.layers.6.mlp.experts.9.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.6.mlp.gate" [label="MoEGate @ model.layers.6.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.6.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.6.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.6.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.6.mlp.shared_experts.down_proj" [label="Linear @ model.layers.6.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.6.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.6.mlp.shared_experts.up_proj" [label="Linear @ model.layers.6.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.6.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.6.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.self_attn" [label="LlamaFlashAttention2 @ model.layers.6.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.self_attn.k_proj" [label="Linear @ model.layers.6.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.self_attn.o_proj" [label="Linear @ model.layers.6.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.self_attn.q_proj" [label="Linear @ model.layers.6.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.6.self_attn.v_proj" [label="Linear @ model.layers.6.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7" [label="DeepseekV2DecoderLayer @ model.layers.7\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.7.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.mlp" [label="DeepseekV2MoE @ model.layers.7.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.0\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.0.act_fn" [label="SiLU @ model.layers.7.mlp.experts.0.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.0.down_proj" [label="Linear @ model.layers.7.mlp.experts.0.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.0.gate_proj" [label="Linear @ model.layers.7.mlp.experts.0.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.0.up_proj" [label="Linear @ model.layers.7.mlp.experts.0.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.1\nin [52, 1280] torch.bfloat16 | out [52, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.1.act_fn" [label="SiLU @ model.layers.7.mlp.experts.1.act_fn\nin [52, 896] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.1.down_proj" [label="Linear @ model.layers.7.mlp.experts.1.down_proj\nin [52, 896] torch.bfloat16 | out [52, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.1.gate_proj" [label="Linear @ model.layers.7.mlp.experts.1.gate_proj\nin [52, 1280] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.1.up_proj" [label="Linear @ model.layers.7.mlp.experts.1.up_proj\nin [52, 1280] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.10\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.10.act_fn" [label="SiLU @ model.layers.7.mlp.experts.10.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.10.down_proj" [label="Linear @ model.layers.7.mlp.experts.10.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.10.gate_proj" [label="Linear @ model.layers.7.mlp.experts.10.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.10.up_proj" [label="Linear @ model.layers.7.mlp.experts.10.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.11\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.11.act_fn" [label="SiLU @ model.layers.7.mlp.experts.11.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.11.down_proj" [label="Linear @ model.layers.7.mlp.experts.11.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.11.gate_proj" [label="Linear @ model.layers.7.mlp.experts.11.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.11.up_proj" [label="Linear @ model.layers.7.mlp.experts.11.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.12\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.12.act_fn" [label="SiLU @ model.layers.7.mlp.experts.12.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.12.down_proj" [label="Linear @ model.layers.7.mlp.experts.12.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.12.gate_proj" [label="Linear @ model.layers.7.mlp.experts.12.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.12.up_proj" [label="Linear @ model.layers.7.mlp.experts.12.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.13\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.13.act_fn" [label="SiLU @ model.layers.7.mlp.experts.13.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.13.down_proj" [label="Linear @ model.layers.7.mlp.experts.13.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.13.gate_proj" [label="Linear @ model.layers.7.mlp.experts.13.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.13.up_proj" [label="Linear @ model.layers.7.mlp.experts.13.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.14\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.14.act_fn" [label="SiLU @ model.layers.7.mlp.experts.14.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.14.down_proj" [label="Linear @ model.layers.7.mlp.experts.14.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.14.gate_proj" [label="Linear @ model.layers.7.mlp.experts.14.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.14.up_proj" [label="Linear @ model.layers.7.mlp.experts.14.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.15\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.15.act_fn" [label="SiLU @ model.layers.7.mlp.experts.15.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.15.down_proj" [label="Linear @ model.layers.7.mlp.experts.15.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.15.gate_proj" [label="Linear @ model.layers.7.mlp.experts.15.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.15.up_proj" [label="Linear @ model.layers.7.mlp.experts.15.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.16\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.16.act_fn" [label="SiLU @ model.layers.7.mlp.experts.16.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.16.down_proj" [label="Linear @ model.layers.7.mlp.experts.16.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.16.gate_proj" [label="Linear @ model.layers.7.mlp.experts.16.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.16.up_proj" [label="Linear @ model.layers.7.mlp.experts.16.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.17\nin [117, 1280] torch.bfloat16 | out [117, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.17.act_fn" [label="SiLU @ model.layers.7.mlp.experts.17.act_fn\nin [117, 896] torch.bfloat16 | out [117, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.17.down_proj" [label="Linear @ model.layers.7.mlp.experts.17.down_proj\nin [117, 896] torch.bfloat16 | out [117, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.17.gate_proj" [label="Linear @ model.layers.7.mlp.experts.17.gate_proj\nin [117, 1280] torch.bfloat16 | out [117, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.17.up_proj" [label="Linear @ model.layers.7.mlp.experts.17.up_proj\nin [117, 1280] torch.bfloat16 | out [117, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.18\nin [5, 1280] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.18.act_fn" [label="SiLU @ model.layers.7.mlp.experts.18.act_fn\nin [5, 896] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.18.down_proj" [label="Linear @ model.layers.7.mlp.experts.18.down_proj\nin [5, 896] torch.bfloat16 | out [5, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.18.gate_proj" [label="Linear @ model.layers.7.mlp.experts.18.gate_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.18.up_proj" [label="Linear @ model.layers.7.mlp.experts.18.up_proj\nin [5, 1280] torch.bfloat16 | out [5, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.19\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.19.act_fn" [label="SiLU @ model.layers.7.mlp.experts.19.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.19.down_proj" [label="Linear @ model.layers.7.mlp.experts.19.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.19.gate_proj" [label="Linear @ model.layers.7.mlp.experts.19.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.19.up_proj" [label="Linear @ model.layers.7.mlp.experts.19.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.2\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.2.act_fn" [label="SiLU @ model.layers.7.mlp.experts.2.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.2.down_proj" [label="Linear @ model.layers.7.mlp.experts.2.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.2.gate_proj" [label="Linear @ model.layers.7.mlp.experts.2.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.2.up_proj" [label="Linear @ model.layers.7.mlp.experts.2.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.20\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.20.act_fn" [label="SiLU @ model.layers.7.mlp.experts.20.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.20.down_proj" [label="Linear @ model.layers.7.mlp.experts.20.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.20.gate_proj" [label="Linear @ model.layers.7.mlp.experts.20.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.20.up_proj" [label="Linear @ model.layers.7.mlp.experts.20.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.21\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.21.act_fn" [label="SiLU @ model.layers.7.mlp.experts.21.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.21.down_proj" [label="Linear @ model.layers.7.mlp.experts.21.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.21.gate_proj" [label="Linear @ model.layers.7.mlp.experts.21.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.21.up_proj" [label="Linear @ model.layers.7.mlp.experts.21.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.22\nin [54, 1280] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.22.act_fn" [label="SiLU @ model.layers.7.mlp.experts.22.act_fn\nin [54, 896] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.22.down_proj" [label="Linear @ model.layers.7.mlp.experts.22.down_proj\nin [54, 896] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.22.gate_proj" [label="Linear @ model.layers.7.mlp.experts.22.gate_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.22.up_proj" [label="Linear @ model.layers.7.mlp.experts.22.up_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.23\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.23.act_fn" [label="SiLU @ model.layers.7.mlp.experts.23.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.23.down_proj" [label="Linear @ model.layers.7.mlp.experts.23.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.23.gate_proj" [label="Linear @ model.layers.7.mlp.experts.23.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.23.up_proj" [label="Linear @ model.layers.7.mlp.experts.23.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.24\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.24.act_fn" [label="SiLU @ model.layers.7.mlp.experts.24.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.24.down_proj" [label="Linear @ model.layers.7.mlp.experts.24.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.24.gate_proj" [label="Linear @ model.layers.7.mlp.experts.24.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.24.up_proj" [label="Linear @ model.layers.7.mlp.experts.24.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.25\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.25.act_fn" [label="SiLU @ model.layers.7.mlp.experts.25.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.25.down_proj" [label="Linear @ model.layers.7.mlp.experts.25.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.25.gate_proj" [label="Linear @ model.layers.7.mlp.experts.25.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.25.up_proj" [label="Linear @ model.layers.7.mlp.experts.25.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.26\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.26.act_fn" [label="SiLU @ model.layers.7.mlp.experts.26.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.26.down_proj" [label="Linear @ model.layers.7.mlp.experts.26.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.26.gate_proj" [label="Linear @ model.layers.7.mlp.experts.26.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.26.up_proj" [label="Linear @ model.layers.7.mlp.experts.26.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.27\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.27.act_fn" [label="SiLU @ model.layers.7.mlp.experts.27.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.27.down_proj" [label="Linear @ model.layers.7.mlp.experts.27.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.27.gate_proj" [label="Linear @ model.layers.7.mlp.experts.27.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.27.up_proj" [label="Linear @ model.layers.7.mlp.experts.27.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.28\nin [73, 1280] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.28.act_fn" [label="SiLU @ model.layers.7.mlp.experts.28.act_fn\nin [73, 896] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.28.down_proj" [label="Linear @ model.layers.7.mlp.experts.28.down_proj\nin [73, 896] torch.bfloat16 | out [73, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.28.gate_proj" [label="Linear @ model.layers.7.mlp.experts.28.gate_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.28.up_proj" [label="Linear @ model.layers.7.mlp.experts.28.up_proj\nin [73, 1280] torch.bfloat16 | out [73, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.29\nin [66, 1280] torch.bfloat16 | out [66, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.29.act_fn" [label="SiLU @ model.layers.7.mlp.experts.29.act_fn\nin [66, 896] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.29.down_proj" [label="Linear @ model.layers.7.mlp.experts.29.down_proj\nin [66, 896] torch.bfloat16 | out [66, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.29.gate_proj" [label="Linear @ model.layers.7.mlp.experts.29.gate_proj\nin [66, 1280] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.29.up_proj" [label="Linear @ model.layers.7.mlp.experts.29.up_proj\nin [66, 1280] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.3\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.3.act_fn" [label="SiLU @ model.layers.7.mlp.experts.3.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.3.down_proj" [label="Linear @ model.layers.7.mlp.experts.3.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.3.gate_proj" [label="Linear @ model.layers.7.mlp.experts.3.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.3.up_proj" [label="Linear @ model.layers.7.mlp.experts.3.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.30\nin [104, 1280] torch.bfloat16 | out [104, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.30.act_fn" [label="SiLU @ model.layers.7.mlp.experts.30.act_fn\nin [104, 896] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.30.down_proj" [label="Linear @ model.layers.7.mlp.experts.30.down_proj\nin [104, 896] torch.bfloat16 | out [104, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.30.gate_proj" [label="Linear @ model.layers.7.mlp.experts.30.gate_proj\nin [104, 1280] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.30.up_proj" [label="Linear @ model.layers.7.mlp.experts.30.up_proj\nin [104, 1280] torch.bfloat16 | out [104, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.31\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.31.act_fn" [label="SiLU @ model.layers.7.mlp.experts.31.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.31.down_proj" [label="Linear @ model.layers.7.mlp.experts.31.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.31.gate_proj" [label="Linear @ model.layers.7.mlp.experts.31.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.31.up_proj" [label="Linear @ model.layers.7.mlp.experts.31.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.32\nin [6, 1280] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.32.act_fn" [label="SiLU @ model.layers.7.mlp.experts.32.act_fn\nin [6, 896] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.32.down_proj" [label="Linear @ model.layers.7.mlp.experts.32.down_proj\nin [6, 896] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.32.gate_proj" [label="Linear @ model.layers.7.mlp.experts.32.gate_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.32.up_proj" [label="Linear @ model.layers.7.mlp.experts.32.up_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.33\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.33.act_fn" [label="SiLU @ model.layers.7.mlp.experts.33.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.33.down_proj" [label="Linear @ model.layers.7.mlp.experts.33.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.33.gate_proj" [label="Linear @ model.layers.7.mlp.experts.33.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.33.up_proj" [label="Linear @ model.layers.7.mlp.experts.33.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.34\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.34.act_fn" [label="SiLU @ model.layers.7.mlp.experts.34.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.34.down_proj" [label="Linear @ model.layers.7.mlp.experts.34.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.34.gate_proj" [label="Linear @ model.layers.7.mlp.experts.34.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.34.up_proj" [label="Linear @ model.layers.7.mlp.experts.34.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.35\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.35.act_fn" [label="SiLU @ model.layers.7.mlp.experts.35.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.35.down_proj" [label="Linear @ model.layers.7.mlp.experts.35.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.35.gate_proj" [label="Linear @ model.layers.7.mlp.experts.35.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.35.up_proj" [label="Linear @ model.layers.7.mlp.experts.35.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.36\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.36.act_fn" [label="SiLU @ model.layers.7.mlp.experts.36.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.36.down_proj" [label="Linear @ model.layers.7.mlp.experts.36.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.36.gate_proj" [label="Linear @ model.layers.7.mlp.experts.36.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.36.up_proj" [label="Linear @ model.layers.7.mlp.experts.36.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.37\nin [58, 1280] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.37.act_fn" [label="SiLU @ model.layers.7.mlp.experts.37.act_fn\nin [58, 896] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.37.down_proj" [label="Linear @ model.layers.7.mlp.experts.37.down_proj\nin [58, 896] torch.bfloat16 | out [58, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.37.gate_proj" [label="Linear @ model.layers.7.mlp.experts.37.gate_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.37.up_proj" [label="Linear @ model.layers.7.mlp.experts.37.up_proj\nin [58, 1280] torch.bfloat16 | out [58, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.38\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.38.act_fn" [label="SiLU @ model.layers.7.mlp.experts.38.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.38.down_proj" [label="Linear @ model.layers.7.mlp.experts.38.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.38.gate_proj" [label="Linear @ model.layers.7.mlp.experts.38.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.38.up_proj" [label="Linear @ model.layers.7.mlp.experts.38.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.39\nin [155, 1280] torch.bfloat16 | out [155, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.39.act_fn" [label="SiLU @ model.layers.7.mlp.experts.39.act_fn\nin [155, 896] torch.bfloat16 | out [155, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.39.down_proj" [label="Linear @ model.layers.7.mlp.experts.39.down_proj\nin [155, 896] torch.bfloat16 | out [155, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.39.gate_proj" [label="Linear @ model.layers.7.mlp.experts.39.gate_proj\nin [155, 1280] torch.bfloat16 | out [155, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.39.up_proj" [label="Linear @ model.layers.7.mlp.experts.39.up_proj\nin [155, 1280] torch.bfloat16 | out [155, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.4\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.4.act_fn" [label="SiLU @ model.layers.7.mlp.experts.4.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.4.down_proj" [label="Linear @ model.layers.7.mlp.experts.4.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.4.gate_proj" [label="Linear @ model.layers.7.mlp.experts.4.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.4.up_proj" [label="Linear @ model.layers.7.mlp.experts.4.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.41\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.41.act_fn" [label="SiLU @ model.layers.7.mlp.experts.41.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.41.down_proj" [label="Linear @ model.layers.7.mlp.experts.41.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.41.gate_proj" [label="Linear @ model.layers.7.mlp.experts.41.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.41.up_proj" [label="Linear @ model.layers.7.mlp.experts.41.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.42\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.42.act_fn" [label="SiLU @ model.layers.7.mlp.experts.42.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.42.down_proj" [label="Linear @ model.layers.7.mlp.experts.42.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.42.gate_proj" [label="Linear @ model.layers.7.mlp.experts.42.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.42.up_proj" [label="Linear @ model.layers.7.mlp.experts.42.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.43\nin [66, 1280] torch.bfloat16 | out [66, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.43.act_fn" [label="SiLU @ model.layers.7.mlp.experts.43.act_fn\nin [66, 896] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.43.down_proj" [label="Linear @ model.layers.7.mlp.experts.43.down_proj\nin [66, 896] torch.bfloat16 | out [66, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.43.gate_proj" [label="Linear @ model.layers.7.mlp.experts.43.gate_proj\nin [66, 1280] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.43.up_proj" [label="Linear @ model.layers.7.mlp.experts.43.up_proj\nin [66, 1280] torch.bfloat16 | out [66, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.44\nin [44, 1280] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.44.act_fn" [label="SiLU @ model.layers.7.mlp.experts.44.act_fn\nin [44, 896] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.44.down_proj" [label="Linear @ model.layers.7.mlp.experts.44.down_proj\nin [44, 896] torch.bfloat16 | out [44, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.44.gate_proj" [label="Linear @ model.layers.7.mlp.experts.44.gate_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.44.up_proj" [label="Linear @ model.layers.7.mlp.experts.44.up_proj\nin [44, 1280] torch.bfloat16 | out [44, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.45\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.45.act_fn" [label="SiLU @ model.layers.7.mlp.experts.45.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.45.down_proj" [label="Linear @ model.layers.7.mlp.experts.45.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.45.gate_proj" [label="Linear @ model.layers.7.mlp.experts.45.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.45.up_proj" [label="Linear @ model.layers.7.mlp.experts.45.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.46\nin [47, 1280] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.46.act_fn" [label="SiLU @ model.layers.7.mlp.experts.46.act_fn\nin [47, 896] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.46.down_proj" [label="Linear @ model.layers.7.mlp.experts.46.down_proj\nin [47, 896] torch.bfloat16 | out [47, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.46.gate_proj" [label="Linear @ model.layers.7.mlp.experts.46.gate_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.46.up_proj" [label="Linear @ model.layers.7.mlp.experts.46.up_proj\nin [47, 1280] torch.bfloat16 | out [47, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.47\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.47.act_fn" [label="SiLU @ model.layers.7.mlp.experts.47.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.47.down_proj" [label="Linear @ model.layers.7.mlp.experts.47.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.47.gate_proj" [label="Linear @ model.layers.7.mlp.experts.47.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.47.up_proj" [label="Linear @ model.layers.7.mlp.experts.47.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.48\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.48.act_fn" [label="SiLU @ model.layers.7.mlp.experts.48.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.48.down_proj" [label="Linear @ model.layers.7.mlp.experts.48.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.48.gate_proj" [label="Linear @ model.layers.7.mlp.experts.48.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.48.up_proj" [label="Linear @ model.layers.7.mlp.experts.48.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.49\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.49.act_fn" [label="SiLU @ model.layers.7.mlp.experts.49.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.49.down_proj" [label="Linear @ model.layers.7.mlp.experts.49.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.49.gate_proj" [label="Linear @ model.layers.7.mlp.experts.49.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.49.up_proj" [label="Linear @ model.layers.7.mlp.experts.49.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.5\nin [61, 1280] torch.bfloat16 | out [61, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.5.act_fn" [label="SiLU @ model.layers.7.mlp.experts.5.act_fn\nin [61, 896] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.5.down_proj" [label="Linear @ model.layers.7.mlp.experts.5.down_proj\nin [61, 896] torch.bfloat16 | out [61, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.5.gate_proj" [label="Linear @ model.layers.7.mlp.experts.5.gate_proj\nin [61, 1280] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.5.up_proj" [label="Linear @ model.layers.7.mlp.experts.5.up_proj\nin [61, 1280] torch.bfloat16 | out [61, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.51\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.51.act_fn" [label="SiLU @ model.layers.7.mlp.experts.51.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.51.down_proj" [label="Linear @ model.layers.7.mlp.experts.51.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.51.gate_proj" [label="Linear @ model.layers.7.mlp.experts.51.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.51.up_proj" [label="Linear @ model.layers.7.mlp.experts.51.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.52\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.52.act_fn" [label="SiLU @ model.layers.7.mlp.experts.52.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.52.down_proj" [label="Linear @ model.layers.7.mlp.experts.52.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.52.gate_proj" [label="Linear @ model.layers.7.mlp.experts.52.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.52.up_proj" [label="Linear @ model.layers.7.mlp.experts.52.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.53\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.53.act_fn" [label="SiLU @ model.layers.7.mlp.experts.53.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.53.down_proj" [label="Linear @ model.layers.7.mlp.experts.53.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.53.gate_proj" [label="Linear @ model.layers.7.mlp.experts.53.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.53.up_proj" [label="Linear @ model.layers.7.mlp.experts.53.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.54\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.54.act_fn" [label="SiLU @ model.layers.7.mlp.experts.54.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.54.down_proj" [label="Linear @ model.layers.7.mlp.experts.54.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.54.gate_proj" [label="Linear @ model.layers.7.mlp.experts.54.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.54.up_proj" [label="Linear @ model.layers.7.mlp.experts.54.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.55\nin [80, 1280] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.55.act_fn" [label="SiLU @ model.layers.7.mlp.experts.55.act_fn\nin [80, 896] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.55.down_proj" [label="Linear @ model.layers.7.mlp.experts.55.down_proj\nin [80, 896] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.55.gate_proj" [label="Linear @ model.layers.7.mlp.experts.55.gate_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.55.up_proj" [label="Linear @ model.layers.7.mlp.experts.55.up_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.56\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.56.act_fn" [label="SiLU @ model.layers.7.mlp.experts.56.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.56.down_proj" [label="Linear @ model.layers.7.mlp.experts.56.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.56.gate_proj" [label="Linear @ model.layers.7.mlp.experts.56.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.56.up_proj" [label="Linear @ model.layers.7.mlp.experts.56.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.57\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.57.act_fn" [label="SiLU @ model.layers.7.mlp.experts.57.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.57.down_proj" [label="Linear @ model.layers.7.mlp.experts.57.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.57.gate_proj" [label="Linear @ model.layers.7.mlp.experts.57.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.57.up_proj" [label="Linear @ model.layers.7.mlp.experts.57.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.58\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.58.act_fn" [label="SiLU @ model.layers.7.mlp.experts.58.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.58.down_proj" [label="Linear @ model.layers.7.mlp.experts.58.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.58.gate_proj" [label="Linear @ model.layers.7.mlp.experts.58.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.58.up_proj" [label="Linear @ model.layers.7.mlp.experts.58.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.59\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.59.act_fn" [label="SiLU @ model.layers.7.mlp.experts.59.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.59.down_proj" [label="Linear @ model.layers.7.mlp.experts.59.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.59.gate_proj" [label="Linear @ model.layers.7.mlp.experts.59.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.59.up_proj" [label="Linear @ model.layers.7.mlp.experts.59.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.6\nin [38, 1280] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.6.act_fn" [label="SiLU @ model.layers.7.mlp.experts.6.act_fn\nin [38, 896] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.6.down_proj" [label="Linear @ model.layers.7.mlp.experts.6.down_proj\nin [38, 896] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.6.gate_proj" [label="Linear @ model.layers.7.mlp.experts.6.gate_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.6.up_proj" [label="Linear @ model.layers.7.mlp.experts.6.up_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.60\nin [65, 1280] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.60.act_fn" [label="SiLU @ model.layers.7.mlp.experts.60.act_fn\nin [65, 896] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.60.down_proj" [label="Linear @ model.layers.7.mlp.experts.60.down_proj\nin [65, 896] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.60.gate_proj" [label="Linear @ model.layers.7.mlp.experts.60.gate_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.60.up_proj" [label="Linear @ model.layers.7.mlp.experts.60.up_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.61\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.61.act_fn" [label="SiLU @ model.layers.7.mlp.experts.61.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.61.down_proj" [label="Linear @ model.layers.7.mlp.experts.61.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.61.gate_proj" [label="Linear @ model.layers.7.mlp.experts.61.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.61.up_proj" [label="Linear @ model.layers.7.mlp.experts.61.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.62\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.62.act_fn" [label="SiLU @ model.layers.7.mlp.experts.62.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.62.down_proj" [label="Linear @ model.layers.7.mlp.experts.62.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.62.gate_proj" [label="Linear @ model.layers.7.mlp.experts.62.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.62.up_proj" [label="Linear @ model.layers.7.mlp.experts.62.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.63\nin [25, 1280] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.63.act_fn" [label="SiLU @ model.layers.7.mlp.experts.63.act_fn\nin [25, 896] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.63.down_proj" [label="Linear @ model.layers.7.mlp.experts.63.down_proj\nin [25, 896] torch.bfloat16 | out [25, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.63.gate_proj" [label="Linear @ model.layers.7.mlp.experts.63.gate_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.63.up_proj" [label="Linear @ model.layers.7.mlp.experts.63.up_proj\nin [25, 1280] torch.bfloat16 | out [25, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.7\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.7.act_fn" [label="SiLU @ model.layers.7.mlp.experts.7.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.7.down_proj" [label="Linear @ model.layers.7.mlp.experts.7.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.7.gate_proj" [label="Linear @ model.layers.7.mlp.experts.7.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.7.up_proj" [label="Linear @ model.layers.7.mlp.experts.7.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.8\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.8.act_fn" [label="SiLU @ model.layers.7.mlp.experts.8.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.8.down_proj" [label="Linear @ model.layers.7.mlp.experts.8.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.8.gate_proj" [label="Linear @ model.layers.7.mlp.experts.8.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.8.up_proj" [label="Linear @ model.layers.7.mlp.experts.8.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.7.mlp.experts.9\nin [67, 1280] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.9.act_fn" [label="SiLU @ model.layers.7.mlp.experts.9.act_fn\nin [67, 896] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.9.down_proj" [label="Linear @ model.layers.7.mlp.experts.9.down_proj\nin [67, 896] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.7.mlp.experts.9.gate_proj" [label="Linear @ model.layers.7.mlp.experts.9.gate_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.7.mlp.experts.9.up_proj" [label="Linear @ model.layers.7.mlp.experts.9.up_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.7.mlp.gate" [label="MoEGate @ model.layers.7.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.7.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.7.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.7.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.7.mlp.shared_experts.down_proj" [label="Linear @ model.layers.7.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.7.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.7.mlp.shared_experts.up_proj" [label="Linear @ model.layers.7.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.7.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.7.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.self_attn" [label="LlamaFlashAttention2 @ model.layers.7.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.self_attn.k_proj" [label="Linear @ model.layers.7.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.self_attn.o_proj" [label="Linear @ model.layers.7.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.self_attn.q_proj" [label="Linear @ model.layers.7.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.7.self_attn.v_proj" [label="Linear @ model.layers.7.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8" [label="DeepseekV2DecoderLayer @ model.layers.8\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.8.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.mlp" [label="DeepseekV2MoE @ model.layers.8.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.1\nin [43, 1280] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.1.act_fn" [label="SiLU @ model.layers.8.mlp.experts.1.act_fn\nin [43, 896] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.1.down_proj" [label="Linear @ model.layers.8.mlp.experts.1.down_proj\nin [43, 896] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.1.gate_proj" [label="Linear @ model.layers.8.mlp.experts.1.gate_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.1.up_proj" [label="Linear @ model.layers.8.mlp.experts.1.up_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.10\nin [79, 1280] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.10.act_fn" [label="SiLU @ model.layers.8.mlp.experts.10.act_fn\nin [79, 896] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.10.down_proj" [label="Linear @ model.layers.8.mlp.experts.10.down_proj\nin [79, 896] torch.bfloat16 | out [79, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.10.gate_proj" [label="Linear @ model.layers.8.mlp.experts.10.gate_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.10.up_proj" [label="Linear @ model.layers.8.mlp.experts.10.up_proj\nin [79, 1280] torch.bfloat16 | out [79, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.11\nin [75, 1280] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.11.act_fn" [label="SiLU @ model.layers.8.mlp.experts.11.act_fn\nin [75, 896] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.11.down_proj" [label="Linear @ model.layers.8.mlp.experts.11.down_proj\nin [75, 896] torch.bfloat16 | out [75, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.11.gate_proj" [label="Linear @ model.layers.8.mlp.experts.11.gate_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.11.up_proj" [label="Linear @ model.layers.8.mlp.experts.11.up_proj\nin [75, 1280] torch.bfloat16 | out [75, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.12\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.12.act_fn" [label="SiLU @ model.layers.8.mlp.experts.12.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.12.down_proj" [label="Linear @ model.layers.8.mlp.experts.12.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.12.gate_proj" [label="Linear @ model.layers.8.mlp.experts.12.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.12.up_proj" [label="Linear @ model.layers.8.mlp.experts.12.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.13\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.13.act_fn" [label="SiLU @ model.layers.8.mlp.experts.13.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.13.down_proj" [label="Linear @ model.layers.8.mlp.experts.13.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.13.gate_proj" [label="Linear @ model.layers.8.mlp.experts.13.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.13.up_proj" [label="Linear @ model.layers.8.mlp.experts.13.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.14\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.14.act_fn" [label="SiLU @ model.layers.8.mlp.experts.14.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.14.down_proj" [label="Linear @ model.layers.8.mlp.experts.14.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.14.gate_proj" [label="Linear @ model.layers.8.mlp.experts.14.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.14.up_proj" [label="Linear @ model.layers.8.mlp.experts.14.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.15\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.15.act_fn" [label="SiLU @ model.layers.8.mlp.experts.15.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.15.down_proj" [label="Linear @ model.layers.8.mlp.experts.15.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.15.gate_proj" [label="Linear @ model.layers.8.mlp.experts.15.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.15.up_proj" [label="Linear @ model.layers.8.mlp.experts.15.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.16\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.16.act_fn" [label="SiLU @ model.layers.8.mlp.experts.16.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.16.down_proj" [label="Linear @ model.layers.8.mlp.experts.16.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.16.gate_proj" [label="Linear @ model.layers.8.mlp.experts.16.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.16.up_proj" [label="Linear @ model.layers.8.mlp.experts.16.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.17\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.17.act_fn" [label="SiLU @ model.layers.8.mlp.experts.17.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.17.down_proj" [label="Linear @ model.layers.8.mlp.experts.17.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.17.gate_proj" [label="Linear @ model.layers.8.mlp.experts.17.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.17.up_proj" [label="Linear @ model.layers.8.mlp.experts.17.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.18\nin [71, 1280] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.18.act_fn" [label="SiLU @ model.layers.8.mlp.experts.18.act_fn\nin [71, 896] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.18.down_proj" [label="Linear @ model.layers.8.mlp.experts.18.down_proj\nin [71, 896] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.18.gate_proj" [label="Linear @ model.layers.8.mlp.experts.18.gate_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.18.up_proj" [label="Linear @ model.layers.8.mlp.experts.18.up_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.2\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.2.act_fn" [label="SiLU @ model.layers.8.mlp.experts.2.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.2.down_proj" [label="Linear @ model.layers.8.mlp.experts.2.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.2.gate_proj" [label="Linear @ model.layers.8.mlp.experts.2.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.2.up_proj" [label="Linear @ model.layers.8.mlp.experts.2.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.20\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.20.act_fn" [label="SiLU @ model.layers.8.mlp.experts.20.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.20.down_proj" [label="Linear @ model.layers.8.mlp.experts.20.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.20.gate_proj" [label="Linear @ model.layers.8.mlp.experts.20.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.20.up_proj" [label="Linear @ model.layers.8.mlp.experts.20.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.21\nin [49, 1280] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.21.act_fn" [label="SiLU @ model.layers.8.mlp.experts.21.act_fn\nin [49, 896] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.21.down_proj" [label="Linear @ model.layers.8.mlp.experts.21.down_proj\nin [49, 896] torch.bfloat16 | out [49, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.21.gate_proj" [label="Linear @ model.layers.8.mlp.experts.21.gate_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.21.up_proj" [label="Linear @ model.layers.8.mlp.experts.21.up_proj\nin [49, 1280] torch.bfloat16 | out [49, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.22\nin [33, 1280] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.22.act_fn" [label="SiLU @ model.layers.8.mlp.experts.22.act_fn\nin [33, 896] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.22.down_proj" [label="Linear @ model.layers.8.mlp.experts.22.down_proj\nin [33, 896] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.22.gate_proj" [label="Linear @ model.layers.8.mlp.experts.22.gate_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.22.up_proj" [label="Linear @ model.layers.8.mlp.experts.22.up_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.23\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.23.act_fn" [label="SiLU @ model.layers.8.mlp.experts.23.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.23.down_proj" [label="Linear @ model.layers.8.mlp.experts.23.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.23.gate_proj" [label="Linear @ model.layers.8.mlp.experts.23.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.23.up_proj" [label="Linear @ model.layers.8.mlp.experts.23.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.24\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.24.act_fn" [label="SiLU @ model.layers.8.mlp.experts.24.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.24.down_proj" [label="Linear @ model.layers.8.mlp.experts.24.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.24.gate_proj" [label="Linear @ model.layers.8.mlp.experts.24.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.24.up_proj" [label="Linear @ model.layers.8.mlp.experts.24.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.25\nin [8, 1280] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.25.act_fn" [label="SiLU @ model.layers.8.mlp.experts.25.act_fn\nin [8, 896] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.25.down_proj" [label="Linear @ model.layers.8.mlp.experts.25.down_proj\nin [8, 896] torch.bfloat16 | out [8, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.25.gate_proj" [label="Linear @ model.layers.8.mlp.experts.25.gate_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.25.up_proj" [label="Linear @ model.layers.8.mlp.experts.25.up_proj\nin [8, 1280] torch.bfloat16 | out [8, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.26\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.26.act_fn" [label="SiLU @ model.layers.8.mlp.experts.26.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.26.down_proj" [label="Linear @ model.layers.8.mlp.experts.26.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.26.gate_proj" [label="Linear @ model.layers.8.mlp.experts.26.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.26.up_proj" [label="Linear @ model.layers.8.mlp.experts.26.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.27\nin [59, 1280] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.27.act_fn" [label="SiLU @ model.layers.8.mlp.experts.27.act_fn\nin [59, 896] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.27.down_proj" [label="Linear @ model.layers.8.mlp.experts.27.down_proj\nin [59, 896] torch.bfloat16 | out [59, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.27.gate_proj" [label="Linear @ model.layers.8.mlp.experts.27.gate_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.27.up_proj" [label="Linear @ model.layers.8.mlp.experts.27.up_proj\nin [59, 1280] torch.bfloat16 | out [59, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.28\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.28.act_fn" [label="SiLU @ model.layers.8.mlp.experts.28.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.28.down_proj" [label="Linear @ model.layers.8.mlp.experts.28.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.28.gate_proj" [label="Linear @ model.layers.8.mlp.experts.28.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.28.up_proj" [label="Linear @ model.layers.8.mlp.experts.28.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.29\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.29.act_fn" [label="SiLU @ model.layers.8.mlp.experts.29.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.29.down_proj" [label="Linear @ model.layers.8.mlp.experts.29.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.29.gate_proj" [label="Linear @ model.layers.8.mlp.experts.29.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.29.up_proj" [label="Linear @ model.layers.8.mlp.experts.29.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.3\nin [29, 1280] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.3.act_fn" [label="SiLU @ model.layers.8.mlp.experts.3.act_fn\nin [29, 896] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.3.down_proj" [label="Linear @ model.layers.8.mlp.experts.3.down_proj\nin [29, 896] torch.bfloat16 | out [29, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.3.gate_proj" [label="Linear @ model.layers.8.mlp.experts.3.gate_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.3.up_proj" [label="Linear @ model.layers.8.mlp.experts.3.up_proj\nin [29, 1280] torch.bfloat16 | out [29, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.30\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.30.act_fn" [label="SiLU @ model.layers.8.mlp.experts.30.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.30.down_proj" [label="Linear @ model.layers.8.mlp.experts.30.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.30.gate_proj" [label="Linear @ model.layers.8.mlp.experts.30.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.30.up_proj" [label="Linear @ model.layers.8.mlp.experts.30.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.32\nin [63, 1280] torch.bfloat16 | out [63, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.32.act_fn" [label="SiLU @ model.layers.8.mlp.experts.32.act_fn\nin [63, 896] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.32.down_proj" [label="Linear @ model.layers.8.mlp.experts.32.down_proj\nin [63, 896] torch.bfloat16 | out [63, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.32.gate_proj" [label="Linear @ model.layers.8.mlp.experts.32.gate_proj\nin [63, 1280] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.32.up_proj" [label="Linear @ model.layers.8.mlp.experts.32.up_proj\nin [63, 1280] torch.bfloat16 | out [63, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.33\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.33.act_fn" [label="SiLU @ model.layers.8.mlp.experts.33.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.33.down_proj" [label="Linear @ model.layers.8.mlp.experts.33.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.33.gate_proj" [label="Linear @ model.layers.8.mlp.experts.33.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.33.up_proj" [label="Linear @ model.layers.8.mlp.experts.33.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.34\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.34.act_fn" [label="SiLU @ model.layers.8.mlp.experts.34.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.34.down_proj" [label="Linear @ model.layers.8.mlp.experts.34.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.34.gate_proj" [label="Linear @ model.layers.8.mlp.experts.34.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.34.up_proj" [label="Linear @ model.layers.8.mlp.experts.34.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.35\nin [19, 1280] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.35.act_fn" [label="SiLU @ model.layers.8.mlp.experts.35.act_fn\nin [19, 896] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.35.down_proj" [label="Linear @ model.layers.8.mlp.experts.35.down_proj\nin [19, 896] torch.bfloat16 | out [19, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.35.gate_proj" [label="Linear @ model.layers.8.mlp.experts.35.gate_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.35.up_proj" [label="Linear @ model.layers.8.mlp.experts.35.up_proj\nin [19, 1280] torch.bfloat16 | out [19, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.36\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.36.act_fn" [label="SiLU @ model.layers.8.mlp.experts.36.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.36.down_proj" [label="Linear @ model.layers.8.mlp.experts.36.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.36.gate_proj" [label="Linear @ model.layers.8.mlp.experts.36.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.36.up_proj" [label="Linear @ model.layers.8.mlp.experts.36.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.37\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.37.act_fn" [label="SiLU @ model.layers.8.mlp.experts.37.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.37.down_proj" [label="Linear @ model.layers.8.mlp.experts.37.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.37.gate_proj" [label="Linear @ model.layers.8.mlp.experts.37.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.37.up_proj" [label="Linear @ model.layers.8.mlp.experts.37.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.39\nin [51, 1280] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.39.act_fn" [label="SiLU @ model.layers.8.mlp.experts.39.act_fn\nin [51, 896] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.39.down_proj" [label="Linear @ model.layers.8.mlp.experts.39.down_proj\nin [51, 896] torch.bfloat16 | out [51, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.39.gate_proj" [label="Linear @ model.layers.8.mlp.experts.39.gate_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.39.up_proj" [label="Linear @ model.layers.8.mlp.experts.39.up_proj\nin [51, 1280] torch.bfloat16 | out [51, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.4\nin [6, 1280] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.4.act_fn" [label="SiLU @ model.layers.8.mlp.experts.4.act_fn\nin [6, 896] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.4.down_proj" [label="Linear @ model.layers.8.mlp.experts.4.down_proj\nin [6, 896] torch.bfloat16 | out [6, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.4.gate_proj" [label="Linear @ model.layers.8.mlp.experts.4.gate_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.4.up_proj" [label="Linear @ model.layers.8.mlp.experts.4.up_proj\nin [6, 1280] torch.bfloat16 | out [6, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.40\nin [12, 1280] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.40.act_fn" [label="SiLU @ model.layers.8.mlp.experts.40.act_fn\nin [12, 896] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.40.down_proj" [label="Linear @ model.layers.8.mlp.experts.40.down_proj\nin [12, 896] torch.bfloat16 | out [12, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.40.gate_proj" [label="Linear @ model.layers.8.mlp.experts.40.gate_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.40.up_proj" [label="Linear @ model.layers.8.mlp.experts.40.up_proj\nin [12, 1280] torch.bfloat16 | out [12, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.41\nin [57, 1280] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.41.act_fn" [label="SiLU @ model.layers.8.mlp.experts.41.act_fn\nin [57, 896] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.41.down_proj" [label="Linear @ model.layers.8.mlp.experts.41.down_proj\nin [57, 896] torch.bfloat16 | out [57, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.41.gate_proj" [label="Linear @ model.layers.8.mlp.experts.41.gate_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.41.up_proj" [label="Linear @ model.layers.8.mlp.experts.41.up_proj\nin [57, 1280] torch.bfloat16 | out [57, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.42\nin [33, 1280] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.42.act_fn" [label="SiLU @ model.layers.8.mlp.experts.42.act_fn\nin [33, 896] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.42.down_proj" [label="Linear @ model.layers.8.mlp.experts.42.down_proj\nin [33, 896] torch.bfloat16 | out [33, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.42.gate_proj" [label="Linear @ model.layers.8.mlp.experts.42.gate_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.42.up_proj" [label="Linear @ model.layers.8.mlp.experts.42.up_proj\nin [33, 1280] torch.bfloat16 | out [33, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.43\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.43.act_fn" [label="SiLU @ model.layers.8.mlp.experts.43.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.43.down_proj" [label="Linear @ model.layers.8.mlp.experts.43.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.43.gate_proj" [label="Linear @ model.layers.8.mlp.experts.43.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.43.up_proj" [label="Linear @ model.layers.8.mlp.experts.43.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.44\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.44.act_fn" [label="SiLU @ model.layers.8.mlp.experts.44.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.44.down_proj" [label="Linear @ model.layers.8.mlp.experts.44.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.44.gate_proj" [label="Linear @ model.layers.8.mlp.experts.44.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.44.up_proj" [label="Linear @ model.layers.8.mlp.experts.44.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.45\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.45.act_fn" [label="SiLU @ model.layers.8.mlp.experts.45.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.45.down_proj" [label="Linear @ model.layers.8.mlp.experts.45.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.45.gate_proj" [label="Linear @ model.layers.8.mlp.experts.45.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.45.up_proj" [label="Linear @ model.layers.8.mlp.experts.45.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.46\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.46.act_fn" [label="SiLU @ model.layers.8.mlp.experts.46.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.46.down_proj" [label="Linear @ model.layers.8.mlp.experts.46.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.46.gate_proj" [label="Linear @ model.layers.8.mlp.experts.46.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.46.up_proj" [label="Linear @ model.layers.8.mlp.experts.46.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.47\nin [46, 1280] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.47.act_fn" [label="SiLU @ model.layers.8.mlp.experts.47.act_fn\nin [46, 896] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.47.down_proj" [label="Linear @ model.layers.8.mlp.experts.47.down_proj\nin [46, 896] torch.bfloat16 | out [46, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.47.gate_proj" [label="Linear @ model.layers.8.mlp.experts.47.gate_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.47.up_proj" [label="Linear @ model.layers.8.mlp.experts.47.up_proj\nin [46, 1280] torch.bfloat16 | out [46, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.48\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.48.act_fn" [label="SiLU @ model.layers.8.mlp.experts.48.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.48.down_proj" [label="Linear @ model.layers.8.mlp.experts.48.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.48.gate_proj" [label="Linear @ model.layers.8.mlp.experts.48.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.48.up_proj" [label="Linear @ model.layers.8.mlp.experts.48.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.49\nin [56, 1280] torch.bfloat16 | out [56, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.49.act_fn" [label="SiLU @ model.layers.8.mlp.experts.49.act_fn\nin [56, 896] torch.bfloat16 | out [56, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.49.down_proj" [label="Linear @ model.layers.8.mlp.experts.49.down_proj\nin [56, 896] torch.bfloat16 | out [56, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.49.gate_proj" [label="Linear @ model.layers.8.mlp.experts.49.gate_proj\nin [56, 1280] torch.bfloat16 | out [56, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.49.up_proj" [label="Linear @ model.layers.8.mlp.experts.49.up_proj\nin [56, 1280] torch.bfloat16 | out [56, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.5\nin [27, 1280] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.5.act_fn" [label="SiLU @ model.layers.8.mlp.experts.5.act_fn\nin [27, 896] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.5.down_proj" [label="Linear @ model.layers.8.mlp.experts.5.down_proj\nin [27, 896] torch.bfloat16 | out [27, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.5.gate_proj" [label="Linear @ model.layers.8.mlp.experts.5.gate_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.5.up_proj" [label="Linear @ model.layers.8.mlp.experts.5.up_proj\nin [27, 1280] torch.bfloat16 | out [27, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.50\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.50.act_fn" [label="SiLU @ model.layers.8.mlp.experts.50.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.50.down_proj" [label="Linear @ model.layers.8.mlp.experts.50.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.50.gate_proj" [label="Linear @ model.layers.8.mlp.experts.50.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.50.up_proj" [label="Linear @ model.layers.8.mlp.experts.50.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.51\nin [50, 1280] torch.bfloat16 | out [50, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.51.act_fn" [label="SiLU @ model.layers.8.mlp.experts.51.act_fn\nin [50, 896] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.51.down_proj" [label="Linear @ model.layers.8.mlp.experts.51.down_proj\nin [50, 896] torch.bfloat16 | out [50, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.51.gate_proj" [label="Linear @ model.layers.8.mlp.experts.51.gate_proj\nin [50, 1280] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.51.up_proj" [label="Linear @ model.layers.8.mlp.experts.51.up_proj\nin [50, 1280] torch.bfloat16 | out [50, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.52\nin [43, 1280] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.52.act_fn" [label="SiLU @ model.layers.8.mlp.experts.52.act_fn\nin [43, 896] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.52.down_proj" [label="Linear @ model.layers.8.mlp.experts.52.down_proj\nin [43, 896] torch.bfloat16 | out [43, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.52.gate_proj" [label="Linear @ model.layers.8.mlp.experts.52.gate_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.52.up_proj" [label="Linear @ model.layers.8.mlp.experts.52.up_proj\nin [43, 1280] torch.bfloat16 | out [43, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.53\nin [123, 1280] torch.bfloat16 | out [123, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.53.act_fn" [label="SiLU @ model.layers.8.mlp.experts.53.act_fn\nin [123, 896] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.53.down_proj" [label="Linear @ model.layers.8.mlp.experts.53.down_proj\nin [123, 896] torch.bfloat16 | out [123, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.53.gate_proj" [label="Linear @ model.layers.8.mlp.experts.53.gate_proj\nin [123, 1280] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.53.up_proj" [label="Linear @ model.layers.8.mlp.experts.53.up_proj\nin [123, 1280] torch.bfloat16 | out [123, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.54\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.54.act_fn" [label="SiLU @ model.layers.8.mlp.experts.54.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.54.down_proj" [label="Linear @ model.layers.8.mlp.experts.54.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.54.gate_proj" [label="Linear @ model.layers.8.mlp.experts.54.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.54.up_proj" [label="Linear @ model.layers.8.mlp.experts.54.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.55\nin [85, 1280] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.55.act_fn" [label="SiLU @ model.layers.8.mlp.experts.55.act_fn\nin [85, 896] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.55.down_proj" [label="Linear @ model.layers.8.mlp.experts.55.down_proj\nin [85, 896] torch.bfloat16 | out [85, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.55.gate_proj" [label="Linear @ model.layers.8.mlp.experts.55.gate_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.55.up_proj" [label="Linear @ model.layers.8.mlp.experts.55.up_proj\nin [85, 1280] torch.bfloat16 | out [85, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.56\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.56.act_fn" [label="SiLU @ model.layers.8.mlp.experts.56.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.56.down_proj" [label="Linear @ model.layers.8.mlp.experts.56.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.56.gate_proj" [label="Linear @ model.layers.8.mlp.experts.56.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.56.up_proj" [label="Linear @ model.layers.8.mlp.experts.56.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.57\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.57.act_fn" [label="SiLU @ model.layers.8.mlp.experts.57.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.57.down_proj" [label="Linear @ model.layers.8.mlp.experts.57.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.57.gate_proj" [label="Linear @ model.layers.8.mlp.experts.57.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.57.up_proj" [label="Linear @ model.layers.8.mlp.experts.57.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.58\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.58.act_fn" [label="SiLU @ model.layers.8.mlp.experts.58.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.58.down_proj" [label="Linear @ model.layers.8.mlp.experts.58.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.58.gate_proj" [label="Linear @ model.layers.8.mlp.experts.58.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.58.up_proj" [label="Linear @ model.layers.8.mlp.experts.58.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.59\nin [7, 1280] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.59.act_fn" [label="SiLU @ model.layers.8.mlp.experts.59.act_fn\nin [7, 896] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.59.down_proj" [label="Linear @ model.layers.8.mlp.experts.59.down_proj\nin [7, 896] torch.bfloat16 | out [7, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.59.gate_proj" [label="Linear @ model.layers.8.mlp.experts.59.gate_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.59.up_proj" [label="Linear @ model.layers.8.mlp.experts.59.up_proj\nin [7, 1280] torch.bfloat16 | out [7, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.6\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.6.act_fn" [label="SiLU @ model.layers.8.mlp.experts.6.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.6.down_proj" [label="Linear @ model.layers.8.mlp.experts.6.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.6.gate_proj" [label="Linear @ model.layers.8.mlp.experts.6.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.6.up_proj" [label="Linear @ model.layers.8.mlp.experts.6.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.60\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.60.act_fn" [label="SiLU @ model.layers.8.mlp.experts.60.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.60.down_proj" [label="Linear @ model.layers.8.mlp.experts.60.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.60.gate_proj" [label="Linear @ model.layers.8.mlp.experts.60.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.60.up_proj" [label="Linear @ model.layers.8.mlp.experts.60.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.61\nin [31, 1280] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.61.act_fn" [label="SiLU @ model.layers.8.mlp.experts.61.act_fn\nin [31, 896] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.61.down_proj" [label="Linear @ model.layers.8.mlp.experts.61.down_proj\nin [31, 896] torch.bfloat16 | out [31, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.61.gate_proj" [label="Linear @ model.layers.8.mlp.experts.61.gate_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.61.up_proj" [label="Linear @ model.layers.8.mlp.experts.61.up_proj\nin [31, 1280] torch.bfloat16 | out [31, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.62\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.62.act_fn" [label="SiLU @ model.layers.8.mlp.experts.62.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.62.down_proj" [label="Linear @ model.layers.8.mlp.experts.62.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.62.gate_proj" [label="Linear @ model.layers.8.mlp.experts.62.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.62.up_proj" [label="Linear @ model.layers.8.mlp.experts.62.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.63\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.63.act_fn" [label="SiLU @ model.layers.8.mlp.experts.63.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.63.down_proj" [label="Linear @ model.layers.8.mlp.experts.63.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.63.gate_proj" [label="Linear @ model.layers.8.mlp.experts.63.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.63.up_proj" [label="Linear @ model.layers.8.mlp.experts.63.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.7\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.7.act_fn" [label="SiLU @ model.layers.8.mlp.experts.7.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.7.down_proj" [label="Linear @ model.layers.8.mlp.experts.7.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.7.gate_proj" [label="Linear @ model.layers.8.mlp.experts.7.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.7.up_proj" [label="Linear @ model.layers.8.mlp.experts.7.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.8\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.8.act_fn" [label="SiLU @ model.layers.8.mlp.experts.8.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.8.down_proj" [label="Linear @ model.layers.8.mlp.experts.8.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.8.gate_proj" [label="Linear @ model.layers.8.mlp.experts.8.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.8.up_proj" [label="Linear @ model.layers.8.mlp.experts.8.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.8.mlp.experts.9\nin [102, 1280] torch.bfloat16 | out [102, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.9.act_fn" [label="SiLU @ model.layers.8.mlp.experts.9.act_fn\nin [102, 896] torch.bfloat16 | out [102, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.9.down_proj" [label="Linear @ model.layers.8.mlp.experts.9.down_proj\nin [102, 896] torch.bfloat16 | out [102, 1280] torch.bfloat16"];
  "model.layers.8.mlp.experts.9.gate_proj" [label="Linear @ model.layers.8.mlp.experts.9.gate_proj\nin [102, 1280] torch.bfloat16 | out [102, 896] torch.bfloat16"];
  "model.layers.8.mlp.experts.9.up_proj" [label="Linear @ model.layers.8.mlp.experts.9.up_proj\nin [102, 1280] torch.bfloat16 | out [102, 896] torch.bfloat16"];
  "model.layers.8.mlp.gate" [label="MoEGate @ model.layers.8.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.8.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.8.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.8.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.8.mlp.shared_experts.down_proj" [label="Linear @ model.layers.8.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.8.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.8.mlp.shared_experts.up_proj" [label="Linear @ model.layers.8.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.8.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.8.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.self_attn" [label="LlamaFlashAttention2 @ model.layers.8.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.self_attn.k_proj" [label="Linear @ model.layers.8.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.self_attn.o_proj" [label="Linear @ model.layers.8.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.self_attn.q_proj" [label="Linear @ model.layers.8.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.8.self_attn.v_proj" [label="Linear @ model.layers.8.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9" [label="DeepseekV2DecoderLayer @ model.layers.9\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.input_layernorm" [label="DeepseekV2RMSNorm @ model.layers.9.input_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.mlp" [label="DeepseekV2MoE @ model.layers.9.mlp\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.0" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.0\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.0.act_fn" [label="SiLU @ model.layers.9.mlp.experts.0.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.0.down_proj" [label="Linear @ model.layers.9.mlp.experts.0.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.0.gate_proj" [label="Linear @ model.layers.9.mlp.experts.0.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.0.up_proj" [label="Linear @ model.layers.9.mlp.experts.0.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.1" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.1\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.1.act_fn" [label="SiLU @ model.layers.9.mlp.experts.1.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.1.down_proj" [label="Linear @ model.layers.9.mlp.experts.1.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.1.gate_proj" [label="Linear @ model.layers.9.mlp.experts.1.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.1.up_proj" [label="Linear @ model.layers.9.mlp.experts.1.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.10" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.10\nin [68, 1280] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.10.act_fn" [label="SiLU @ model.layers.9.mlp.experts.10.act_fn\nin [68, 896] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.10.down_proj" [label="Linear @ model.layers.9.mlp.experts.10.down_proj\nin [68, 896] torch.bfloat16 | out [68, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.10.gate_proj" [label="Linear @ model.layers.9.mlp.experts.10.gate_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.10.up_proj" [label="Linear @ model.layers.9.mlp.experts.10.up_proj\nin [68, 1280] torch.bfloat16 | out [68, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.11" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.11\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.11.act_fn" [label="SiLU @ model.layers.9.mlp.experts.11.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.11.down_proj" [label="Linear @ model.layers.9.mlp.experts.11.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.11.gate_proj" [label="Linear @ model.layers.9.mlp.experts.11.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.11.up_proj" [label="Linear @ model.layers.9.mlp.experts.11.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.12" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.12\nin [24, 1280] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.12.act_fn" [label="SiLU @ model.layers.9.mlp.experts.12.act_fn\nin [24, 896] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.12.down_proj" [label="Linear @ model.layers.9.mlp.experts.12.down_proj\nin [24, 896] torch.bfloat16 | out [24, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.12.gate_proj" [label="Linear @ model.layers.9.mlp.experts.12.gate_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.12.up_proj" [label="Linear @ model.layers.9.mlp.experts.12.up_proj\nin [24, 1280] torch.bfloat16 | out [24, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.13" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.13\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.13.act_fn" [label="SiLU @ model.layers.9.mlp.experts.13.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.13.down_proj" [label="Linear @ model.layers.9.mlp.experts.13.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.13.gate_proj" [label="Linear @ model.layers.9.mlp.experts.13.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.13.up_proj" [label="Linear @ model.layers.9.mlp.experts.13.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.14" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.14\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.14.act_fn" [label="SiLU @ model.layers.9.mlp.experts.14.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.14.down_proj" [label="Linear @ model.layers.9.mlp.experts.14.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.14.gate_proj" [label="Linear @ model.layers.9.mlp.experts.14.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.14.up_proj" [label="Linear @ model.layers.9.mlp.experts.14.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.15" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.15\nin [103, 1280] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.15.act_fn" [label="SiLU @ model.layers.9.mlp.experts.15.act_fn\nin [103, 896] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.15.down_proj" [label="Linear @ model.layers.9.mlp.experts.15.down_proj\nin [103, 896] torch.bfloat16 | out [103, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.15.gate_proj" [label="Linear @ model.layers.9.mlp.experts.15.gate_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.15.up_proj" [label="Linear @ model.layers.9.mlp.experts.15.up_proj\nin [103, 1280] torch.bfloat16 | out [103, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.16" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.16\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.16.act_fn" [label="SiLU @ model.layers.9.mlp.experts.16.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.16.down_proj" [label="Linear @ model.layers.9.mlp.experts.16.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.16.gate_proj" [label="Linear @ model.layers.9.mlp.experts.16.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.16.up_proj" [label="Linear @ model.layers.9.mlp.experts.16.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.17" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.17\nin [20, 1280] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.17.act_fn" [label="SiLU @ model.layers.9.mlp.experts.17.act_fn\nin [20, 896] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.17.down_proj" [label="Linear @ model.layers.9.mlp.experts.17.down_proj\nin [20, 896] torch.bfloat16 | out [20, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.17.gate_proj" [label="Linear @ model.layers.9.mlp.experts.17.gate_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.17.up_proj" [label="Linear @ model.layers.9.mlp.experts.17.up_proj\nin [20, 1280] torch.bfloat16 | out [20, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.18" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.18\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.18.act_fn" [label="SiLU @ model.layers.9.mlp.experts.18.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.18.down_proj" [label="Linear @ model.layers.9.mlp.experts.18.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.18.gate_proj" [label="Linear @ model.layers.9.mlp.experts.18.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.18.up_proj" [label="Linear @ model.layers.9.mlp.experts.18.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.19" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.19\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.19.act_fn" [label="SiLU @ model.layers.9.mlp.experts.19.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.19.down_proj" [label="Linear @ model.layers.9.mlp.experts.19.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.19.gate_proj" [label="Linear @ model.layers.9.mlp.experts.19.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.19.up_proj" [label="Linear @ model.layers.9.mlp.experts.19.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.2" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.2\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.2.act_fn" [label="SiLU @ model.layers.9.mlp.experts.2.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.2.down_proj" [label="Linear @ model.layers.9.mlp.experts.2.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.2.gate_proj" [label="Linear @ model.layers.9.mlp.experts.2.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.2.up_proj" [label="Linear @ model.layers.9.mlp.experts.2.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.20" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.20\nin [9, 1280] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.20.act_fn" [label="SiLU @ model.layers.9.mlp.experts.20.act_fn\nin [9, 896] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.20.down_proj" [label="Linear @ model.layers.9.mlp.experts.20.down_proj\nin [9, 896] torch.bfloat16 | out [9, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.20.gate_proj" [label="Linear @ model.layers.9.mlp.experts.20.gate_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.20.up_proj" [label="Linear @ model.layers.9.mlp.experts.20.up_proj\nin [9, 1280] torch.bfloat16 | out [9, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.21" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.21\nin [41, 1280] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.21.act_fn" [label="SiLU @ model.layers.9.mlp.experts.21.act_fn\nin [41, 896] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.21.down_proj" [label="Linear @ model.layers.9.mlp.experts.21.down_proj\nin [41, 896] torch.bfloat16 | out [41, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.21.gate_proj" [label="Linear @ model.layers.9.mlp.experts.21.gate_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.21.up_proj" [label="Linear @ model.layers.9.mlp.experts.21.up_proj\nin [41, 1280] torch.bfloat16 | out [41, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.22" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.22\nin [52, 1280] torch.bfloat16 | out [52, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.22.act_fn" [label="SiLU @ model.layers.9.mlp.experts.22.act_fn\nin [52, 896] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.22.down_proj" [label="Linear @ model.layers.9.mlp.experts.22.down_proj\nin [52, 896] torch.bfloat16 | out [52, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.22.gate_proj" [label="Linear @ model.layers.9.mlp.experts.22.gate_proj\nin [52, 1280] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.22.up_proj" [label="Linear @ model.layers.9.mlp.experts.22.up_proj\nin [52, 1280] torch.bfloat16 | out [52, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.23" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.23\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.23.act_fn" [label="SiLU @ model.layers.9.mlp.experts.23.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.23.down_proj" [label="Linear @ model.layers.9.mlp.experts.23.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.23.gate_proj" [label="Linear @ model.layers.9.mlp.experts.23.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.23.up_proj" [label="Linear @ model.layers.9.mlp.experts.23.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.24" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.24\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.24.act_fn" [label="SiLU @ model.layers.9.mlp.experts.24.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.24.down_proj" [label="Linear @ model.layers.9.mlp.experts.24.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.24.gate_proj" [label="Linear @ model.layers.9.mlp.experts.24.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.24.up_proj" [label="Linear @ model.layers.9.mlp.experts.24.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.25" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.25\nin [30, 1280] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.25.act_fn" [label="SiLU @ model.layers.9.mlp.experts.25.act_fn\nin [30, 896] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.25.down_proj" [label="Linear @ model.layers.9.mlp.experts.25.down_proj\nin [30, 896] torch.bfloat16 | out [30, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.25.gate_proj" [label="Linear @ model.layers.9.mlp.experts.25.gate_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.25.up_proj" [label="Linear @ model.layers.9.mlp.experts.25.up_proj\nin [30, 1280] torch.bfloat16 | out [30, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.26" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.26\nin [10, 1280] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.26.act_fn" [label="SiLU @ model.layers.9.mlp.experts.26.act_fn\nin [10, 896] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.26.down_proj" [label="Linear @ model.layers.9.mlp.experts.26.down_proj\nin [10, 896] torch.bfloat16 | out [10, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.26.gate_proj" [label="Linear @ model.layers.9.mlp.experts.26.gate_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.26.up_proj" [label="Linear @ model.layers.9.mlp.experts.26.up_proj\nin [10, 1280] torch.bfloat16 | out [10, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.27" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.27\nin [21, 1280] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.27.act_fn" [label="SiLU @ model.layers.9.mlp.experts.27.act_fn\nin [21, 896] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.27.down_proj" [label="Linear @ model.layers.9.mlp.experts.27.down_proj\nin [21, 896] torch.bfloat16 | out [21, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.27.gate_proj" [label="Linear @ model.layers.9.mlp.experts.27.gate_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.27.up_proj" [label="Linear @ model.layers.9.mlp.experts.27.up_proj\nin [21, 1280] torch.bfloat16 | out [21, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.28" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.28\nin [35, 1280] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.28.act_fn" [label="SiLU @ model.layers.9.mlp.experts.28.act_fn\nin [35, 896] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.28.down_proj" [label="Linear @ model.layers.9.mlp.experts.28.down_proj\nin [35, 896] torch.bfloat16 | out [35, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.28.gate_proj" [label="Linear @ model.layers.9.mlp.experts.28.gate_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.28.up_proj" [label="Linear @ model.layers.9.mlp.experts.28.up_proj\nin [35, 1280] torch.bfloat16 | out [35, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.29" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.29\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.29.act_fn" [label="SiLU @ model.layers.9.mlp.experts.29.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.29.down_proj" [label="Linear @ model.layers.9.mlp.experts.29.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.29.gate_proj" [label="Linear @ model.layers.9.mlp.experts.29.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.29.up_proj" [label="Linear @ model.layers.9.mlp.experts.29.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.3" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.3\nin [40, 1280] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.3.act_fn" [label="SiLU @ model.layers.9.mlp.experts.3.act_fn\nin [40, 896] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.3.down_proj" [label="Linear @ model.layers.9.mlp.experts.3.down_proj\nin [40, 896] torch.bfloat16 | out [40, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.3.gate_proj" [label="Linear @ model.layers.9.mlp.experts.3.gate_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.3.up_proj" [label="Linear @ model.layers.9.mlp.experts.3.up_proj\nin [40, 1280] torch.bfloat16 | out [40, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.30" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.30\nin [80, 1280] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.30.act_fn" [label="SiLU @ model.layers.9.mlp.experts.30.act_fn\nin [80, 896] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.30.down_proj" [label="Linear @ model.layers.9.mlp.experts.30.down_proj\nin [80, 896] torch.bfloat16 | out [80, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.30.gate_proj" [label="Linear @ model.layers.9.mlp.experts.30.gate_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.30.up_proj" [label="Linear @ model.layers.9.mlp.experts.30.up_proj\nin [80, 1280] torch.bfloat16 | out [80, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.31" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.31\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.31.act_fn" [label="SiLU @ model.layers.9.mlp.experts.31.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.31.down_proj" [label="Linear @ model.layers.9.mlp.experts.31.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.31.gate_proj" [label="Linear @ model.layers.9.mlp.experts.31.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.31.up_proj" [label="Linear @ model.layers.9.mlp.experts.31.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.32" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.32\nin [71, 1280] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.32.act_fn" [label="SiLU @ model.layers.9.mlp.experts.32.act_fn\nin [71, 896] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.32.down_proj" [label="Linear @ model.layers.9.mlp.experts.32.down_proj\nin [71, 896] torch.bfloat16 | out [71, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.32.gate_proj" [label="Linear @ model.layers.9.mlp.experts.32.gate_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.32.up_proj" [label="Linear @ model.layers.9.mlp.experts.32.up_proj\nin [71, 1280] torch.bfloat16 | out [71, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.33" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.33\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.33.act_fn" [label="SiLU @ model.layers.9.mlp.experts.33.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.33.down_proj" [label="Linear @ model.layers.9.mlp.experts.33.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.33.gate_proj" [label="Linear @ model.layers.9.mlp.experts.33.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.33.up_proj" [label="Linear @ model.layers.9.mlp.experts.33.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.34" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.34\nin [4, 1280] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.34.act_fn" [label="SiLU @ model.layers.9.mlp.experts.34.act_fn\nin [4, 896] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.34.down_proj" [label="Linear @ model.layers.9.mlp.experts.34.down_proj\nin [4, 896] torch.bfloat16 | out [4, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.34.gate_proj" [label="Linear @ model.layers.9.mlp.experts.34.gate_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.34.up_proj" [label="Linear @ model.layers.9.mlp.experts.34.up_proj\nin [4, 1280] torch.bfloat16 | out [4, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.35" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.35\nin [38, 1280] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.35.act_fn" [label="SiLU @ model.layers.9.mlp.experts.35.act_fn\nin [38, 896] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.35.down_proj" [label="Linear @ model.layers.9.mlp.experts.35.down_proj\nin [38, 896] torch.bfloat16 | out [38, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.35.gate_proj" [label="Linear @ model.layers.9.mlp.experts.35.gate_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.35.up_proj" [label="Linear @ model.layers.9.mlp.experts.35.up_proj\nin [38, 1280] torch.bfloat16 | out [38, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.36" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.36\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.36.act_fn" [label="SiLU @ model.layers.9.mlp.experts.36.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.36.down_proj" [label="Linear @ model.layers.9.mlp.experts.36.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.36.gate_proj" [label="Linear @ model.layers.9.mlp.experts.36.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.36.up_proj" [label="Linear @ model.layers.9.mlp.experts.36.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.37" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.37\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.37.act_fn" [label="SiLU @ model.layers.9.mlp.experts.37.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.37.down_proj" [label="Linear @ model.layers.9.mlp.experts.37.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.37.gate_proj" [label="Linear @ model.layers.9.mlp.experts.37.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.37.up_proj" [label="Linear @ model.layers.9.mlp.experts.37.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.38" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.38\nin [22, 1280] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.38.act_fn" [label="SiLU @ model.layers.9.mlp.experts.38.act_fn\nin [22, 896] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.38.down_proj" [label="Linear @ model.layers.9.mlp.experts.38.down_proj\nin [22, 896] torch.bfloat16 | out [22, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.38.gate_proj" [label="Linear @ model.layers.9.mlp.experts.38.gate_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.38.up_proj" [label="Linear @ model.layers.9.mlp.experts.38.up_proj\nin [22, 1280] torch.bfloat16 | out [22, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.39" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.39\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.39.act_fn" [label="SiLU @ model.layers.9.mlp.experts.39.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.39.down_proj" [label="Linear @ model.layers.9.mlp.experts.39.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.39.gate_proj" [label="Linear @ model.layers.9.mlp.experts.39.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.39.up_proj" [label="Linear @ model.layers.9.mlp.experts.39.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.4" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.4\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.4.act_fn" [label="SiLU @ model.layers.9.mlp.experts.4.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.4.down_proj" [label="Linear @ model.layers.9.mlp.experts.4.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.4.gate_proj" [label="Linear @ model.layers.9.mlp.experts.4.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.4.up_proj" [label="Linear @ model.layers.9.mlp.experts.4.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.40" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.40\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.40.act_fn" [label="SiLU @ model.layers.9.mlp.experts.40.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.40.down_proj" [label="Linear @ model.layers.9.mlp.experts.40.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.40.gate_proj" [label="Linear @ model.layers.9.mlp.experts.40.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.40.up_proj" [label="Linear @ model.layers.9.mlp.experts.40.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.41" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.41\nin [16, 1280] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.41.act_fn" [label="SiLU @ model.layers.9.mlp.experts.41.act_fn\nin [16, 896] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.41.down_proj" [label="Linear @ model.layers.9.mlp.experts.41.down_proj\nin [16, 896] torch.bfloat16 | out [16, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.41.gate_proj" [label="Linear @ model.layers.9.mlp.experts.41.gate_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.41.up_proj" [label="Linear @ model.layers.9.mlp.experts.41.up_proj\nin [16, 1280] torch.bfloat16 | out [16, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.42" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.42\nin [45, 1280] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.42.act_fn" [label="SiLU @ model.layers.9.mlp.experts.42.act_fn\nin [45, 896] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.42.down_proj" [label="Linear @ model.layers.9.mlp.experts.42.down_proj\nin [45, 896] torch.bfloat16 | out [45, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.42.gate_proj" [label="Linear @ model.layers.9.mlp.experts.42.gate_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.42.up_proj" [label="Linear @ model.layers.9.mlp.experts.42.up_proj\nin [45, 1280] torch.bfloat16 | out [45, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.43" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.43\nin [54, 1280] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.43.act_fn" [label="SiLU @ model.layers.9.mlp.experts.43.act_fn\nin [54, 896] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.43.down_proj" [label="Linear @ model.layers.9.mlp.experts.43.down_proj\nin [54, 896] torch.bfloat16 | out [54, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.43.gate_proj" [label="Linear @ model.layers.9.mlp.experts.43.gate_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.43.up_proj" [label="Linear @ model.layers.9.mlp.experts.43.up_proj\nin [54, 1280] torch.bfloat16 | out [54, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.44" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.44\nin [13, 1280] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.44.act_fn" [label="SiLU @ model.layers.9.mlp.experts.44.act_fn\nin [13, 896] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.44.down_proj" [label="Linear @ model.layers.9.mlp.experts.44.down_proj\nin [13, 896] torch.bfloat16 | out [13, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.44.gate_proj" [label="Linear @ model.layers.9.mlp.experts.44.gate_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.44.up_proj" [label="Linear @ model.layers.9.mlp.experts.44.up_proj\nin [13, 1280] torch.bfloat16 | out [13, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.45" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.45\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.45.act_fn" [label="SiLU @ model.layers.9.mlp.experts.45.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.45.down_proj" [label="Linear @ model.layers.9.mlp.experts.45.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.45.gate_proj" [label="Linear @ model.layers.9.mlp.experts.45.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.45.up_proj" [label="Linear @ model.layers.9.mlp.experts.45.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.46" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.46\nin [11, 1280] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.46.act_fn" [label="SiLU @ model.layers.9.mlp.experts.46.act_fn\nin [11, 896] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.46.down_proj" [label="Linear @ model.layers.9.mlp.experts.46.down_proj\nin [11, 896] torch.bfloat16 | out [11, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.46.gate_proj" [label="Linear @ model.layers.9.mlp.experts.46.gate_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.46.up_proj" [label="Linear @ model.layers.9.mlp.experts.46.up_proj\nin [11, 1280] torch.bfloat16 | out [11, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.47" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.47\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.47.act_fn" [label="SiLU @ model.layers.9.mlp.experts.47.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.47.down_proj" [label="Linear @ model.layers.9.mlp.experts.47.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.47.gate_proj" [label="Linear @ model.layers.9.mlp.experts.47.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.47.up_proj" [label="Linear @ model.layers.9.mlp.experts.47.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.48" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.48\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.48.act_fn" [label="SiLU @ model.layers.9.mlp.experts.48.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.48.down_proj" [label="Linear @ model.layers.9.mlp.experts.48.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.48.gate_proj" [label="Linear @ model.layers.9.mlp.experts.48.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.48.up_proj" [label="Linear @ model.layers.9.mlp.experts.48.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.49" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.49\nin [65, 1280] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.49.act_fn" [label="SiLU @ model.layers.9.mlp.experts.49.act_fn\nin [65, 896] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.49.down_proj" [label="Linear @ model.layers.9.mlp.experts.49.down_proj\nin [65, 896] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.49.gate_proj" [label="Linear @ model.layers.9.mlp.experts.49.gate_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.49.up_proj" [label="Linear @ model.layers.9.mlp.experts.49.up_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.5" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.5\nin [3, 1280] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.5.act_fn" [label="SiLU @ model.layers.9.mlp.experts.5.act_fn\nin [3, 896] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.5.down_proj" [label="Linear @ model.layers.9.mlp.experts.5.down_proj\nin [3, 896] torch.bfloat16 | out [3, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.5.gate_proj" [label="Linear @ model.layers.9.mlp.experts.5.gate_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.5.up_proj" [label="Linear @ model.layers.9.mlp.experts.5.up_proj\nin [3, 1280] torch.bfloat16 | out [3, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.50" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.50\nin [15, 1280] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.50.act_fn" [label="SiLU @ model.layers.9.mlp.experts.50.act_fn\nin [15, 896] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.50.down_proj" [label="Linear @ model.layers.9.mlp.experts.50.down_proj\nin [15, 896] torch.bfloat16 | out [15, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.50.gate_proj" [label="Linear @ model.layers.9.mlp.experts.50.gate_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.50.up_proj" [label="Linear @ model.layers.9.mlp.experts.50.up_proj\nin [15, 1280] torch.bfloat16 | out [15, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.51" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.51\nin [67, 1280] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.51.act_fn" [label="SiLU @ model.layers.9.mlp.experts.51.act_fn\nin [67, 896] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.51.down_proj" [label="Linear @ model.layers.9.mlp.experts.51.down_proj\nin [67, 896] torch.bfloat16 | out [67, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.51.gate_proj" [label="Linear @ model.layers.9.mlp.experts.51.gate_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.51.up_proj" [label="Linear @ model.layers.9.mlp.experts.51.up_proj\nin [67, 1280] torch.bfloat16 | out [67, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.52" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.52\nin [1, 1280] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.52.act_fn" [label="SiLU @ model.layers.9.mlp.experts.52.act_fn\nin [1, 896] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.52.down_proj" [label="Linear @ model.layers.9.mlp.experts.52.down_proj\nin [1, 896] torch.bfloat16 | out [1, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.52.gate_proj" [label="Linear @ model.layers.9.mlp.experts.52.gate_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.52.up_proj" [label="Linear @ model.layers.9.mlp.experts.52.up_proj\nin [1, 1280] torch.bfloat16 | out [1, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.53" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.53\nin [28, 1280] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.53.act_fn" [label="SiLU @ model.layers.9.mlp.experts.53.act_fn\nin [28, 896] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.53.down_proj" [label="Linear @ model.layers.9.mlp.experts.53.down_proj\nin [28, 896] torch.bfloat16 | out [28, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.53.gate_proj" [label="Linear @ model.layers.9.mlp.experts.53.gate_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.53.up_proj" [label="Linear @ model.layers.9.mlp.experts.53.up_proj\nin [28, 1280] torch.bfloat16 | out [28, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.54" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.54\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.54.act_fn" [label="SiLU @ model.layers.9.mlp.experts.54.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.54.down_proj" [label="Linear @ model.layers.9.mlp.experts.54.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.54.gate_proj" [label="Linear @ model.layers.9.mlp.experts.54.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.54.up_proj" [label="Linear @ model.layers.9.mlp.experts.54.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.55" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.55\nin [26, 1280] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.55.act_fn" [label="SiLU @ model.layers.9.mlp.experts.55.act_fn\nin [26, 896] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.55.down_proj" [label="Linear @ model.layers.9.mlp.experts.55.down_proj\nin [26, 896] torch.bfloat16 | out [26, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.55.gate_proj" [label="Linear @ model.layers.9.mlp.experts.55.gate_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.55.up_proj" [label="Linear @ model.layers.9.mlp.experts.55.up_proj\nin [26, 1280] torch.bfloat16 | out [26, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.56" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.56\nin [34, 1280] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.56.act_fn" [label="SiLU @ model.layers.9.mlp.experts.56.act_fn\nin [34, 896] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.56.down_proj" [label="Linear @ model.layers.9.mlp.experts.56.down_proj\nin [34, 896] torch.bfloat16 | out [34, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.56.gate_proj" [label="Linear @ model.layers.9.mlp.experts.56.gate_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.56.up_proj" [label="Linear @ model.layers.9.mlp.experts.56.up_proj\nin [34, 1280] torch.bfloat16 | out [34, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.57" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.57\nin [23, 1280] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.57.act_fn" [label="SiLU @ model.layers.9.mlp.experts.57.act_fn\nin [23, 896] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.57.down_proj" [label="Linear @ model.layers.9.mlp.experts.57.down_proj\nin [23, 896] torch.bfloat16 | out [23, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.57.gate_proj" [label="Linear @ model.layers.9.mlp.experts.57.gate_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.57.up_proj" [label="Linear @ model.layers.9.mlp.experts.57.up_proj\nin [23, 1280] torch.bfloat16 | out [23, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.58" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.58\nin [65, 1280] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.58.act_fn" [label="SiLU @ model.layers.9.mlp.experts.58.act_fn\nin [65, 896] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.58.down_proj" [label="Linear @ model.layers.9.mlp.experts.58.down_proj\nin [65, 896] torch.bfloat16 | out [65, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.58.gate_proj" [label="Linear @ model.layers.9.mlp.experts.58.gate_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.58.up_proj" [label="Linear @ model.layers.9.mlp.experts.58.up_proj\nin [65, 1280] torch.bfloat16 | out [65, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.59" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.59\nin [2, 1280] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.59.act_fn" [label="SiLU @ model.layers.9.mlp.experts.59.act_fn\nin [2, 896] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.59.down_proj" [label="Linear @ model.layers.9.mlp.experts.59.down_proj\nin [2, 896] torch.bfloat16 | out [2, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.59.gate_proj" [label="Linear @ model.layers.9.mlp.experts.59.gate_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.59.up_proj" [label="Linear @ model.layers.9.mlp.experts.59.up_proj\nin [2, 1280] torch.bfloat16 | out [2, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.6" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.6\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.6.act_fn" [label="SiLU @ model.layers.9.mlp.experts.6.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.6.down_proj" [label="Linear @ model.layers.9.mlp.experts.6.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.6.gate_proj" [label="Linear @ model.layers.9.mlp.experts.6.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.6.up_proj" [label="Linear @ model.layers.9.mlp.experts.6.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.60" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.60\nin [18, 1280] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.60.act_fn" [label="SiLU @ model.layers.9.mlp.experts.60.act_fn\nin [18, 896] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.60.down_proj" [label="Linear @ model.layers.9.mlp.experts.60.down_proj\nin [18, 896] torch.bfloat16 | out [18, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.60.gate_proj" [label="Linear @ model.layers.9.mlp.experts.60.gate_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.60.up_proj" [label="Linear @ model.layers.9.mlp.experts.60.up_proj\nin [18, 1280] torch.bfloat16 | out [18, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.61" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.61\nin [42, 1280] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.61.act_fn" [label="SiLU @ model.layers.9.mlp.experts.61.act_fn\nin [42, 896] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.61.down_proj" [label="Linear @ model.layers.9.mlp.experts.61.down_proj\nin [42, 896] torch.bfloat16 | out [42, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.61.gate_proj" [label="Linear @ model.layers.9.mlp.experts.61.gate_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.61.up_proj" [label="Linear @ model.layers.9.mlp.experts.61.up_proj\nin [42, 1280] torch.bfloat16 | out [42, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.62" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.62\nin [17, 1280] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.62.act_fn" [label="SiLU @ model.layers.9.mlp.experts.62.act_fn\nin [17, 896] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.62.down_proj" [label="Linear @ model.layers.9.mlp.experts.62.down_proj\nin [17, 896] torch.bfloat16 | out [17, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.62.gate_proj" [label="Linear @ model.layers.9.mlp.experts.62.gate_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.62.up_proj" [label="Linear @ model.layers.9.mlp.experts.62.up_proj\nin [17, 1280] torch.bfloat16 | out [17, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.63" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.63\nin [48, 1280] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.63.act_fn" [label="SiLU @ model.layers.9.mlp.experts.63.act_fn\nin [48, 896] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.63.down_proj" [label="Linear @ model.layers.9.mlp.experts.63.down_proj\nin [48, 896] torch.bfloat16 | out [48, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.63.gate_proj" [label="Linear @ model.layers.9.mlp.experts.63.gate_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.63.up_proj" [label="Linear @ model.layers.9.mlp.experts.63.up_proj\nin [48, 1280] torch.bfloat16 | out [48, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.7" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.7\nin [39, 1280] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.7.act_fn" [label="SiLU @ model.layers.9.mlp.experts.7.act_fn\nin [39, 896] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.7.down_proj" [label="Linear @ model.layers.9.mlp.experts.7.down_proj\nin [39, 896] torch.bfloat16 | out [39, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.7.gate_proj" [label="Linear @ model.layers.9.mlp.experts.7.gate_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.7.up_proj" [label="Linear @ model.layers.9.mlp.experts.7.up_proj\nin [39, 1280] torch.bfloat16 | out [39, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.8" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.8\nin [14, 1280] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.8.act_fn" [label="SiLU @ model.layers.9.mlp.experts.8.act_fn\nin [14, 896] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.8.down_proj" [label="Linear @ model.layers.9.mlp.experts.8.down_proj\nin [14, 896] torch.bfloat16 | out [14, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.8.gate_proj" [label="Linear @ model.layers.9.mlp.experts.8.gate_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.8.up_proj" [label="Linear @ model.layers.9.mlp.experts.8.up_proj\nin [14, 1280] torch.bfloat16 | out [14, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.9" [label="DeepseekV2MLP @ model.layers.9.mlp.experts.9\nin [122, 1280] torch.bfloat16 | out [122, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.9.act_fn" [label="SiLU @ model.layers.9.mlp.experts.9.act_fn\nin [122, 896] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.9.down_proj" [label="Linear @ model.layers.9.mlp.experts.9.down_proj\nin [122, 896] torch.bfloat16 | out [122, 1280] torch.bfloat16"];
  "model.layers.9.mlp.experts.9.gate_proj" [label="Linear @ model.layers.9.mlp.experts.9.gate_proj\nin [122, 1280] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.9.mlp.experts.9.up_proj" [label="Linear @ model.layers.9.mlp.experts.9.up_proj\nin [122, 1280] torch.bfloat16 | out [122, 896] torch.bfloat16"];
  "model.layers.9.mlp.gate" [label="MoEGate @ model.layers.9.mlp.gate\nin [1, 323, 1280] torch.bfloat16 | out [323, 6] torch.int64"];
  "model.layers.9.mlp.shared_experts" [label="DeepseekV2MLP @ model.layers.9.mlp.shared_experts\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.mlp.shared_experts.act_fn" [label="SiLU @ model.layers.9.mlp.shared_experts.act_fn\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.9.mlp.shared_experts.down_proj" [label="Linear @ model.layers.9.mlp.shared_experts.down_proj\nin [1, 323, 1792] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.mlp.shared_experts.gate_proj" [label="Linear @ model.layers.9.mlp.shared_experts.gate_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.9.mlp.shared_experts.up_proj" [label="Linear @ model.layers.9.mlp.shared_experts.up_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1792] torch.bfloat16"];
  "model.layers.9.post_attention_layernorm" [label="DeepseekV2RMSNorm @ model.layers.9.post_attention_layernorm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.self_attn" [label="LlamaFlashAttention2 @ model.layers.9.self_attn\nout [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.self_attn.k_proj" [label="Linear @ model.layers.9.self_attn.k_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.self_attn.o_proj" [label="Linear @ model.layers.9.self_attn.o_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.self_attn.q_proj" [label="Linear @ model.layers.9.self_attn.q_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.layers.9.self_attn.v_proj" [label="Linear @ model.layers.9.self_attn.v_proj\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.norm" [label="DeepseekV2RMSNorm @ model.norm\nin [1, 323, 1280] torch.bfloat16 | out [1, 323, 1280] torch.bfloat16"];
  "model.projector" [label="MlpProjector @ model.projector\nin [9, 25, 2048] torch.float32 | out [9, 25, 1280] torch.bfloat16"];
  "model.projector.layers" [label="Linear @ model.projector.layers\nin [9, 25, 2048] torch.float32 | out [9, 25, 1280] torch.bfloat16"];
  "model.sam_model" [label="ImageEncoderViT @ model.sam_model\nin [9, 3, 320, 320] torch.bfloat16 | out [9, 1024, 5, 5] torch.bfloat16"];
  "model.sam_model.blocks.0" [label="Block @ model.sam_model.blocks.0\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.0.attn" [label="Attention @ model.sam_model.blocks.0.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.0.attn.proj" [label="Linear @ model.sam_model.blocks.0.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.0.attn.qkv" [label="Linear @ model.sam_model.blocks.0.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.0.mlp" [label="MLPBlock @ model.sam_model.blocks.0.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.0.mlp.lin1" [label="Linear @ model.sam_model.blocks.0.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.0.mlp.lin2" [label="Linear @ model.sam_model.blocks.0.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.0.norm1" [label="LayerNorm @ model.sam_model.blocks.0.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.0.norm2" [label="LayerNorm @ model.sam_model.blocks.0.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.1" [label="Block @ model.sam_model.blocks.1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.1.attn" [label="Attention @ model.sam_model.blocks.1.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.1.attn.proj" [label="Linear @ model.sam_model.blocks.1.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.1.attn.qkv" [label="Linear @ model.sam_model.blocks.1.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.1.mlp" [label="MLPBlock @ model.sam_model.blocks.1.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.1.mlp.lin1" [label="Linear @ model.sam_model.blocks.1.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.1.mlp.lin2" [label="Linear @ model.sam_model.blocks.1.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.1.norm1" [label="LayerNorm @ model.sam_model.blocks.1.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.1.norm2" [label="LayerNorm @ model.sam_model.blocks.1.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.10" [label="Block @ model.sam_model.blocks.10\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.10.attn" [label="Attention @ model.sam_model.blocks.10.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.10.attn.proj" [label="Linear @ model.sam_model.blocks.10.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.10.attn.qkv" [label="Linear @ model.sam_model.blocks.10.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.10.mlp" [label="MLPBlock @ model.sam_model.blocks.10.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.10.mlp.lin1" [label="Linear @ model.sam_model.blocks.10.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.10.mlp.lin2" [label="Linear @ model.sam_model.blocks.10.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.10.norm1" [label="LayerNorm @ model.sam_model.blocks.10.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.10.norm2" [label="LayerNorm @ model.sam_model.blocks.10.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.11" [label="Block @ model.sam_model.blocks.11\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.11.attn" [label="Attention @ model.sam_model.blocks.11.attn\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.11.attn.proj" [label="Linear @ model.sam_model.blocks.11.attn.proj\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.11.attn.qkv" [label="Linear @ model.sam_model.blocks.11.attn.qkv\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 2304] torch.bfloat16"];
  "model.sam_model.blocks.11.mlp" [label="MLPBlock @ model.sam_model.blocks.11.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.11.mlp.lin1" [label="Linear @ model.sam_model.blocks.11.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.11.mlp.lin2" [label="Linear @ model.sam_model.blocks.11.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.11.norm1" [label="LayerNorm @ model.sam_model.blocks.11.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.11.norm2" [label="LayerNorm @ model.sam_model.blocks.11.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.2" [label="Block @ model.sam_model.blocks.2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.2.attn" [label="Attention @ model.sam_model.blocks.2.attn\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.2.attn.proj" [label="Linear @ model.sam_model.blocks.2.attn.proj\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.2.attn.qkv" [label="Linear @ model.sam_model.blocks.2.attn.qkv\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 2304] torch.bfloat16"];
  "model.sam_model.blocks.2.mlp" [label="MLPBlock @ model.sam_model.blocks.2.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.2.mlp.lin1" [label="Linear @ model.sam_model.blocks.2.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.2.mlp.lin2" [label="Linear @ model.sam_model.blocks.2.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.2.norm1" [label="LayerNorm @ model.sam_model.blocks.2.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.2.norm2" [label="LayerNorm @ model.sam_model.blocks.2.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.3" [label="Block @ model.sam_model.blocks.3\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.3.attn" [label="Attention @ model.sam_model.blocks.3.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.3.attn.proj" [label="Linear @ model.sam_model.blocks.3.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.3.attn.qkv" [label="Linear @ model.sam_model.blocks.3.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.3.mlp" [label="MLPBlock @ model.sam_model.blocks.3.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.3.mlp.lin1" [label="Linear @ model.sam_model.blocks.3.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.3.mlp.lin2" [label="Linear @ model.sam_model.blocks.3.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.3.norm1" [label="LayerNorm @ model.sam_model.blocks.3.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.3.norm2" [label="LayerNorm @ model.sam_model.blocks.3.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.4" [label="Block @ model.sam_model.blocks.4\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.4.attn" [label="Attention @ model.sam_model.blocks.4.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.4.attn.proj" [label="Linear @ model.sam_model.blocks.4.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.4.attn.qkv" [label="Linear @ model.sam_model.blocks.4.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.4.mlp" [label="MLPBlock @ model.sam_model.blocks.4.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.4.mlp.lin1" [label="Linear @ model.sam_model.blocks.4.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.4.mlp.lin2" [label="Linear @ model.sam_model.blocks.4.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.4.norm1" [label="LayerNorm @ model.sam_model.blocks.4.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.4.norm2" [label="LayerNorm @ model.sam_model.blocks.4.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.5" [label="Block @ model.sam_model.blocks.5\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.5.attn" [label="Attention @ model.sam_model.blocks.5.attn\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.5.attn.proj" [label="Linear @ model.sam_model.blocks.5.attn.proj\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.5.attn.qkv" [label="Linear @ model.sam_model.blocks.5.attn.qkv\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 2304] torch.bfloat16"];
  "model.sam_model.blocks.5.mlp" [label="MLPBlock @ model.sam_model.blocks.5.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.5.mlp.lin1" [label="Linear @ model.sam_model.blocks.5.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.5.mlp.lin2" [label="Linear @ model.sam_model.blocks.5.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.5.norm1" [label="LayerNorm @ model.sam_model.blocks.5.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.5.norm2" [label="LayerNorm @ model.sam_model.blocks.5.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.6" [label="Block @ model.sam_model.blocks.6\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.6.attn" [label="Attention @ model.sam_model.blocks.6.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.6.attn.proj" [label="Linear @ model.sam_model.blocks.6.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.6.attn.qkv" [label="Linear @ model.sam_model.blocks.6.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.6.mlp" [label="MLPBlock @ model.sam_model.blocks.6.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.6.mlp.lin1" [label="Linear @ model.sam_model.blocks.6.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.6.mlp.lin2" [label="Linear @ model.sam_model.blocks.6.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.6.norm1" [label="LayerNorm @ model.sam_model.blocks.6.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.6.norm2" [label="LayerNorm @ model.sam_model.blocks.6.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.7" [label="Block @ model.sam_model.blocks.7\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.7.attn" [label="Attention @ model.sam_model.blocks.7.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.7.attn.proj" [label="Linear @ model.sam_model.blocks.7.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.7.attn.qkv" [label="Linear @ model.sam_model.blocks.7.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.7.mlp" [label="MLPBlock @ model.sam_model.blocks.7.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.7.mlp.lin1" [label="Linear @ model.sam_model.blocks.7.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.7.mlp.lin2" [label="Linear @ model.sam_model.blocks.7.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.7.norm1" [label="LayerNorm @ model.sam_model.blocks.7.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.7.norm2" [label="LayerNorm @ model.sam_model.blocks.7.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.8" [label="Block @ model.sam_model.blocks.8\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.8.attn" [label="Attention @ model.sam_model.blocks.8.attn\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.8.attn.proj" [label="Linear @ model.sam_model.blocks.8.attn.proj\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.8.attn.qkv" [label="Linear @ model.sam_model.blocks.8.attn.qkv\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 2304] torch.bfloat16"];
  "model.sam_model.blocks.8.mlp" [label="MLPBlock @ model.sam_model.blocks.8.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.8.mlp.lin1" [label="Linear @ model.sam_model.blocks.8.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.8.mlp.lin2" [label="Linear @ model.sam_model.blocks.8.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.8.norm1" [label="LayerNorm @ model.sam_model.blocks.8.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.8.norm2" [label="LayerNorm @ model.sam_model.blocks.8.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.9" [label="Block @ model.sam_model.blocks.9\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.9.attn" [label="Attention @ model.sam_model.blocks.9.attn\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.9.attn.proj" [label="Linear @ model.sam_model.blocks.9.attn.proj\nin [36, 14, 14, 768] torch.bfloat16 | out [36, 14, 14, 768] torch.bfloat16"];
  "model.sam_model.blocks.9.attn.qkv" [label="Linear @ model.sam_model.blocks.9.attn.qkv\nin [36, 14, 14, 768] torch.float32 | out [36, 14, 14, 2304] torch.bfloat16"];
  "model.sam_model.blocks.9.mlp" [label="MLPBlock @ model.sam_model.blocks.9.mlp\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.9.mlp.lin1" [label="Linear @ model.sam_model.blocks.9.mlp.lin1\nin [9, 20, 20, 768] torch.float32 | out [9, 20, 20, 3072] torch.bfloat16"];
  "model.sam_model.blocks.9.mlp.lin2" [label="Linear @ model.sam_model.blocks.9.mlp.lin2\nin [9, 20, 20, 3072] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.blocks.9.norm1" [label="LayerNorm @ model.sam_model.blocks.9.norm1\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.blocks.9.norm2" [label="LayerNorm @ model.sam_model.blocks.9.norm2\nin [9, 20, 20, 768] torch.bfloat16 | out [9, 20, 20, 768] torch.float32"];
  "model.sam_model.neck" [label="Sequential @ model.sam_model.neck\nin [9, 768, 20, 20] torch.bfloat16 | out [9, 256, 20, 20] torch.float32"];
  "model.sam_model.neck.0" [label="Conv2d @ model.sam_model.neck.0\nin [9, 768, 20, 20] torch.bfloat16 | out [9, 256, 20, 20] torch.bfloat16"];
  "model.sam_model.neck.1" [label="LayerNorm2d @ model.sam_model.neck.1\nin [9, 256, 20, 20] torch.bfloat16 | out [9, 256, 20, 20] torch.float32"];
  "model.sam_model.neck.2" [label="Conv2d @ model.sam_model.neck.2\nin [9, 256, 20, 20] torch.float32 | out [9, 256, 20, 20] torch.bfloat16"];
  "model.sam_model.neck.3" [label="LayerNorm2d @ model.sam_model.neck.3\nin [9, 256, 20, 20] torch.bfloat16 | out [9, 256, 20, 20] torch.float32"];
  "model.sam_model.net_2" [label="Conv2d @ model.sam_model.net_2\nin [9, 256, 20, 20] torch.float32 | out [9, 512, 10, 10] torch.bfloat16"];
  "model.sam_model.net_3" [label="Conv2d @ model.sam_model.net_3\nin [9, 512, 10, 10] torch.bfloat16 | out [9, 1024, 5, 5] torch.bfloat16"];
  "model.sam_model.patch_embed" [label="PatchEmbed @ model.sam_model.patch_embed\nin [9, 3, 320, 320] torch.bfloat16 | out [9, 20, 20, 768] torch.bfloat16"];
  "model.sam_model.patch_embed.proj" [label="Conv2d @ model.sam_model.patch_embed.proj\nin [9, 3, 320, 320] torch.bfloat16 | out [9, 768, 20, 20] torch.bfloat16"];
  "model.vision_model" [label="VitModel @ model.vision_model\nin [9, 3, 320, 320] torch.bfloat16 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.embeddings" [label="CLIPVisionEmbeddings @ model.vision_model.embeddings\nin [9, 3, 320, 320] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.embeddings.position_embedding" [label="Embedding @ model.vision_model.embeddings.position_embedding\nin [1, 257] torch.int64 | out [1, 257, 1024] torch.bfloat16"];
  "model.vision_model.pre_layrnorm" [label="LayerNorm @ model.vision_model.pre_layrnorm\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer" [label="NoTPTransformer @ model.vision_model.transformer\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.0" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.0\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.0.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.0.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.0.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.0.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.0.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.0.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.0.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.0.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.0.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.0.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.0.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.0.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.1" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.1.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.1.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.1.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.1.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.1.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.1.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.1.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.1.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.1.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.1.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.1.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.1.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.10" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.10\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.10.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.10.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.10.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.10.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.10.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.10.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.10.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.10.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.10.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.10.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.10.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.10.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.11" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.11\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.11.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.11.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.11.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.11.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.11.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.11.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.11.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.11.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.11.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.11.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.11.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.11.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.12" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.12\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.12.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.12.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.12.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.12.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.12.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.12.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.12.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.12.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.12.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.12.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.12.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.12.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.13" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.13\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.13.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.13.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.13.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.13.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.13.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.13.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.13.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.13.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.13.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.13.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.13.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.13.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.14" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.14\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.14.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.14.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.14.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.14.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.14.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.14.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.14.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.14.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.14.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.14.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.14.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.14.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.15" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.15\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.15.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.15.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.15.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.15.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.15.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.15.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.15.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.15.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.15.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.15.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.15.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.15.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.16" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.16\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.16.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.16.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.16.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.16.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.16.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.16.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.16.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.16.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.16.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.16.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.16.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.16.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.17" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.17\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.17.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.17.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.17.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.17.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.17.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.17.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.17.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.17.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.17.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.17.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.17.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.17.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.18" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.18\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.18.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.18.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.18.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.18.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.18.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.18.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.18.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.18.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.18.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.18.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.18.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.18.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.19" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.19\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.19.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.19.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.19.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.19.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.19.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.19.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.19.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.19.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.19.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.19.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.19.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.19.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.2" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.2.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.2.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.2.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.2.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.2.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.2.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.2.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.2.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.2.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.2.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.2.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.2.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.20" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.20\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.20.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.20.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.20.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.20.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.20.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.20.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.20.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.20.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.20.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.20.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.20.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.20.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.21" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.21\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.21.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.21.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.21.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.21.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.21.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.21.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.21.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.21.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.21.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.21.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.21.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.21.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.22" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.22\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.22.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.22.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.22.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.22.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.22.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.22.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.22.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.22.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.22.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.22.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.22.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.22.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.23" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.23\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.23.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.23.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.23.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.23.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.23.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.23.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.23.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.23.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.23.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.23.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.23.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.23.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.3" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.3\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.3.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.3.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.3.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.3.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.3.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.3.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.3.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.3.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.3.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.3.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.3.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.3.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.4" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.4\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.4.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.4.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.4.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.4.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.4.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.4.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.4.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.4.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.4.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.4.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.4.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.4.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.5" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.5\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.5.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.5.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.5.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.5.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.5.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.5.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.5.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.5.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.5.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.5.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.5.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.5.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.6" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.6\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.6.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.6.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.6.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.6.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.6.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.6.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.6.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.6.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.6.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.6.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.6.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.6.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.7" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.7\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.7.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.7.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.7.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.7.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.7.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.7.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.7.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.7.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.7.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.7.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.7.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.7.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.8" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.8\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.8.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.8.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.8.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.8.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.8.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.8.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.8.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.8.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.8.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.8.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.8.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.8.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model.vision_model.transformer.layers.9" [label="NoTPTransformerBlock @ model.vision_model.transformer.layers.9\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.9.layer_norm1" [label="LayerNorm @ model.vision_model.transformer.layers.9.layer_norm1\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.9.layer_norm2" [label="LayerNorm @ model.vision_model.transformer.layers.9.layer_norm2\nin [9, 26, 1024] torch.float32 | out [9, 26, 1024] torch.float32"];
  "model.vision_model.transformer.layers.9.mlp.fc1" [label="Linear @ model.vision_model.transformer.layers.9.mlp.fc1\nin [9, 26, 1024] torch.float32 | out [9, 26, 4096] torch.bfloat16"];
  "model.vision_model.transformer.layers.9.mlp.fc2" [label="Linear @ model.vision_model.transformer.layers.9.mlp.fc2\nin [9, 26, 4096] torch.float32 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.9.self_attn.out_proj" [label="Linear @ model.vision_model.transformer.layers.9.self_attn.out_proj\nin [9, 26, 1024] torch.bfloat16 | out [9, 26, 1024] torch.bfloat16"];
  "model.vision_model.transformer.layers.9.self_attn.qkv_proj" [label="Linear @ model.vision_model.transformer.layers.9.self_attn.qkv_proj\nin [9, 26, 1024] torch.float32 | out [9, 26, 3072] torch.bfloat16"];
  "model" -> "model.embed_tokens" [label="1"];
  "model" -> "model.sam_model" [label="2"];
  "model.sam_model" -> "model.sam_model.patch_embed" [label="2"];
  "model.sam_model.patch_embed" -> "model.sam_model.patch_embed.proj" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.0" [label="2"];
  "model.sam_model.blocks.0" -> "model.sam_model.blocks.0.norm1" [label="2"];
  "model.sam_model.blocks.0" -> "model.sam_model.blocks.0.attn" [label="2"];
  "model.sam_model.blocks.0.attn" -> "model.sam_model.blocks.0.attn.qkv" [label="2"];
  "model.sam_model.blocks.0.attn" -> "model.sam_model.blocks.0.attn.proj" [label="2"];
  "model.sam_model.blocks.0" -> "model.sam_model.blocks.0.norm2" [label="2"];
  "model.sam_model.blocks.0" -> "model.sam_model.blocks.0.mlp" [label="2"];
  "model.sam_model.blocks.0.mlp" -> "model.sam_model.blocks.0.mlp.lin1" [label="2"];
  "model.sam_model.blocks.0.mlp" -> "model.sam_model.blocks.0.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.1" [label="2"];
  "model.sam_model.blocks.1" -> "model.sam_model.blocks.1.norm1" [label="2"];
  "model.sam_model.blocks.1" -> "model.sam_model.blocks.1.attn" [label="2"];
  "model.sam_model.blocks.1.attn" -> "model.sam_model.blocks.1.attn.qkv" [label="2"];
  "model.sam_model.blocks.1.attn" -> "model.sam_model.blocks.1.attn.proj" [label="2"];
  "model.sam_model.blocks.1" -> "model.sam_model.blocks.1.norm2" [label="2"];
  "model.sam_model.blocks.1" -> "model.sam_model.blocks.1.mlp" [label="2"];
  "model.sam_model.blocks.1.mlp" -> "model.sam_model.blocks.1.mlp.lin1" [label="2"];
  "model.sam_model.blocks.1.mlp" -> "model.sam_model.blocks.1.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.2" [label="2"];
  "model.sam_model.blocks.2" -> "model.sam_model.blocks.2.norm1" [label="2"];
  "model.sam_model.blocks.2" -> "model.sam_model.blocks.2.attn" [label="2"];
  "model.sam_model.blocks.2.attn" -> "model.sam_model.blocks.2.attn.qkv" [label="2"];
  "model.sam_model.blocks.2.attn" -> "model.sam_model.blocks.2.attn.proj" [label="2"];
  "model.sam_model.blocks.2" -> "model.sam_model.blocks.2.norm2" [label="2"];
  "model.sam_model.blocks.2" -> "model.sam_model.blocks.2.mlp" [label="2"];
  "model.sam_model.blocks.2.mlp" -> "model.sam_model.blocks.2.mlp.lin1" [label="2"];
  "model.sam_model.blocks.2.mlp" -> "model.sam_model.blocks.2.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.3" [label="2"];
  "model.sam_model.blocks.3" -> "model.sam_model.blocks.3.norm1" [label="2"];
  "model.sam_model.blocks.3" -> "model.sam_model.blocks.3.attn" [label="2"];
  "model.sam_model.blocks.3.attn" -> "model.sam_model.blocks.3.attn.qkv" [label="2"];
  "model.sam_model.blocks.3.attn" -> "model.sam_model.blocks.3.attn.proj" [label="2"];
  "model.sam_model.blocks.3" -> "model.sam_model.blocks.3.norm2" [label="2"];
  "model.sam_model.blocks.3" -> "model.sam_model.blocks.3.mlp" [label="2"];
  "model.sam_model.blocks.3.mlp" -> "model.sam_model.blocks.3.mlp.lin1" [label="2"];
  "model.sam_model.blocks.3.mlp" -> "model.sam_model.blocks.3.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.4" [label="2"];
  "model.sam_model.blocks.4" -> "model.sam_model.blocks.4.norm1" [label="2"];
  "model.sam_model.blocks.4" -> "model.sam_model.blocks.4.attn" [label="2"];
  "model.sam_model.blocks.4.attn" -> "model.sam_model.blocks.4.attn.qkv" [label="2"];
  "model.sam_model.blocks.4.attn" -> "model.sam_model.blocks.4.attn.proj" [label="2"];
  "model.sam_model.blocks.4" -> "model.sam_model.blocks.4.norm2" [label="2"];
  "model.sam_model.blocks.4" -> "model.sam_model.blocks.4.mlp" [label="2"];
  "model.sam_model.blocks.4.mlp" -> "model.sam_model.blocks.4.mlp.lin1" [label="2"];
  "model.sam_model.blocks.4.mlp" -> "model.sam_model.blocks.4.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.5" [label="2"];
  "model.sam_model.blocks.5" -> "model.sam_model.blocks.5.norm1" [label="2"];
  "model.sam_model.blocks.5" -> "model.sam_model.blocks.5.attn" [label="2"];
  "model.sam_model.blocks.5.attn" -> "model.sam_model.blocks.5.attn.qkv" [label="2"];
  "model.sam_model.blocks.5.attn" -> "model.sam_model.blocks.5.attn.proj" [label="2"];
  "model.sam_model.blocks.5" -> "model.sam_model.blocks.5.norm2" [label="2"];
  "model.sam_model.blocks.5" -> "model.sam_model.blocks.5.mlp" [label="2"];
  "model.sam_model.blocks.5.mlp" -> "model.sam_model.blocks.5.mlp.lin1" [label="2"];
  "model.sam_model.blocks.5.mlp" -> "model.sam_model.blocks.5.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.6" [label="2"];
  "model.sam_model.blocks.6" -> "model.sam_model.blocks.6.norm1" [label="2"];
  "model.sam_model.blocks.6" -> "model.sam_model.blocks.6.attn" [label="2"];
  "model.sam_model.blocks.6.attn" -> "model.sam_model.blocks.6.attn.qkv" [label="2"];
  "model.sam_model.blocks.6.attn" -> "model.sam_model.blocks.6.attn.proj" [label="2"];
  "model.sam_model.blocks.6" -> "model.sam_model.blocks.6.norm2" [label="2"];
  "model.sam_model.blocks.6" -> "model.sam_model.blocks.6.mlp" [label="2"];
  "model.sam_model.blocks.6.mlp" -> "model.sam_model.blocks.6.mlp.lin1" [label="2"];
  "model.sam_model.blocks.6.mlp" -> "model.sam_model.blocks.6.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.7" [label="2"];
  "model.sam_model.blocks.7" -> "model.sam_model.blocks.7.norm1" [label="2"];
  "model.sam_model.blocks.7" -> "model.sam_model.blocks.7.attn" [label="2"];
  "model.sam_model.blocks.7.attn" -> "model.sam_model.blocks.7.attn.qkv" [label="2"];
  "model.sam_model.blocks.7.attn" -> "model.sam_model.blocks.7.attn.proj" [label="2"];
  "model.sam_model.blocks.7" -> "model.sam_model.blocks.7.norm2" [label="2"];
  "model.sam_model.blocks.7" -> "model.sam_model.blocks.7.mlp" [label="2"];
  "model.sam_model.blocks.7.mlp" -> "model.sam_model.blocks.7.mlp.lin1" [label="2"];
  "model.sam_model.blocks.7.mlp" -> "model.sam_model.blocks.7.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.8" [label="2"];
  "model.sam_model.blocks.8" -> "model.sam_model.blocks.8.norm1" [label="2"];
  "model.sam_model.blocks.8" -> "model.sam_model.blocks.8.attn" [label="2"];
  "model.sam_model.blocks.8.attn" -> "model.sam_model.blocks.8.attn.qkv" [label="2"];
  "model.sam_model.blocks.8.attn" -> "model.sam_model.blocks.8.attn.proj" [label="2"];
  "model.sam_model.blocks.8" -> "model.sam_model.blocks.8.norm2" [label="2"];
  "model.sam_model.blocks.8" -> "model.sam_model.blocks.8.mlp" [label="2"];
  "model.sam_model.blocks.8.mlp" -> "model.sam_model.blocks.8.mlp.lin1" [label="2"];
  "model.sam_model.blocks.8.mlp" -> "model.sam_model.blocks.8.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.9" [label="2"];
  "model.sam_model.blocks.9" -> "model.sam_model.blocks.9.norm1" [label="2"];
  "model.sam_model.blocks.9" -> "model.sam_model.blocks.9.attn" [label="2"];
  "model.sam_model.blocks.9.attn" -> "model.sam_model.blocks.9.attn.qkv" [label="2"];
  "model.sam_model.blocks.9.attn" -> "model.sam_model.blocks.9.attn.proj" [label="2"];
  "model.sam_model.blocks.9" -> "model.sam_model.blocks.9.norm2" [label="2"];
  "model.sam_model.blocks.9" -> "model.sam_model.blocks.9.mlp" [label="2"];
  "model.sam_model.blocks.9.mlp" -> "model.sam_model.blocks.9.mlp.lin1" [label="2"];
  "model.sam_model.blocks.9.mlp" -> "model.sam_model.blocks.9.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.10" [label="2"];
  "model.sam_model.blocks.10" -> "model.sam_model.blocks.10.norm1" [label="2"];
  "model.sam_model.blocks.10" -> "model.sam_model.blocks.10.attn" [label="2"];
  "model.sam_model.blocks.10.attn" -> "model.sam_model.blocks.10.attn.qkv" [label="2"];
  "model.sam_model.blocks.10.attn" -> "model.sam_model.blocks.10.attn.proj" [label="2"];
  "model.sam_model.blocks.10" -> "model.sam_model.blocks.10.norm2" [label="2"];
  "model.sam_model.blocks.10" -> "model.sam_model.blocks.10.mlp" [label="2"];
  "model.sam_model.blocks.10.mlp" -> "model.sam_model.blocks.10.mlp.lin1" [label="2"];
  "model.sam_model.blocks.10.mlp" -> "model.sam_model.blocks.10.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.blocks.11" [label="2"];
  "model.sam_model.blocks.11" -> "model.sam_model.blocks.11.norm1" [label="2"];
  "model.sam_model.blocks.11" -> "model.sam_model.blocks.11.attn" [label="2"];
  "model.sam_model.blocks.11.attn" -> "model.sam_model.blocks.11.attn.qkv" [label="2"];
  "model.sam_model.blocks.11.attn" -> "model.sam_model.blocks.11.attn.proj" [label="2"];
  "model.sam_model.blocks.11" -> "model.sam_model.blocks.11.norm2" [label="2"];
  "model.sam_model.blocks.11" -> "model.sam_model.blocks.11.mlp" [label="2"];
  "model.sam_model.blocks.11.mlp" -> "model.sam_model.blocks.11.mlp.lin1" [label="2"];
  "model.sam_model.blocks.11.mlp" -> "model.sam_model.blocks.11.mlp.lin2" [label="2"];
  "model.sam_model" -> "model.sam_model.neck" [label="2"];
  "model.sam_model.neck" -> "model.sam_model.neck.0" [label="2"];
  "model.sam_model.neck" -> "model.sam_model.neck.1" [label="2"];
  "model.sam_model.neck" -> "model.sam_model.neck.2" [label="2"];
  "model.sam_model.neck" -> "model.sam_model.neck.3" [label="2"];
  "model.sam_model" -> "model.sam_model.net_2" [label="2"];
  "model.sam_model" -> "model.sam_model.net_3" [label="2"];
  "model" -> "model.vision_model" [label="2"];
  "model.vision_model" -> "model.vision_model.embeddings" [label="2"];
  "model.vision_model.embeddings" -> "model.vision_model.embeddings.position_embedding" [label="2"];
  "model.vision_model" -> "model.vision_model.pre_layrnorm" [label="2"];
  "model.vision_model" -> "model.vision_model.transformer" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.0" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.0" -> "model.vision_model.transformer.layers.0.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.1" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.1" -> "model.vision_model.transformer.layers.1.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.2" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.2" -> "model.vision_model.transformer.layers.2.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.3" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.3" -> "model.vision_model.transformer.layers.3.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.4" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.4" -> "model.vision_model.transformer.layers.4.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.5" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.5" -> "model.vision_model.transformer.layers.5.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.6" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.6" -> "model.vision_model.transformer.layers.6.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.7" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.7" -> "model.vision_model.transformer.layers.7.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.8" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.8" -> "model.vision_model.transformer.layers.8.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.9" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.9" -> "model.vision_model.transformer.layers.9.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.10" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.10" -> "model.vision_model.transformer.layers.10.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.11" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.11" -> "model.vision_model.transformer.layers.11.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.12" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.12" -> "model.vision_model.transformer.layers.12.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.13" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.13" -> "model.vision_model.transformer.layers.13.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.14" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.14" -> "model.vision_model.transformer.layers.14.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.15" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.15" -> "model.vision_model.transformer.layers.15.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.16" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.16" -> "model.vision_model.transformer.layers.16.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.17" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.17" -> "model.vision_model.transformer.layers.17.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.18" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.18" -> "model.vision_model.transformer.layers.18.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.19" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.19" -> "model.vision_model.transformer.layers.19.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.20" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.20" -> "model.vision_model.transformer.layers.20.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.21" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.21" -> "model.vision_model.transformer.layers.21.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.22" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.22" -> "model.vision_model.transformer.layers.22.mlp.fc2" [label="2"];
  "model.vision_model.transformer" -> "model.vision_model.transformer.layers.23" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.layer_norm1" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.self_attn.qkv_proj" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.self_attn.out_proj" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.layer_norm2" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.mlp.fc1" [label="2"];
  "model.vision_model.transformer.layers.23" -> "model.vision_model.transformer.layers.23.mlp.fc2" [label="2"];
  "model" -> "model.projector" [label="2"];
  "model.projector" -> "model.projector.layers" [label="2"];
  "model" -> "model.layers.0" [label="1"];
  "model.layers.0" -> "model.layers.0.input_layernorm" [label="1"];
  "model.layers.0" -> "model.layers.0.self_attn" [label="1"];
  "model.layers.0.self_attn" -> "model.layers.0.self_attn.q_proj" [label="1"];
  "model.layers.0.self_attn" -> "model.layers.0.self_attn.k_proj" [label="1"];
  "model.layers.0.self_attn" -> "model.layers.0.self_attn.v_proj" [label="1"];
  "model.layers.0.self_attn" -> "model.layers.0.self_attn.o_proj" [label="1"];
  "model.layers.0" -> "model.layers.0.post_attention_layernorm" [label="1"];
  "model.layers.0" -> "model.layers.0.mlp" [label="1"];
  "model.layers.0.mlp" -> "model.layers.0.mlp.gate_proj" [label="1"];
  "model.layers.0.mlp" -> "model.layers.0.mlp.act_fn" [label="1"];
  "model.layers.0.mlp" -> "model.layers.0.mlp.up_proj" [label="1"];
  "model.layers.0.mlp" -> "model.layers.0.mlp.down_proj" [label="1"];
  "model" -> "model.layers.1" [label="1"];
  "model.layers.1" -> "model.layers.1.input_layernorm" [label="1"];
  "model.layers.1" -> "model.layers.1.self_attn" [label="1"];
  "model.layers.1.self_attn" -> "model.layers.1.self_attn.q_proj" [label="1"];
  "model.layers.1.self_attn" -> "model.layers.1.self_attn.k_proj" [label="1"];
  "model.layers.1.self_attn" -> "model.layers.1.self_attn.v_proj" [label="1"];
  "model.layers.1.self_attn" -> "model.layers.1.self_attn.o_proj" [label="1"];
  "model.layers.1" -> "model.layers.1.post_attention_layernorm" [label="1"];
  "model.layers.1" -> "model.layers.1.mlp" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.gate" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.0" [label="1"];
  "model.layers.1.mlp.experts.0" -> "model.layers.1.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.0" -> "model.layers.1.mlp.experts.0.act_fn" [label="1"];
  "model.layers.1.mlp.experts.0" -> "model.layers.1.mlp.experts.0.up_proj" [label="1"];
  "model.layers.1.mlp.experts.0" -> "model.layers.1.mlp.experts.0.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.1" [label="1"];
  "model.layers.1.mlp.experts.1" -> "model.layers.1.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.1" -> "model.layers.1.mlp.experts.1.act_fn" [label="1"];
  "model.layers.1.mlp.experts.1" -> "model.layers.1.mlp.experts.1.up_proj" [label="1"];
  "model.layers.1.mlp.experts.1" -> "model.layers.1.mlp.experts.1.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.2" [label="1"];
  "model.layers.1.mlp.experts.2" -> "model.layers.1.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.2" -> "model.layers.1.mlp.experts.2.act_fn" [label="1"];
  "model.layers.1.mlp.experts.2" -> "model.layers.1.mlp.experts.2.up_proj" [label="1"];
  "model.layers.1.mlp.experts.2" -> "model.layers.1.mlp.experts.2.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.3" [label="1"];
  "model.layers.1.mlp.experts.3" -> "model.layers.1.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.3" -> "model.layers.1.mlp.experts.3.act_fn" [label="1"];
  "model.layers.1.mlp.experts.3" -> "model.layers.1.mlp.experts.3.up_proj" [label="1"];
  "model.layers.1.mlp.experts.3" -> "model.layers.1.mlp.experts.3.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.4" [label="1"];
  "model.layers.1.mlp.experts.4" -> "model.layers.1.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.4" -> "model.layers.1.mlp.experts.4.act_fn" [label="1"];
  "model.layers.1.mlp.experts.4" -> "model.layers.1.mlp.experts.4.up_proj" [label="1"];
  "model.layers.1.mlp.experts.4" -> "model.layers.1.mlp.experts.4.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.5" [label="1"];
  "model.layers.1.mlp.experts.5" -> "model.layers.1.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.5" -> "model.layers.1.mlp.experts.5.act_fn" [label="1"];
  "model.layers.1.mlp.experts.5" -> "model.layers.1.mlp.experts.5.up_proj" [label="1"];
  "model.layers.1.mlp.experts.5" -> "model.layers.1.mlp.experts.5.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.6" [label="1"];
  "model.layers.1.mlp.experts.6" -> "model.layers.1.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.6" -> "model.layers.1.mlp.experts.6.act_fn" [label="1"];
  "model.layers.1.mlp.experts.6" -> "model.layers.1.mlp.experts.6.up_proj" [label="1"];
  "model.layers.1.mlp.experts.6" -> "model.layers.1.mlp.experts.6.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.7" [label="1"];
  "model.layers.1.mlp.experts.7" -> "model.layers.1.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.7" -> "model.layers.1.mlp.experts.7.act_fn" [label="1"];
  "model.layers.1.mlp.experts.7" -> "model.layers.1.mlp.experts.7.up_proj" [label="1"];
  "model.layers.1.mlp.experts.7" -> "model.layers.1.mlp.experts.7.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.8" [label="1"];
  "model.layers.1.mlp.experts.8" -> "model.layers.1.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.8" -> "model.layers.1.mlp.experts.8.act_fn" [label="1"];
  "model.layers.1.mlp.experts.8" -> "model.layers.1.mlp.experts.8.up_proj" [label="1"];
  "model.layers.1.mlp.experts.8" -> "model.layers.1.mlp.experts.8.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.9" [label="1"];
  "model.layers.1.mlp.experts.9" -> "model.layers.1.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.9" -> "model.layers.1.mlp.experts.9.act_fn" [label="1"];
  "model.layers.1.mlp.experts.9" -> "model.layers.1.mlp.experts.9.up_proj" [label="1"];
  "model.layers.1.mlp.experts.9" -> "model.layers.1.mlp.experts.9.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.10" [label="1"];
  "model.layers.1.mlp.experts.10" -> "model.layers.1.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.10" -> "model.layers.1.mlp.experts.10.act_fn" [label="1"];
  "model.layers.1.mlp.experts.10" -> "model.layers.1.mlp.experts.10.up_proj" [label="1"];
  "model.layers.1.mlp.experts.10" -> "model.layers.1.mlp.experts.10.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.11" [label="1"];
  "model.layers.1.mlp.experts.11" -> "model.layers.1.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.11" -> "model.layers.1.mlp.experts.11.act_fn" [label="1"];
  "model.layers.1.mlp.experts.11" -> "model.layers.1.mlp.experts.11.up_proj" [label="1"];
  "model.layers.1.mlp.experts.11" -> "model.layers.1.mlp.experts.11.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.12" [label="1"];
  "model.layers.1.mlp.experts.12" -> "model.layers.1.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.12" -> "model.layers.1.mlp.experts.12.act_fn" [label="1"];
  "model.layers.1.mlp.experts.12" -> "model.layers.1.mlp.experts.12.up_proj" [label="1"];
  "model.layers.1.mlp.experts.12" -> "model.layers.1.mlp.experts.12.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.14" [label="1"];
  "model.layers.1.mlp.experts.14" -> "model.layers.1.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.14" -> "model.layers.1.mlp.experts.14.act_fn" [label="1"];
  "model.layers.1.mlp.experts.14" -> "model.layers.1.mlp.experts.14.up_proj" [label="1"];
  "model.layers.1.mlp.experts.14" -> "model.layers.1.mlp.experts.14.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.15" [label="1"];
  "model.layers.1.mlp.experts.15" -> "model.layers.1.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.15" -> "model.layers.1.mlp.experts.15.act_fn" [label="1"];
  "model.layers.1.mlp.experts.15" -> "model.layers.1.mlp.experts.15.up_proj" [label="1"];
  "model.layers.1.mlp.experts.15" -> "model.layers.1.mlp.experts.15.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.16" [label="1"];
  "model.layers.1.mlp.experts.16" -> "model.layers.1.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.16" -> "model.layers.1.mlp.experts.16.act_fn" [label="1"];
  "model.layers.1.mlp.experts.16" -> "model.layers.1.mlp.experts.16.up_proj" [label="1"];
  "model.layers.1.mlp.experts.16" -> "model.layers.1.mlp.experts.16.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.17" [label="1"];
  "model.layers.1.mlp.experts.17" -> "model.layers.1.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.17" -> "model.layers.1.mlp.experts.17.act_fn" [label="1"];
  "model.layers.1.mlp.experts.17" -> "model.layers.1.mlp.experts.17.up_proj" [label="1"];
  "model.layers.1.mlp.experts.17" -> "model.layers.1.mlp.experts.17.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.18" [label="1"];
  "model.layers.1.mlp.experts.18" -> "model.layers.1.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.18" -> "model.layers.1.mlp.experts.18.act_fn" [label="1"];
  "model.layers.1.mlp.experts.18" -> "model.layers.1.mlp.experts.18.up_proj" [label="1"];
  "model.layers.1.mlp.experts.18" -> "model.layers.1.mlp.experts.18.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.19" [label="1"];
  "model.layers.1.mlp.experts.19" -> "model.layers.1.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.19" -> "model.layers.1.mlp.experts.19.act_fn" [label="1"];
  "model.layers.1.mlp.experts.19" -> "model.layers.1.mlp.experts.19.up_proj" [label="1"];
  "model.layers.1.mlp.experts.19" -> "model.layers.1.mlp.experts.19.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.20" [label="1"];
  "model.layers.1.mlp.experts.20" -> "model.layers.1.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.20" -> "model.layers.1.mlp.experts.20.act_fn" [label="1"];
  "model.layers.1.mlp.experts.20" -> "model.layers.1.mlp.experts.20.up_proj" [label="1"];
  "model.layers.1.mlp.experts.20" -> "model.layers.1.mlp.experts.20.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.21" [label="1"];
  "model.layers.1.mlp.experts.21" -> "model.layers.1.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.21" -> "model.layers.1.mlp.experts.21.act_fn" [label="1"];
  "model.layers.1.mlp.experts.21" -> "model.layers.1.mlp.experts.21.up_proj" [label="1"];
  "model.layers.1.mlp.experts.21" -> "model.layers.1.mlp.experts.21.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.22" [label="1"];
  "model.layers.1.mlp.experts.22" -> "model.layers.1.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.22" -> "model.layers.1.mlp.experts.22.act_fn" [label="1"];
  "model.layers.1.mlp.experts.22" -> "model.layers.1.mlp.experts.22.up_proj" [label="1"];
  "model.layers.1.mlp.experts.22" -> "model.layers.1.mlp.experts.22.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.23" [label="1"];
  "model.layers.1.mlp.experts.23" -> "model.layers.1.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.23" -> "model.layers.1.mlp.experts.23.act_fn" [label="1"];
  "model.layers.1.mlp.experts.23" -> "model.layers.1.mlp.experts.23.up_proj" [label="1"];
  "model.layers.1.mlp.experts.23" -> "model.layers.1.mlp.experts.23.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.24" [label="1"];
  "model.layers.1.mlp.experts.24" -> "model.layers.1.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.24" -> "model.layers.1.mlp.experts.24.act_fn" [label="1"];
  "model.layers.1.mlp.experts.24" -> "model.layers.1.mlp.experts.24.up_proj" [label="1"];
  "model.layers.1.mlp.experts.24" -> "model.layers.1.mlp.experts.24.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.25" [label="1"];
  "model.layers.1.mlp.experts.25" -> "model.layers.1.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.25" -> "model.layers.1.mlp.experts.25.act_fn" [label="1"];
  "model.layers.1.mlp.experts.25" -> "model.layers.1.mlp.experts.25.up_proj" [label="1"];
  "model.layers.1.mlp.experts.25" -> "model.layers.1.mlp.experts.25.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.27" [label="1"];
  "model.layers.1.mlp.experts.27" -> "model.layers.1.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.27" -> "model.layers.1.mlp.experts.27.act_fn" [label="1"];
  "model.layers.1.mlp.experts.27" -> "model.layers.1.mlp.experts.27.up_proj" [label="1"];
  "model.layers.1.mlp.experts.27" -> "model.layers.1.mlp.experts.27.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.28" [label="1"];
  "model.layers.1.mlp.experts.28" -> "model.layers.1.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.28" -> "model.layers.1.mlp.experts.28.act_fn" [label="1"];
  "model.layers.1.mlp.experts.28" -> "model.layers.1.mlp.experts.28.up_proj" [label="1"];
  "model.layers.1.mlp.experts.28" -> "model.layers.1.mlp.experts.28.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.29" [label="1"];
  "model.layers.1.mlp.experts.29" -> "model.layers.1.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.29" -> "model.layers.1.mlp.experts.29.act_fn" [label="1"];
  "model.layers.1.mlp.experts.29" -> "model.layers.1.mlp.experts.29.up_proj" [label="1"];
  "model.layers.1.mlp.experts.29" -> "model.layers.1.mlp.experts.29.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.30" [label="1"];
  "model.layers.1.mlp.experts.30" -> "model.layers.1.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.30" -> "model.layers.1.mlp.experts.30.act_fn" [label="1"];
  "model.layers.1.mlp.experts.30" -> "model.layers.1.mlp.experts.30.up_proj" [label="1"];
  "model.layers.1.mlp.experts.30" -> "model.layers.1.mlp.experts.30.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.31" [label="1"];
  "model.layers.1.mlp.experts.31" -> "model.layers.1.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.31" -> "model.layers.1.mlp.experts.31.act_fn" [label="1"];
  "model.layers.1.mlp.experts.31" -> "model.layers.1.mlp.experts.31.up_proj" [label="1"];
  "model.layers.1.mlp.experts.31" -> "model.layers.1.mlp.experts.31.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.32" [label="1"];
  "model.layers.1.mlp.experts.32" -> "model.layers.1.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.32" -> "model.layers.1.mlp.experts.32.act_fn" [label="1"];
  "model.layers.1.mlp.experts.32" -> "model.layers.1.mlp.experts.32.up_proj" [label="1"];
  "model.layers.1.mlp.experts.32" -> "model.layers.1.mlp.experts.32.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.33" [label="1"];
  "model.layers.1.mlp.experts.33" -> "model.layers.1.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.33" -> "model.layers.1.mlp.experts.33.act_fn" [label="1"];
  "model.layers.1.mlp.experts.33" -> "model.layers.1.mlp.experts.33.up_proj" [label="1"];
  "model.layers.1.mlp.experts.33" -> "model.layers.1.mlp.experts.33.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.34" [label="1"];
  "model.layers.1.mlp.experts.34" -> "model.layers.1.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.34" -> "model.layers.1.mlp.experts.34.act_fn" [label="1"];
  "model.layers.1.mlp.experts.34" -> "model.layers.1.mlp.experts.34.up_proj" [label="1"];
  "model.layers.1.mlp.experts.34" -> "model.layers.1.mlp.experts.34.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.35" [label="1"];
  "model.layers.1.mlp.experts.35" -> "model.layers.1.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.35" -> "model.layers.1.mlp.experts.35.act_fn" [label="1"];
  "model.layers.1.mlp.experts.35" -> "model.layers.1.mlp.experts.35.up_proj" [label="1"];
  "model.layers.1.mlp.experts.35" -> "model.layers.1.mlp.experts.35.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.36" [label="1"];
  "model.layers.1.mlp.experts.36" -> "model.layers.1.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.36" -> "model.layers.1.mlp.experts.36.act_fn" [label="1"];
  "model.layers.1.mlp.experts.36" -> "model.layers.1.mlp.experts.36.up_proj" [label="1"];
  "model.layers.1.mlp.experts.36" -> "model.layers.1.mlp.experts.36.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.37" [label="1"];
  "model.layers.1.mlp.experts.37" -> "model.layers.1.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.37" -> "model.layers.1.mlp.experts.37.act_fn" [label="1"];
  "model.layers.1.mlp.experts.37" -> "model.layers.1.mlp.experts.37.up_proj" [label="1"];
  "model.layers.1.mlp.experts.37" -> "model.layers.1.mlp.experts.37.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.38" [label="1"];
  "model.layers.1.mlp.experts.38" -> "model.layers.1.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.38" -> "model.layers.1.mlp.experts.38.act_fn" [label="1"];
  "model.layers.1.mlp.experts.38" -> "model.layers.1.mlp.experts.38.up_proj" [label="1"];
  "model.layers.1.mlp.experts.38" -> "model.layers.1.mlp.experts.38.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.39" [label="1"];
  "model.layers.1.mlp.experts.39" -> "model.layers.1.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.39" -> "model.layers.1.mlp.experts.39.act_fn" [label="1"];
  "model.layers.1.mlp.experts.39" -> "model.layers.1.mlp.experts.39.up_proj" [label="1"];
  "model.layers.1.mlp.experts.39" -> "model.layers.1.mlp.experts.39.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.40" [label="1"];
  "model.layers.1.mlp.experts.40" -> "model.layers.1.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.40" -> "model.layers.1.mlp.experts.40.act_fn" [label="1"];
  "model.layers.1.mlp.experts.40" -> "model.layers.1.mlp.experts.40.up_proj" [label="1"];
  "model.layers.1.mlp.experts.40" -> "model.layers.1.mlp.experts.40.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.41" [label="1"];
  "model.layers.1.mlp.experts.41" -> "model.layers.1.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.41" -> "model.layers.1.mlp.experts.41.act_fn" [label="1"];
  "model.layers.1.mlp.experts.41" -> "model.layers.1.mlp.experts.41.up_proj" [label="1"];
  "model.layers.1.mlp.experts.41" -> "model.layers.1.mlp.experts.41.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.42" [label="1"];
  "model.layers.1.mlp.experts.42" -> "model.layers.1.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.42" -> "model.layers.1.mlp.experts.42.act_fn" [label="1"];
  "model.layers.1.mlp.experts.42" -> "model.layers.1.mlp.experts.42.up_proj" [label="1"];
  "model.layers.1.mlp.experts.42" -> "model.layers.1.mlp.experts.42.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.43" [label="1"];
  "model.layers.1.mlp.experts.43" -> "model.layers.1.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.43" -> "model.layers.1.mlp.experts.43.act_fn" [label="1"];
  "model.layers.1.mlp.experts.43" -> "model.layers.1.mlp.experts.43.up_proj" [label="1"];
  "model.layers.1.mlp.experts.43" -> "model.layers.1.mlp.experts.43.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.44" [label="1"];
  "model.layers.1.mlp.experts.44" -> "model.layers.1.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.44" -> "model.layers.1.mlp.experts.44.act_fn" [label="1"];
  "model.layers.1.mlp.experts.44" -> "model.layers.1.mlp.experts.44.up_proj" [label="1"];
  "model.layers.1.mlp.experts.44" -> "model.layers.1.mlp.experts.44.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.45" [label="1"];
  "model.layers.1.mlp.experts.45" -> "model.layers.1.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.45" -> "model.layers.1.mlp.experts.45.act_fn" [label="1"];
  "model.layers.1.mlp.experts.45" -> "model.layers.1.mlp.experts.45.up_proj" [label="1"];
  "model.layers.1.mlp.experts.45" -> "model.layers.1.mlp.experts.45.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.46" [label="1"];
  "model.layers.1.mlp.experts.46" -> "model.layers.1.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.46" -> "model.layers.1.mlp.experts.46.act_fn" [label="1"];
  "model.layers.1.mlp.experts.46" -> "model.layers.1.mlp.experts.46.up_proj" [label="1"];
  "model.layers.1.mlp.experts.46" -> "model.layers.1.mlp.experts.46.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.47" [label="1"];
  "model.layers.1.mlp.experts.47" -> "model.layers.1.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.47" -> "model.layers.1.mlp.experts.47.act_fn" [label="1"];
  "model.layers.1.mlp.experts.47" -> "model.layers.1.mlp.experts.47.up_proj" [label="1"];
  "model.layers.1.mlp.experts.47" -> "model.layers.1.mlp.experts.47.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.48" [label="1"];
  "model.layers.1.mlp.experts.48" -> "model.layers.1.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.48" -> "model.layers.1.mlp.experts.48.act_fn" [label="1"];
  "model.layers.1.mlp.experts.48" -> "model.layers.1.mlp.experts.48.up_proj" [label="1"];
  "model.layers.1.mlp.experts.48" -> "model.layers.1.mlp.experts.48.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.49" [label="1"];
  "model.layers.1.mlp.experts.49" -> "model.layers.1.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.49" -> "model.layers.1.mlp.experts.49.act_fn" [label="1"];
  "model.layers.1.mlp.experts.49" -> "model.layers.1.mlp.experts.49.up_proj" [label="1"];
  "model.layers.1.mlp.experts.49" -> "model.layers.1.mlp.experts.49.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.51" [label="1"];
  "model.layers.1.mlp.experts.51" -> "model.layers.1.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.51" -> "model.layers.1.mlp.experts.51.act_fn" [label="1"];
  "model.layers.1.mlp.experts.51" -> "model.layers.1.mlp.experts.51.up_proj" [label="1"];
  "model.layers.1.mlp.experts.51" -> "model.layers.1.mlp.experts.51.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.52" [label="1"];
  "model.layers.1.mlp.experts.52" -> "model.layers.1.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.52" -> "model.layers.1.mlp.experts.52.act_fn" [label="1"];
  "model.layers.1.mlp.experts.52" -> "model.layers.1.mlp.experts.52.up_proj" [label="1"];
  "model.layers.1.mlp.experts.52" -> "model.layers.1.mlp.experts.52.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.53" [label="1"];
  "model.layers.1.mlp.experts.53" -> "model.layers.1.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.53" -> "model.layers.1.mlp.experts.53.act_fn" [label="1"];
  "model.layers.1.mlp.experts.53" -> "model.layers.1.mlp.experts.53.up_proj" [label="1"];
  "model.layers.1.mlp.experts.53" -> "model.layers.1.mlp.experts.53.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.55" [label="1"];
  "model.layers.1.mlp.experts.55" -> "model.layers.1.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.55" -> "model.layers.1.mlp.experts.55.act_fn" [label="1"];
  "model.layers.1.mlp.experts.55" -> "model.layers.1.mlp.experts.55.up_proj" [label="1"];
  "model.layers.1.mlp.experts.55" -> "model.layers.1.mlp.experts.55.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.56" [label="1"];
  "model.layers.1.mlp.experts.56" -> "model.layers.1.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.56" -> "model.layers.1.mlp.experts.56.act_fn" [label="1"];
  "model.layers.1.mlp.experts.56" -> "model.layers.1.mlp.experts.56.up_proj" [label="1"];
  "model.layers.1.mlp.experts.56" -> "model.layers.1.mlp.experts.56.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.57" [label="1"];
  "model.layers.1.mlp.experts.57" -> "model.layers.1.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.57" -> "model.layers.1.mlp.experts.57.act_fn" [label="1"];
  "model.layers.1.mlp.experts.57" -> "model.layers.1.mlp.experts.57.up_proj" [label="1"];
  "model.layers.1.mlp.experts.57" -> "model.layers.1.mlp.experts.57.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.58" [label="1"];
  "model.layers.1.mlp.experts.58" -> "model.layers.1.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.58" -> "model.layers.1.mlp.experts.58.act_fn" [label="1"];
  "model.layers.1.mlp.experts.58" -> "model.layers.1.mlp.experts.58.up_proj" [label="1"];
  "model.layers.1.mlp.experts.58" -> "model.layers.1.mlp.experts.58.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.59" [label="1"];
  "model.layers.1.mlp.experts.59" -> "model.layers.1.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.59" -> "model.layers.1.mlp.experts.59.act_fn" [label="1"];
  "model.layers.1.mlp.experts.59" -> "model.layers.1.mlp.experts.59.up_proj" [label="1"];
  "model.layers.1.mlp.experts.59" -> "model.layers.1.mlp.experts.59.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.60" [label="1"];
  "model.layers.1.mlp.experts.60" -> "model.layers.1.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.60" -> "model.layers.1.mlp.experts.60.act_fn" [label="1"];
  "model.layers.1.mlp.experts.60" -> "model.layers.1.mlp.experts.60.up_proj" [label="1"];
  "model.layers.1.mlp.experts.60" -> "model.layers.1.mlp.experts.60.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.61" [label="1"];
  "model.layers.1.mlp.experts.61" -> "model.layers.1.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.61" -> "model.layers.1.mlp.experts.61.act_fn" [label="1"];
  "model.layers.1.mlp.experts.61" -> "model.layers.1.mlp.experts.61.up_proj" [label="1"];
  "model.layers.1.mlp.experts.61" -> "model.layers.1.mlp.experts.61.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.62" [label="1"];
  "model.layers.1.mlp.experts.62" -> "model.layers.1.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.62" -> "model.layers.1.mlp.experts.62.act_fn" [label="1"];
  "model.layers.1.mlp.experts.62" -> "model.layers.1.mlp.experts.62.up_proj" [label="1"];
  "model.layers.1.mlp.experts.62" -> "model.layers.1.mlp.experts.62.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.experts.63" [label="1"];
  "model.layers.1.mlp.experts.63" -> "model.layers.1.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.1.mlp.experts.63" -> "model.layers.1.mlp.experts.63.act_fn" [label="1"];
  "model.layers.1.mlp.experts.63" -> "model.layers.1.mlp.experts.63.up_proj" [label="1"];
  "model.layers.1.mlp.experts.63" -> "model.layers.1.mlp.experts.63.down_proj" [label="1"];
  "model.layers.1.mlp" -> "model.layers.1.mlp.shared_experts" [label="1"];
  "model.layers.1.mlp.shared_experts" -> "model.layers.1.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.1.mlp.shared_experts" -> "model.layers.1.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.1.mlp.shared_experts" -> "model.layers.1.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.1.mlp.shared_experts" -> "model.layers.1.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.2" [label="1"];
  "model.layers.2" -> "model.layers.2.input_layernorm" [label="1"];
  "model.layers.2" -> "model.layers.2.self_attn" [label="1"];
  "model.layers.2.self_attn" -> "model.layers.2.self_attn.q_proj" [label="1"];
  "model.layers.2.self_attn" -> "model.layers.2.self_attn.k_proj" [label="1"];
  "model.layers.2.self_attn" -> "model.layers.2.self_attn.v_proj" [label="1"];
  "model.layers.2.self_attn" -> "model.layers.2.self_attn.o_proj" [label="1"];
  "model.layers.2" -> "model.layers.2.post_attention_layernorm" [label="1"];
  "model.layers.2" -> "model.layers.2.mlp" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.gate" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.0" [label="1"];
  "model.layers.2.mlp.experts.0" -> "model.layers.2.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.0" -> "model.layers.2.mlp.experts.0.act_fn" [label="1"];
  "model.layers.2.mlp.experts.0" -> "model.layers.2.mlp.experts.0.up_proj" [label="1"];
  "model.layers.2.mlp.experts.0" -> "model.layers.2.mlp.experts.0.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.1" [label="1"];
  "model.layers.2.mlp.experts.1" -> "model.layers.2.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.1" -> "model.layers.2.mlp.experts.1.act_fn" [label="1"];
  "model.layers.2.mlp.experts.1" -> "model.layers.2.mlp.experts.1.up_proj" [label="1"];
  "model.layers.2.mlp.experts.1" -> "model.layers.2.mlp.experts.1.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.2" [label="1"];
  "model.layers.2.mlp.experts.2" -> "model.layers.2.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.2" -> "model.layers.2.mlp.experts.2.act_fn" [label="1"];
  "model.layers.2.mlp.experts.2" -> "model.layers.2.mlp.experts.2.up_proj" [label="1"];
  "model.layers.2.mlp.experts.2" -> "model.layers.2.mlp.experts.2.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.3" [label="1"];
  "model.layers.2.mlp.experts.3" -> "model.layers.2.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.3" -> "model.layers.2.mlp.experts.3.act_fn" [label="1"];
  "model.layers.2.mlp.experts.3" -> "model.layers.2.mlp.experts.3.up_proj" [label="1"];
  "model.layers.2.mlp.experts.3" -> "model.layers.2.mlp.experts.3.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.4" [label="1"];
  "model.layers.2.mlp.experts.4" -> "model.layers.2.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.4" -> "model.layers.2.mlp.experts.4.act_fn" [label="1"];
  "model.layers.2.mlp.experts.4" -> "model.layers.2.mlp.experts.4.up_proj" [label="1"];
  "model.layers.2.mlp.experts.4" -> "model.layers.2.mlp.experts.4.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.6" [label="1"];
  "model.layers.2.mlp.experts.6" -> "model.layers.2.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.6" -> "model.layers.2.mlp.experts.6.act_fn" [label="1"];
  "model.layers.2.mlp.experts.6" -> "model.layers.2.mlp.experts.6.up_proj" [label="1"];
  "model.layers.2.mlp.experts.6" -> "model.layers.2.mlp.experts.6.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.7" [label="1"];
  "model.layers.2.mlp.experts.7" -> "model.layers.2.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.7" -> "model.layers.2.mlp.experts.7.act_fn" [label="1"];
  "model.layers.2.mlp.experts.7" -> "model.layers.2.mlp.experts.7.up_proj" [label="1"];
  "model.layers.2.mlp.experts.7" -> "model.layers.2.mlp.experts.7.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.8" [label="1"];
  "model.layers.2.mlp.experts.8" -> "model.layers.2.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.8" -> "model.layers.2.mlp.experts.8.act_fn" [label="1"];
  "model.layers.2.mlp.experts.8" -> "model.layers.2.mlp.experts.8.up_proj" [label="1"];
  "model.layers.2.mlp.experts.8" -> "model.layers.2.mlp.experts.8.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.9" [label="1"];
  "model.layers.2.mlp.experts.9" -> "model.layers.2.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.9" -> "model.layers.2.mlp.experts.9.act_fn" [label="1"];
  "model.layers.2.mlp.experts.9" -> "model.layers.2.mlp.experts.9.up_proj" [label="1"];
  "model.layers.2.mlp.experts.9" -> "model.layers.2.mlp.experts.9.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.10" [label="1"];
  "model.layers.2.mlp.experts.10" -> "model.layers.2.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.10" -> "model.layers.2.mlp.experts.10.act_fn" [label="1"];
  "model.layers.2.mlp.experts.10" -> "model.layers.2.mlp.experts.10.up_proj" [label="1"];
  "model.layers.2.mlp.experts.10" -> "model.layers.2.mlp.experts.10.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.11" [label="1"];
  "model.layers.2.mlp.experts.11" -> "model.layers.2.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.11" -> "model.layers.2.mlp.experts.11.act_fn" [label="1"];
  "model.layers.2.mlp.experts.11" -> "model.layers.2.mlp.experts.11.up_proj" [label="1"];
  "model.layers.2.mlp.experts.11" -> "model.layers.2.mlp.experts.11.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.12" [label="1"];
  "model.layers.2.mlp.experts.12" -> "model.layers.2.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.12" -> "model.layers.2.mlp.experts.12.act_fn" [label="1"];
  "model.layers.2.mlp.experts.12" -> "model.layers.2.mlp.experts.12.up_proj" [label="1"];
  "model.layers.2.mlp.experts.12" -> "model.layers.2.mlp.experts.12.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.14" [label="1"];
  "model.layers.2.mlp.experts.14" -> "model.layers.2.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.14" -> "model.layers.2.mlp.experts.14.act_fn" [label="1"];
  "model.layers.2.mlp.experts.14" -> "model.layers.2.mlp.experts.14.up_proj" [label="1"];
  "model.layers.2.mlp.experts.14" -> "model.layers.2.mlp.experts.14.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.15" [label="1"];
  "model.layers.2.mlp.experts.15" -> "model.layers.2.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.15" -> "model.layers.2.mlp.experts.15.act_fn" [label="1"];
  "model.layers.2.mlp.experts.15" -> "model.layers.2.mlp.experts.15.up_proj" [label="1"];
  "model.layers.2.mlp.experts.15" -> "model.layers.2.mlp.experts.15.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.16" [label="1"];
  "model.layers.2.mlp.experts.16" -> "model.layers.2.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.16" -> "model.layers.2.mlp.experts.16.act_fn" [label="1"];
  "model.layers.2.mlp.experts.16" -> "model.layers.2.mlp.experts.16.up_proj" [label="1"];
  "model.layers.2.mlp.experts.16" -> "model.layers.2.mlp.experts.16.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.17" [label="1"];
  "model.layers.2.mlp.experts.17" -> "model.layers.2.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.17" -> "model.layers.2.mlp.experts.17.act_fn" [label="1"];
  "model.layers.2.mlp.experts.17" -> "model.layers.2.mlp.experts.17.up_proj" [label="1"];
  "model.layers.2.mlp.experts.17" -> "model.layers.2.mlp.experts.17.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.18" [label="1"];
  "model.layers.2.mlp.experts.18" -> "model.layers.2.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.18" -> "model.layers.2.mlp.experts.18.act_fn" [label="1"];
  "model.layers.2.mlp.experts.18" -> "model.layers.2.mlp.experts.18.up_proj" [label="1"];
  "model.layers.2.mlp.experts.18" -> "model.layers.2.mlp.experts.18.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.20" [label="1"];
  "model.layers.2.mlp.experts.20" -> "model.layers.2.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.20" -> "model.layers.2.mlp.experts.20.act_fn" [label="1"];
  "model.layers.2.mlp.experts.20" -> "model.layers.2.mlp.experts.20.up_proj" [label="1"];
  "model.layers.2.mlp.experts.20" -> "model.layers.2.mlp.experts.20.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.21" [label="1"];
  "model.layers.2.mlp.experts.21" -> "model.layers.2.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.21" -> "model.layers.2.mlp.experts.21.act_fn" [label="1"];
  "model.layers.2.mlp.experts.21" -> "model.layers.2.mlp.experts.21.up_proj" [label="1"];
  "model.layers.2.mlp.experts.21" -> "model.layers.2.mlp.experts.21.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.22" [label="1"];
  "model.layers.2.mlp.experts.22" -> "model.layers.2.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.22" -> "model.layers.2.mlp.experts.22.act_fn" [label="1"];
  "model.layers.2.mlp.experts.22" -> "model.layers.2.mlp.experts.22.up_proj" [label="1"];
  "model.layers.2.mlp.experts.22" -> "model.layers.2.mlp.experts.22.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.23" [label="1"];
  "model.layers.2.mlp.experts.23" -> "model.layers.2.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.23" -> "model.layers.2.mlp.experts.23.act_fn" [label="1"];
  "model.layers.2.mlp.experts.23" -> "model.layers.2.mlp.experts.23.up_proj" [label="1"];
  "model.layers.2.mlp.experts.23" -> "model.layers.2.mlp.experts.23.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.24" [label="1"];
  "model.layers.2.mlp.experts.24" -> "model.layers.2.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.24" -> "model.layers.2.mlp.experts.24.act_fn" [label="1"];
  "model.layers.2.mlp.experts.24" -> "model.layers.2.mlp.experts.24.up_proj" [label="1"];
  "model.layers.2.mlp.experts.24" -> "model.layers.2.mlp.experts.24.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.25" [label="1"];
  "model.layers.2.mlp.experts.25" -> "model.layers.2.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.25" -> "model.layers.2.mlp.experts.25.act_fn" [label="1"];
  "model.layers.2.mlp.experts.25" -> "model.layers.2.mlp.experts.25.up_proj" [label="1"];
  "model.layers.2.mlp.experts.25" -> "model.layers.2.mlp.experts.25.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.26" [label="1"];
  "model.layers.2.mlp.experts.26" -> "model.layers.2.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.26" -> "model.layers.2.mlp.experts.26.act_fn" [label="1"];
  "model.layers.2.mlp.experts.26" -> "model.layers.2.mlp.experts.26.up_proj" [label="1"];
  "model.layers.2.mlp.experts.26" -> "model.layers.2.mlp.experts.26.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.27" [label="1"];
  "model.layers.2.mlp.experts.27" -> "model.layers.2.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.27" -> "model.layers.2.mlp.experts.27.act_fn" [label="1"];
  "model.layers.2.mlp.experts.27" -> "model.layers.2.mlp.experts.27.up_proj" [label="1"];
  "model.layers.2.mlp.experts.27" -> "model.layers.2.mlp.experts.27.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.28" [label="1"];
  "model.layers.2.mlp.experts.28" -> "model.layers.2.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.28" -> "model.layers.2.mlp.experts.28.act_fn" [label="1"];
  "model.layers.2.mlp.experts.28" -> "model.layers.2.mlp.experts.28.up_proj" [label="1"];
  "model.layers.2.mlp.experts.28" -> "model.layers.2.mlp.experts.28.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.29" [label="1"];
  "model.layers.2.mlp.experts.29" -> "model.layers.2.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.29" -> "model.layers.2.mlp.experts.29.act_fn" [label="1"];
  "model.layers.2.mlp.experts.29" -> "model.layers.2.mlp.experts.29.up_proj" [label="1"];
  "model.layers.2.mlp.experts.29" -> "model.layers.2.mlp.experts.29.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.30" [label="1"];
  "model.layers.2.mlp.experts.30" -> "model.layers.2.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.30" -> "model.layers.2.mlp.experts.30.act_fn" [label="1"];
  "model.layers.2.mlp.experts.30" -> "model.layers.2.mlp.experts.30.up_proj" [label="1"];
  "model.layers.2.mlp.experts.30" -> "model.layers.2.mlp.experts.30.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.31" [label="1"];
  "model.layers.2.mlp.experts.31" -> "model.layers.2.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.31" -> "model.layers.2.mlp.experts.31.act_fn" [label="1"];
  "model.layers.2.mlp.experts.31" -> "model.layers.2.mlp.experts.31.up_proj" [label="1"];
  "model.layers.2.mlp.experts.31" -> "model.layers.2.mlp.experts.31.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.32" [label="1"];
  "model.layers.2.mlp.experts.32" -> "model.layers.2.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.32" -> "model.layers.2.mlp.experts.32.act_fn" [label="1"];
  "model.layers.2.mlp.experts.32" -> "model.layers.2.mlp.experts.32.up_proj" [label="1"];
  "model.layers.2.mlp.experts.32" -> "model.layers.2.mlp.experts.32.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.33" [label="1"];
  "model.layers.2.mlp.experts.33" -> "model.layers.2.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.33" -> "model.layers.2.mlp.experts.33.act_fn" [label="1"];
  "model.layers.2.mlp.experts.33" -> "model.layers.2.mlp.experts.33.up_proj" [label="1"];
  "model.layers.2.mlp.experts.33" -> "model.layers.2.mlp.experts.33.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.34" [label="1"];
  "model.layers.2.mlp.experts.34" -> "model.layers.2.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.34" -> "model.layers.2.mlp.experts.34.act_fn" [label="1"];
  "model.layers.2.mlp.experts.34" -> "model.layers.2.mlp.experts.34.up_proj" [label="1"];
  "model.layers.2.mlp.experts.34" -> "model.layers.2.mlp.experts.34.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.35" [label="1"];
  "model.layers.2.mlp.experts.35" -> "model.layers.2.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.35" -> "model.layers.2.mlp.experts.35.act_fn" [label="1"];
  "model.layers.2.mlp.experts.35" -> "model.layers.2.mlp.experts.35.up_proj" [label="1"];
  "model.layers.2.mlp.experts.35" -> "model.layers.2.mlp.experts.35.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.36" [label="1"];
  "model.layers.2.mlp.experts.36" -> "model.layers.2.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.36" -> "model.layers.2.mlp.experts.36.act_fn" [label="1"];
  "model.layers.2.mlp.experts.36" -> "model.layers.2.mlp.experts.36.up_proj" [label="1"];
  "model.layers.2.mlp.experts.36" -> "model.layers.2.mlp.experts.36.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.37" [label="1"];
  "model.layers.2.mlp.experts.37" -> "model.layers.2.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.37" -> "model.layers.2.mlp.experts.37.act_fn" [label="1"];
  "model.layers.2.mlp.experts.37" -> "model.layers.2.mlp.experts.37.up_proj" [label="1"];
  "model.layers.2.mlp.experts.37" -> "model.layers.2.mlp.experts.37.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.38" [label="1"];
  "model.layers.2.mlp.experts.38" -> "model.layers.2.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.38" -> "model.layers.2.mlp.experts.38.act_fn" [label="1"];
  "model.layers.2.mlp.experts.38" -> "model.layers.2.mlp.experts.38.up_proj" [label="1"];
  "model.layers.2.mlp.experts.38" -> "model.layers.2.mlp.experts.38.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.39" [label="1"];
  "model.layers.2.mlp.experts.39" -> "model.layers.2.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.39" -> "model.layers.2.mlp.experts.39.act_fn" [label="1"];
  "model.layers.2.mlp.experts.39" -> "model.layers.2.mlp.experts.39.up_proj" [label="1"];
  "model.layers.2.mlp.experts.39" -> "model.layers.2.mlp.experts.39.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.40" [label="1"];
  "model.layers.2.mlp.experts.40" -> "model.layers.2.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.40" -> "model.layers.2.mlp.experts.40.act_fn" [label="1"];
  "model.layers.2.mlp.experts.40" -> "model.layers.2.mlp.experts.40.up_proj" [label="1"];
  "model.layers.2.mlp.experts.40" -> "model.layers.2.mlp.experts.40.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.41" [label="1"];
  "model.layers.2.mlp.experts.41" -> "model.layers.2.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.41" -> "model.layers.2.mlp.experts.41.act_fn" [label="1"];
  "model.layers.2.mlp.experts.41" -> "model.layers.2.mlp.experts.41.up_proj" [label="1"];
  "model.layers.2.mlp.experts.41" -> "model.layers.2.mlp.experts.41.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.42" [label="1"];
  "model.layers.2.mlp.experts.42" -> "model.layers.2.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.42" -> "model.layers.2.mlp.experts.42.act_fn" [label="1"];
  "model.layers.2.mlp.experts.42" -> "model.layers.2.mlp.experts.42.up_proj" [label="1"];
  "model.layers.2.mlp.experts.42" -> "model.layers.2.mlp.experts.42.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.43" [label="1"];
  "model.layers.2.mlp.experts.43" -> "model.layers.2.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.43" -> "model.layers.2.mlp.experts.43.act_fn" [label="1"];
  "model.layers.2.mlp.experts.43" -> "model.layers.2.mlp.experts.43.up_proj" [label="1"];
  "model.layers.2.mlp.experts.43" -> "model.layers.2.mlp.experts.43.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.44" [label="1"];
  "model.layers.2.mlp.experts.44" -> "model.layers.2.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.44" -> "model.layers.2.mlp.experts.44.act_fn" [label="1"];
  "model.layers.2.mlp.experts.44" -> "model.layers.2.mlp.experts.44.up_proj" [label="1"];
  "model.layers.2.mlp.experts.44" -> "model.layers.2.mlp.experts.44.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.45" [label="1"];
  "model.layers.2.mlp.experts.45" -> "model.layers.2.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.45" -> "model.layers.2.mlp.experts.45.act_fn" [label="1"];
  "model.layers.2.mlp.experts.45" -> "model.layers.2.mlp.experts.45.up_proj" [label="1"];
  "model.layers.2.mlp.experts.45" -> "model.layers.2.mlp.experts.45.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.46" [label="1"];
  "model.layers.2.mlp.experts.46" -> "model.layers.2.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.46" -> "model.layers.2.mlp.experts.46.act_fn" [label="1"];
  "model.layers.2.mlp.experts.46" -> "model.layers.2.mlp.experts.46.up_proj" [label="1"];
  "model.layers.2.mlp.experts.46" -> "model.layers.2.mlp.experts.46.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.47" [label="1"];
  "model.layers.2.mlp.experts.47" -> "model.layers.2.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.47" -> "model.layers.2.mlp.experts.47.act_fn" [label="1"];
  "model.layers.2.mlp.experts.47" -> "model.layers.2.mlp.experts.47.up_proj" [label="1"];
  "model.layers.2.mlp.experts.47" -> "model.layers.2.mlp.experts.47.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.48" [label="1"];
  "model.layers.2.mlp.experts.48" -> "model.layers.2.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.48" -> "model.layers.2.mlp.experts.48.act_fn" [label="1"];
  "model.layers.2.mlp.experts.48" -> "model.layers.2.mlp.experts.48.up_proj" [label="1"];
  "model.layers.2.mlp.experts.48" -> "model.layers.2.mlp.experts.48.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.49" [label="1"];
  "model.layers.2.mlp.experts.49" -> "model.layers.2.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.49" -> "model.layers.2.mlp.experts.49.act_fn" [label="1"];
  "model.layers.2.mlp.experts.49" -> "model.layers.2.mlp.experts.49.up_proj" [label="1"];
  "model.layers.2.mlp.experts.49" -> "model.layers.2.mlp.experts.49.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.50" [label="1"];
  "model.layers.2.mlp.experts.50" -> "model.layers.2.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.50" -> "model.layers.2.mlp.experts.50.act_fn" [label="1"];
  "model.layers.2.mlp.experts.50" -> "model.layers.2.mlp.experts.50.up_proj" [label="1"];
  "model.layers.2.mlp.experts.50" -> "model.layers.2.mlp.experts.50.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.51" [label="1"];
  "model.layers.2.mlp.experts.51" -> "model.layers.2.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.51" -> "model.layers.2.mlp.experts.51.act_fn" [label="1"];
  "model.layers.2.mlp.experts.51" -> "model.layers.2.mlp.experts.51.up_proj" [label="1"];
  "model.layers.2.mlp.experts.51" -> "model.layers.2.mlp.experts.51.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.52" [label="1"];
  "model.layers.2.mlp.experts.52" -> "model.layers.2.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.52" -> "model.layers.2.mlp.experts.52.act_fn" [label="1"];
  "model.layers.2.mlp.experts.52" -> "model.layers.2.mlp.experts.52.up_proj" [label="1"];
  "model.layers.2.mlp.experts.52" -> "model.layers.2.mlp.experts.52.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.53" [label="1"];
  "model.layers.2.mlp.experts.53" -> "model.layers.2.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.53" -> "model.layers.2.mlp.experts.53.act_fn" [label="1"];
  "model.layers.2.mlp.experts.53" -> "model.layers.2.mlp.experts.53.up_proj" [label="1"];
  "model.layers.2.mlp.experts.53" -> "model.layers.2.mlp.experts.53.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.54" [label="1"];
  "model.layers.2.mlp.experts.54" -> "model.layers.2.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.54" -> "model.layers.2.mlp.experts.54.act_fn" [label="1"];
  "model.layers.2.mlp.experts.54" -> "model.layers.2.mlp.experts.54.up_proj" [label="1"];
  "model.layers.2.mlp.experts.54" -> "model.layers.2.mlp.experts.54.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.55" [label="1"];
  "model.layers.2.mlp.experts.55" -> "model.layers.2.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.55" -> "model.layers.2.mlp.experts.55.act_fn" [label="1"];
  "model.layers.2.mlp.experts.55" -> "model.layers.2.mlp.experts.55.up_proj" [label="1"];
  "model.layers.2.mlp.experts.55" -> "model.layers.2.mlp.experts.55.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.56" [label="1"];
  "model.layers.2.mlp.experts.56" -> "model.layers.2.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.56" -> "model.layers.2.mlp.experts.56.act_fn" [label="1"];
  "model.layers.2.mlp.experts.56" -> "model.layers.2.mlp.experts.56.up_proj" [label="1"];
  "model.layers.2.mlp.experts.56" -> "model.layers.2.mlp.experts.56.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.57" [label="1"];
  "model.layers.2.mlp.experts.57" -> "model.layers.2.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.57" -> "model.layers.2.mlp.experts.57.act_fn" [label="1"];
  "model.layers.2.mlp.experts.57" -> "model.layers.2.mlp.experts.57.up_proj" [label="1"];
  "model.layers.2.mlp.experts.57" -> "model.layers.2.mlp.experts.57.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.59" [label="1"];
  "model.layers.2.mlp.experts.59" -> "model.layers.2.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.59" -> "model.layers.2.mlp.experts.59.act_fn" [label="1"];
  "model.layers.2.mlp.experts.59" -> "model.layers.2.mlp.experts.59.up_proj" [label="1"];
  "model.layers.2.mlp.experts.59" -> "model.layers.2.mlp.experts.59.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.60" [label="1"];
  "model.layers.2.mlp.experts.60" -> "model.layers.2.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.60" -> "model.layers.2.mlp.experts.60.act_fn" [label="1"];
  "model.layers.2.mlp.experts.60" -> "model.layers.2.mlp.experts.60.up_proj" [label="1"];
  "model.layers.2.mlp.experts.60" -> "model.layers.2.mlp.experts.60.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.61" [label="1"];
  "model.layers.2.mlp.experts.61" -> "model.layers.2.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.61" -> "model.layers.2.mlp.experts.61.act_fn" [label="1"];
  "model.layers.2.mlp.experts.61" -> "model.layers.2.mlp.experts.61.up_proj" [label="1"];
  "model.layers.2.mlp.experts.61" -> "model.layers.2.mlp.experts.61.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.62" [label="1"];
  "model.layers.2.mlp.experts.62" -> "model.layers.2.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.62" -> "model.layers.2.mlp.experts.62.act_fn" [label="1"];
  "model.layers.2.mlp.experts.62" -> "model.layers.2.mlp.experts.62.up_proj" [label="1"];
  "model.layers.2.mlp.experts.62" -> "model.layers.2.mlp.experts.62.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.experts.63" [label="1"];
  "model.layers.2.mlp.experts.63" -> "model.layers.2.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.2.mlp.experts.63" -> "model.layers.2.mlp.experts.63.act_fn" [label="1"];
  "model.layers.2.mlp.experts.63" -> "model.layers.2.mlp.experts.63.up_proj" [label="1"];
  "model.layers.2.mlp.experts.63" -> "model.layers.2.mlp.experts.63.down_proj" [label="1"];
  "model.layers.2.mlp" -> "model.layers.2.mlp.shared_experts" [label="1"];
  "model.layers.2.mlp.shared_experts" -> "model.layers.2.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.2.mlp.shared_experts" -> "model.layers.2.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.2.mlp.shared_experts" -> "model.layers.2.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.2.mlp.shared_experts" -> "model.layers.2.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.3" [label="1"];
  "model.layers.3" -> "model.layers.3.input_layernorm" [label="1"];
  "model.layers.3" -> "model.layers.3.self_attn" [label="1"];
  "model.layers.3.self_attn" -> "model.layers.3.self_attn.q_proj" [label="1"];
  "model.layers.3.self_attn" -> "model.layers.3.self_attn.k_proj" [label="1"];
  "model.layers.3.self_attn" -> "model.layers.3.self_attn.v_proj" [label="1"];
  "model.layers.3.self_attn" -> "model.layers.3.self_attn.o_proj" [label="1"];
  "model.layers.3" -> "model.layers.3.post_attention_layernorm" [label="1"];
  "model.layers.3" -> "model.layers.3.mlp" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.gate" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.0" [label="1"];
  "model.layers.3.mlp.experts.0" -> "model.layers.3.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.0" -> "model.layers.3.mlp.experts.0.act_fn" [label="1"];
  "model.layers.3.mlp.experts.0" -> "model.layers.3.mlp.experts.0.up_proj" [label="1"];
  "model.layers.3.mlp.experts.0" -> "model.layers.3.mlp.experts.0.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.1" [label="1"];
  "model.layers.3.mlp.experts.1" -> "model.layers.3.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.1" -> "model.layers.3.mlp.experts.1.act_fn" [label="1"];
  "model.layers.3.mlp.experts.1" -> "model.layers.3.mlp.experts.1.up_proj" [label="1"];
  "model.layers.3.mlp.experts.1" -> "model.layers.3.mlp.experts.1.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.2" [label="1"];
  "model.layers.3.mlp.experts.2" -> "model.layers.3.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.2" -> "model.layers.3.mlp.experts.2.act_fn" [label="1"];
  "model.layers.3.mlp.experts.2" -> "model.layers.3.mlp.experts.2.up_proj" [label="1"];
  "model.layers.3.mlp.experts.2" -> "model.layers.3.mlp.experts.2.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.3" [label="1"];
  "model.layers.3.mlp.experts.3" -> "model.layers.3.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.3" -> "model.layers.3.mlp.experts.3.act_fn" [label="1"];
  "model.layers.3.mlp.experts.3" -> "model.layers.3.mlp.experts.3.up_proj" [label="1"];
  "model.layers.3.mlp.experts.3" -> "model.layers.3.mlp.experts.3.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.4" [label="1"];
  "model.layers.3.mlp.experts.4" -> "model.layers.3.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.4" -> "model.layers.3.mlp.experts.4.act_fn" [label="1"];
  "model.layers.3.mlp.experts.4" -> "model.layers.3.mlp.experts.4.up_proj" [label="1"];
  "model.layers.3.mlp.experts.4" -> "model.layers.3.mlp.experts.4.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.5" [label="1"];
  "model.layers.3.mlp.experts.5" -> "model.layers.3.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.5" -> "model.layers.3.mlp.experts.5.act_fn" [label="1"];
  "model.layers.3.mlp.experts.5" -> "model.layers.3.mlp.experts.5.up_proj" [label="1"];
  "model.layers.3.mlp.experts.5" -> "model.layers.3.mlp.experts.5.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.6" [label="1"];
  "model.layers.3.mlp.experts.6" -> "model.layers.3.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.6" -> "model.layers.3.mlp.experts.6.act_fn" [label="1"];
  "model.layers.3.mlp.experts.6" -> "model.layers.3.mlp.experts.6.up_proj" [label="1"];
  "model.layers.3.mlp.experts.6" -> "model.layers.3.mlp.experts.6.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.8" [label="1"];
  "model.layers.3.mlp.experts.8" -> "model.layers.3.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.8" -> "model.layers.3.mlp.experts.8.act_fn" [label="1"];
  "model.layers.3.mlp.experts.8" -> "model.layers.3.mlp.experts.8.up_proj" [label="1"];
  "model.layers.3.mlp.experts.8" -> "model.layers.3.mlp.experts.8.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.9" [label="1"];
  "model.layers.3.mlp.experts.9" -> "model.layers.3.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.9" -> "model.layers.3.mlp.experts.9.act_fn" [label="1"];
  "model.layers.3.mlp.experts.9" -> "model.layers.3.mlp.experts.9.up_proj" [label="1"];
  "model.layers.3.mlp.experts.9" -> "model.layers.3.mlp.experts.9.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.10" [label="1"];
  "model.layers.3.mlp.experts.10" -> "model.layers.3.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.10" -> "model.layers.3.mlp.experts.10.act_fn" [label="1"];
  "model.layers.3.mlp.experts.10" -> "model.layers.3.mlp.experts.10.up_proj" [label="1"];
  "model.layers.3.mlp.experts.10" -> "model.layers.3.mlp.experts.10.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.11" [label="1"];
  "model.layers.3.mlp.experts.11" -> "model.layers.3.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.11" -> "model.layers.3.mlp.experts.11.act_fn" [label="1"];
  "model.layers.3.mlp.experts.11" -> "model.layers.3.mlp.experts.11.up_proj" [label="1"];
  "model.layers.3.mlp.experts.11" -> "model.layers.3.mlp.experts.11.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.12" [label="1"];
  "model.layers.3.mlp.experts.12" -> "model.layers.3.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.12" -> "model.layers.3.mlp.experts.12.act_fn" [label="1"];
  "model.layers.3.mlp.experts.12" -> "model.layers.3.mlp.experts.12.up_proj" [label="1"];
  "model.layers.3.mlp.experts.12" -> "model.layers.3.mlp.experts.12.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.13" [label="1"];
  "model.layers.3.mlp.experts.13" -> "model.layers.3.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.13" -> "model.layers.3.mlp.experts.13.act_fn" [label="1"];
  "model.layers.3.mlp.experts.13" -> "model.layers.3.mlp.experts.13.up_proj" [label="1"];
  "model.layers.3.mlp.experts.13" -> "model.layers.3.mlp.experts.13.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.14" [label="1"];
  "model.layers.3.mlp.experts.14" -> "model.layers.3.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.14" -> "model.layers.3.mlp.experts.14.act_fn" [label="1"];
  "model.layers.3.mlp.experts.14" -> "model.layers.3.mlp.experts.14.up_proj" [label="1"];
  "model.layers.3.mlp.experts.14" -> "model.layers.3.mlp.experts.14.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.15" [label="1"];
  "model.layers.3.mlp.experts.15" -> "model.layers.3.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.15" -> "model.layers.3.mlp.experts.15.act_fn" [label="1"];
  "model.layers.3.mlp.experts.15" -> "model.layers.3.mlp.experts.15.up_proj" [label="1"];
  "model.layers.3.mlp.experts.15" -> "model.layers.3.mlp.experts.15.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.16" [label="1"];
  "model.layers.3.mlp.experts.16" -> "model.layers.3.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.16" -> "model.layers.3.mlp.experts.16.act_fn" [label="1"];
  "model.layers.3.mlp.experts.16" -> "model.layers.3.mlp.experts.16.up_proj" [label="1"];
  "model.layers.3.mlp.experts.16" -> "model.layers.3.mlp.experts.16.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.17" [label="1"];
  "model.layers.3.mlp.experts.17" -> "model.layers.3.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.17" -> "model.layers.3.mlp.experts.17.act_fn" [label="1"];
  "model.layers.3.mlp.experts.17" -> "model.layers.3.mlp.experts.17.up_proj" [label="1"];
  "model.layers.3.mlp.experts.17" -> "model.layers.3.mlp.experts.17.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.18" [label="1"];
  "model.layers.3.mlp.experts.18" -> "model.layers.3.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.18" -> "model.layers.3.mlp.experts.18.act_fn" [label="1"];
  "model.layers.3.mlp.experts.18" -> "model.layers.3.mlp.experts.18.up_proj" [label="1"];
  "model.layers.3.mlp.experts.18" -> "model.layers.3.mlp.experts.18.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.20" [label="1"];
  "model.layers.3.mlp.experts.20" -> "model.layers.3.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.20" -> "model.layers.3.mlp.experts.20.act_fn" [label="1"];
  "model.layers.3.mlp.experts.20" -> "model.layers.3.mlp.experts.20.up_proj" [label="1"];
  "model.layers.3.mlp.experts.20" -> "model.layers.3.mlp.experts.20.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.21" [label="1"];
  "model.layers.3.mlp.experts.21" -> "model.layers.3.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.21" -> "model.layers.3.mlp.experts.21.act_fn" [label="1"];
  "model.layers.3.mlp.experts.21" -> "model.layers.3.mlp.experts.21.up_proj" [label="1"];
  "model.layers.3.mlp.experts.21" -> "model.layers.3.mlp.experts.21.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.22" [label="1"];
  "model.layers.3.mlp.experts.22" -> "model.layers.3.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.22" -> "model.layers.3.mlp.experts.22.act_fn" [label="1"];
  "model.layers.3.mlp.experts.22" -> "model.layers.3.mlp.experts.22.up_proj" [label="1"];
  "model.layers.3.mlp.experts.22" -> "model.layers.3.mlp.experts.22.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.23" [label="1"];
  "model.layers.3.mlp.experts.23" -> "model.layers.3.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.23" -> "model.layers.3.mlp.experts.23.act_fn" [label="1"];
  "model.layers.3.mlp.experts.23" -> "model.layers.3.mlp.experts.23.up_proj" [label="1"];
  "model.layers.3.mlp.experts.23" -> "model.layers.3.mlp.experts.23.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.24" [label="1"];
  "model.layers.3.mlp.experts.24" -> "model.layers.3.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.24" -> "model.layers.3.mlp.experts.24.act_fn" [label="1"];
  "model.layers.3.mlp.experts.24" -> "model.layers.3.mlp.experts.24.up_proj" [label="1"];
  "model.layers.3.mlp.experts.24" -> "model.layers.3.mlp.experts.24.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.25" [label="1"];
  "model.layers.3.mlp.experts.25" -> "model.layers.3.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.25" -> "model.layers.3.mlp.experts.25.act_fn" [label="1"];
  "model.layers.3.mlp.experts.25" -> "model.layers.3.mlp.experts.25.up_proj" [label="1"];
  "model.layers.3.mlp.experts.25" -> "model.layers.3.mlp.experts.25.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.26" [label="1"];
  "model.layers.3.mlp.experts.26" -> "model.layers.3.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.26" -> "model.layers.3.mlp.experts.26.act_fn" [label="1"];
  "model.layers.3.mlp.experts.26" -> "model.layers.3.mlp.experts.26.up_proj" [label="1"];
  "model.layers.3.mlp.experts.26" -> "model.layers.3.mlp.experts.26.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.27" [label="1"];
  "model.layers.3.mlp.experts.27" -> "model.layers.3.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.27" -> "model.layers.3.mlp.experts.27.act_fn" [label="1"];
  "model.layers.3.mlp.experts.27" -> "model.layers.3.mlp.experts.27.up_proj" [label="1"];
  "model.layers.3.mlp.experts.27" -> "model.layers.3.mlp.experts.27.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.28" [label="1"];
  "model.layers.3.mlp.experts.28" -> "model.layers.3.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.28" -> "model.layers.3.mlp.experts.28.act_fn" [label="1"];
  "model.layers.3.mlp.experts.28" -> "model.layers.3.mlp.experts.28.up_proj" [label="1"];
  "model.layers.3.mlp.experts.28" -> "model.layers.3.mlp.experts.28.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.29" [label="1"];
  "model.layers.3.mlp.experts.29" -> "model.layers.3.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.29" -> "model.layers.3.mlp.experts.29.act_fn" [label="1"];
  "model.layers.3.mlp.experts.29" -> "model.layers.3.mlp.experts.29.up_proj" [label="1"];
  "model.layers.3.mlp.experts.29" -> "model.layers.3.mlp.experts.29.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.30" [label="1"];
  "model.layers.3.mlp.experts.30" -> "model.layers.3.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.30" -> "model.layers.3.mlp.experts.30.act_fn" [label="1"];
  "model.layers.3.mlp.experts.30" -> "model.layers.3.mlp.experts.30.up_proj" [label="1"];
  "model.layers.3.mlp.experts.30" -> "model.layers.3.mlp.experts.30.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.31" [label="1"];
  "model.layers.3.mlp.experts.31" -> "model.layers.3.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.31" -> "model.layers.3.mlp.experts.31.act_fn" [label="1"];
  "model.layers.3.mlp.experts.31" -> "model.layers.3.mlp.experts.31.up_proj" [label="1"];
  "model.layers.3.mlp.experts.31" -> "model.layers.3.mlp.experts.31.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.32" [label="1"];
  "model.layers.3.mlp.experts.32" -> "model.layers.3.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.32" -> "model.layers.3.mlp.experts.32.act_fn" [label="1"];
  "model.layers.3.mlp.experts.32" -> "model.layers.3.mlp.experts.32.up_proj" [label="1"];
  "model.layers.3.mlp.experts.32" -> "model.layers.3.mlp.experts.32.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.33" [label="1"];
  "model.layers.3.mlp.experts.33" -> "model.layers.3.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.33" -> "model.layers.3.mlp.experts.33.act_fn" [label="1"];
  "model.layers.3.mlp.experts.33" -> "model.layers.3.mlp.experts.33.up_proj" [label="1"];
  "model.layers.3.mlp.experts.33" -> "model.layers.3.mlp.experts.33.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.34" [label="1"];
  "model.layers.3.mlp.experts.34" -> "model.layers.3.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.34" -> "model.layers.3.mlp.experts.34.act_fn" [label="1"];
  "model.layers.3.mlp.experts.34" -> "model.layers.3.mlp.experts.34.up_proj" [label="1"];
  "model.layers.3.mlp.experts.34" -> "model.layers.3.mlp.experts.34.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.35" [label="1"];
  "model.layers.3.mlp.experts.35" -> "model.layers.3.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.35" -> "model.layers.3.mlp.experts.35.act_fn" [label="1"];
  "model.layers.3.mlp.experts.35" -> "model.layers.3.mlp.experts.35.up_proj" [label="1"];
  "model.layers.3.mlp.experts.35" -> "model.layers.3.mlp.experts.35.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.36" [label="1"];
  "model.layers.3.mlp.experts.36" -> "model.layers.3.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.36" -> "model.layers.3.mlp.experts.36.act_fn" [label="1"];
  "model.layers.3.mlp.experts.36" -> "model.layers.3.mlp.experts.36.up_proj" [label="1"];
  "model.layers.3.mlp.experts.36" -> "model.layers.3.mlp.experts.36.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.37" [label="1"];
  "model.layers.3.mlp.experts.37" -> "model.layers.3.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.37" -> "model.layers.3.mlp.experts.37.act_fn" [label="1"];
  "model.layers.3.mlp.experts.37" -> "model.layers.3.mlp.experts.37.up_proj" [label="1"];
  "model.layers.3.mlp.experts.37" -> "model.layers.3.mlp.experts.37.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.38" [label="1"];
  "model.layers.3.mlp.experts.38" -> "model.layers.3.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.38" -> "model.layers.3.mlp.experts.38.act_fn" [label="1"];
  "model.layers.3.mlp.experts.38" -> "model.layers.3.mlp.experts.38.up_proj" [label="1"];
  "model.layers.3.mlp.experts.38" -> "model.layers.3.mlp.experts.38.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.39" [label="1"];
  "model.layers.3.mlp.experts.39" -> "model.layers.3.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.39" -> "model.layers.3.mlp.experts.39.act_fn" [label="1"];
  "model.layers.3.mlp.experts.39" -> "model.layers.3.mlp.experts.39.up_proj" [label="1"];
  "model.layers.3.mlp.experts.39" -> "model.layers.3.mlp.experts.39.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.40" [label="1"];
  "model.layers.3.mlp.experts.40" -> "model.layers.3.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.40" -> "model.layers.3.mlp.experts.40.act_fn" [label="1"];
  "model.layers.3.mlp.experts.40" -> "model.layers.3.mlp.experts.40.up_proj" [label="1"];
  "model.layers.3.mlp.experts.40" -> "model.layers.3.mlp.experts.40.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.41" [label="1"];
  "model.layers.3.mlp.experts.41" -> "model.layers.3.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.41" -> "model.layers.3.mlp.experts.41.act_fn" [label="1"];
  "model.layers.3.mlp.experts.41" -> "model.layers.3.mlp.experts.41.up_proj" [label="1"];
  "model.layers.3.mlp.experts.41" -> "model.layers.3.mlp.experts.41.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.42" [label="1"];
  "model.layers.3.mlp.experts.42" -> "model.layers.3.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.42" -> "model.layers.3.mlp.experts.42.act_fn" [label="1"];
  "model.layers.3.mlp.experts.42" -> "model.layers.3.mlp.experts.42.up_proj" [label="1"];
  "model.layers.3.mlp.experts.42" -> "model.layers.3.mlp.experts.42.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.43" [label="1"];
  "model.layers.3.mlp.experts.43" -> "model.layers.3.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.43" -> "model.layers.3.mlp.experts.43.act_fn" [label="1"];
  "model.layers.3.mlp.experts.43" -> "model.layers.3.mlp.experts.43.up_proj" [label="1"];
  "model.layers.3.mlp.experts.43" -> "model.layers.3.mlp.experts.43.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.44" [label="1"];
  "model.layers.3.mlp.experts.44" -> "model.layers.3.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.44" -> "model.layers.3.mlp.experts.44.act_fn" [label="1"];
  "model.layers.3.mlp.experts.44" -> "model.layers.3.mlp.experts.44.up_proj" [label="1"];
  "model.layers.3.mlp.experts.44" -> "model.layers.3.mlp.experts.44.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.45" [label="1"];
  "model.layers.3.mlp.experts.45" -> "model.layers.3.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.45" -> "model.layers.3.mlp.experts.45.act_fn" [label="1"];
  "model.layers.3.mlp.experts.45" -> "model.layers.3.mlp.experts.45.up_proj" [label="1"];
  "model.layers.3.mlp.experts.45" -> "model.layers.3.mlp.experts.45.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.46" [label="1"];
  "model.layers.3.mlp.experts.46" -> "model.layers.3.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.46" -> "model.layers.3.mlp.experts.46.act_fn" [label="1"];
  "model.layers.3.mlp.experts.46" -> "model.layers.3.mlp.experts.46.up_proj" [label="1"];
  "model.layers.3.mlp.experts.46" -> "model.layers.3.mlp.experts.46.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.47" [label="1"];
  "model.layers.3.mlp.experts.47" -> "model.layers.3.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.47" -> "model.layers.3.mlp.experts.47.act_fn" [label="1"];
  "model.layers.3.mlp.experts.47" -> "model.layers.3.mlp.experts.47.up_proj" [label="1"];
  "model.layers.3.mlp.experts.47" -> "model.layers.3.mlp.experts.47.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.48" [label="1"];
  "model.layers.3.mlp.experts.48" -> "model.layers.3.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.48" -> "model.layers.3.mlp.experts.48.act_fn" [label="1"];
  "model.layers.3.mlp.experts.48" -> "model.layers.3.mlp.experts.48.up_proj" [label="1"];
  "model.layers.3.mlp.experts.48" -> "model.layers.3.mlp.experts.48.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.49" [label="1"];
  "model.layers.3.mlp.experts.49" -> "model.layers.3.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.49" -> "model.layers.3.mlp.experts.49.act_fn" [label="1"];
  "model.layers.3.mlp.experts.49" -> "model.layers.3.mlp.experts.49.up_proj" [label="1"];
  "model.layers.3.mlp.experts.49" -> "model.layers.3.mlp.experts.49.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.50" [label="1"];
  "model.layers.3.mlp.experts.50" -> "model.layers.3.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.50" -> "model.layers.3.mlp.experts.50.act_fn" [label="1"];
  "model.layers.3.mlp.experts.50" -> "model.layers.3.mlp.experts.50.up_proj" [label="1"];
  "model.layers.3.mlp.experts.50" -> "model.layers.3.mlp.experts.50.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.51" [label="1"];
  "model.layers.3.mlp.experts.51" -> "model.layers.3.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.51" -> "model.layers.3.mlp.experts.51.act_fn" [label="1"];
  "model.layers.3.mlp.experts.51" -> "model.layers.3.mlp.experts.51.up_proj" [label="1"];
  "model.layers.3.mlp.experts.51" -> "model.layers.3.mlp.experts.51.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.52" [label="1"];
  "model.layers.3.mlp.experts.52" -> "model.layers.3.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.52" -> "model.layers.3.mlp.experts.52.act_fn" [label="1"];
  "model.layers.3.mlp.experts.52" -> "model.layers.3.mlp.experts.52.up_proj" [label="1"];
  "model.layers.3.mlp.experts.52" -> "model.layers.3.mlp.experts.52.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.54" [label="1"];
  "model.layers.3.mlp.experts.54" -> "model.layers.3.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.54" -> "model.layers.3.mlp.experts.54.act_fn" [label="1"];
  "model.layers.3.mlp.experts.54" -> "model.layers.3.mlp.experts.54.up_proj" [label="1"];
  "model.layers.3.mlp.experts.54" -> "model.layers.3.mlp.experts.54.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.55" [label="1"];
  "model.layers.3.mlp.experts.55" -> "model.layers.3.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.55" -> "model.layers.3.mlp.experts.55.act_fn" [label="1"];
  "model.layers.3.mlp.experts.55" -> "model.layers.3.mlp.experts.55.up_proj" [label="1"];
  "model.layers.3.mlp.experts.55" -> "model.layers.3.mlp.experts.55.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.58" [label="1"];
  "model.layers.3.mlp.experts.58" -> "model.layers.3.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.58" -> "model.layers.3.mlp.experts.58.act_fn" [label="1"];
  "model.layers.3.mlp.experts.58" -> "model.layers.3.mlp.experts.58.up_proj" [label="1"];
  "model.layers.3.mlp.experts.58" -> "model.layers.3.mlp.experts.58.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.59" [label="1"];
  "model.layers.3.mlp.experts.59" -> "model.layers.3.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.59" -> "model.layers.3.mlp.experts.59.act_fn" [label="1"];
  "model.layers.3.mlp.experts.59" -> "model.layers.3.mlp.experts.59.up_proj" [label="1"];
  "model.layers.3.mlp.experts.59" -> "model.layers.3.mlp.experts.59.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.60" [label="1"];
  "model.layers.3.mlp.experts.60" -> "model.layers.3.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.60" -> "model.layers.3.mlp.experts.60.act_fn" [label="1"];
  "model.layers.3.mlp.experts.60" -> "model.layers.3.mlp.experts.60.up_proj" [label="1"];
  "model.layers.3.mlp.experts.60" -> "model.layers.3.mlp.experts.60.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.62" [label="1"];
  "model.layers.3.mlp.experts.62" -> "model.layers.3.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.62" -> "model.layers.3.mlp.experts.62.act_fn" [label="1"];
  "model.layers.3.mlp.experts.62" -> "model.layers.3.mlp.experts.62.up_proj" [label="1"];
  "model.layers.3.mlp.experts.62" -> "model.layers.3.mlp.experts.62.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.experts.63" [label="1"];
  "model.layers.3.mlp.experts.63" -> "model.layers.3.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.3.mlp.experts.63" -> "model.layers.3.mlp.experts.63.act_fn" [label="1"];
  "model.layers.3.mlp.experts.63" -> "model.layers.3.mlp.experts.63.up_proj" [label="1"];
  "model.layers.3.mlp.experts.63" -> "model.layers.3.mlp.experts.63.down_proj" [label="1"];
  "model.layers.3.mlp" -> "model.layers.3.mlp.shared_experts" [label="1"];
  "model.layers.3.mlp.shared_experts" -> "model.layers.3.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.3.mlp.shared_experts" -> "model.layers.3.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.3.mlp.shared_experts" -> "model.layers.3.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.3.mlp.shared_experts" -> "model.layers.3.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.4" [label="1"];
  "model.layers.4" -> "model.layers.4.input_layernorm" [label="1"];
  "model.layers.4" -> "model.layers.4.self_attn" [label="1"];
  "model.layers.4.self_attn" -> "model.layers.4.self_attn.q_proj" [label="1"];
  "model.layers.4.self_attn" -> "model.layers.4.self_attn.k_proj" [label="1"];
  "model.layers.4.self_attn" -> "model.layers.4.self_attn.v_proj" [label="1"];
  "model.layers.4.self_attn" -> "model.layers.4.self_attn.o_proj" [label="1"];
  "model.layers.4" -> "model.layers.4.post_attention_layernorm" [label="1"];
  "model.layers.4" -> "model.layers.4.mlp" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.gate" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.0" [label="1"];
  "model.layers.4.mlp.experts.0" -> "model.layers.4.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.0" -> "model.layers.4.mlp.experts.0.act_fn" [label="1"];
  "model.layers.4.mlp.experts.0" -> "model.layers.4.mlp.experts.0.up_proj" [label="1"];
  "model.layers.4.mlp.experts.0" -> "model.layers.4.mlp.experts.0.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.1" [label="1"];
  "model.layers.4.mlp.experts.1" -> "model.layers.4.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.1" -> "model.layers.4.mlp.experts.1.act_fn" [label="1"];
  "model.layers.4.mlp.experts.1" -> "model.layers.4.mlp.experts.1.up_proj" [label="1"];
  "model.layers.4.mlp.experts.1" -> "model.layers.4.mlp.experts.1.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.2" [label="1"];
  "model.layers.4.mlp.experts.2" -> "model.layers.4.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.2" -> "model.layers.4.mlp.experts.2.act_fn" [label="1"];
  "model.layers.4.mlp.experts.2" -> "model.layers.4.mlp.experts.2.up_proj" [label="1"];
  "model.layers.4.mlp.experts.2" -> "model.layers.4.mlp.experts.2.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.3" [label="1"];
  "model.layers.4.mlp.experts.3" -> "model.layers.4.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.3" -> "model.layers.4.mlp.experts.3.act_fn" [label="1"];
  "model.layers.4.mlp.experts.3" -> "model.layers.4.mlp.experts.3.up_proj" [label="1"];
  "model.layers.4.mlp.experts.3" -> "model.layers.4.mlp.experts.3.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.4" [label="1"];
  "model.layers.4.mlp.experts.4" -> "model.layers.4.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.4" -> "model.layers.4.mlp.experts.4.act_fn" [label="1"];
  "model.layers.4.mlp.experts.4" -> "model.layers.4.mlp.experts.4.up_proj" [label="1"];
  "model.layers.4.mlp.experts.4" -> "model.layers.4.mlp.experts.4.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.5" [label="1"];
  "model.layers.4.mlp.experts.5" -> "model.layers.4.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.5" -> "model.layers.4.mlp.experts.5.act_fn" [label="1"];
  "model.layers.4.mlp.experts.5" -> "model.layers.4.mlp.experts.5.up_proj" [label="1"];
  "model.layers.4.mlp.experts.5" -> "model.layers.4.mlp.experts.5.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.6" [label="1"];
  "model.layers.4.mlp.experts.6" -> "model.layers.4.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.6" -> "model.layers.4.mlp.experts.6.act_fn" [label="1"];
  "model.layers.4.mlp.experts.6" -> "model.layers.4.mlp.experts.6.up_proj" [label="1"];
  "model.layers.4.mlp.experts.6" -> "model.layers.4.mlp.experts.6.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.7" [label="1"];
  "model.layers.4.mlp.experts.7" -> "model.layers.4.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.7" -> "model.layers.4.mlp.experts.7.act_fn" [label="1"];
  "model.layers.4.mlp.experts.7" -> "model.layers.4.mlp.experts.7.up_proj" [label="1"];
  "model.layers.4.mlp.experts.7" -> "model.layers.4.mlp.experts.7.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.8" [label="1"];
  "model.layers.4.mlp.experts.8" -> "model.layers.4.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.8" -> "model.layers.4.mlp.experts.8.act_fn" [label="1"];
  "model.layers.4.mlp.experts.8" -> "model.layers.4.mlp.experts.8.up_proj" [label="1"];
  "model.layers.4.mlp.experts.8" -> "model.layers.4.mlp.experts.8.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.9" [label="1"];
  "model.layers.4.mlp.experts.9" -> "model.layers.4.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.9" -> "model.layers.4.mlp.experts.9.act_fn" [label="1"];
  "model.layers.4.mlp.experts.9" -> "model.layers.4.mlp.experts.9.up_proj" [label="1"];
  "model.layers.4.mlp.experts.9" -> "model.layers.4.mlp.experts.9.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.10" [label="1"];
  "model.layers.4.mlp.experts.10" -> "model.layers.4.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.10" -> "model.layers.4.mlp.experts.10.act_fn" [label="1"];
  "model.layers.4.mlp.experts.10" -> "model.layers.4.mlp.experts.10.up_proj" [label="1"];
  "model.layers.4.mlp.experts.10" -> "model.layers.4.mlp.experts.10.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.11" [label="1"];
  "model.layers.4.mlp.experts.11" -> "model.layers.4.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.11" -> "model.layers.4.mlp.experts.11.act_fn" [label="1"];
  "model.layers.4.mlp.experts.11" -> "model.layers.4.mlp.experts.11.up_proj" [label="1"];
  "model.layers.4.mlp.experts.11" -> "model.layers.4.mlp.experts.11.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.12" [label="1"];
  "model.layers.4.mlp.experts.12" -> "model.layers.4.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.12" -> "model.layers.4.mlp.experts.12.act_fn" [label="1"];
  "model.layers.4.mlp.experts.12" -> "model.layers.4.mlp.experts.12.up_proj" [label="1"];
  "model.layers.4.mlp.experts.12" -> "model.layers.4.mlp.experts.12.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.13" [label="1"];
  "model.layers.4.mlp.experts.13" -> "model.layers.4.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.13" -> "model.layers.4.mlp.experts.13.act_fn" [label="1"];
  "model.layers.4.mlp.experts.13" -> "model.layers.4.mlp.experts.13.up_proj" [label="1"];
  "model.layers.4.mlp.experts.13" -> "model.layers.4.mlp.experts.13.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.14" [label="1"];
  "model.layers.4.mlp.experts.14" -> "model.layers.4.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.14" -> "model.layers.4.mlp.experts.14.act_fn" [label="1"];
  "model.layers.4.mlp.experts.14" -> "model.layers.4.mlp.experts.14.up_proj" [label="1"];
  "model.layers.4.mlp.experts.14" -> "model.layers.4.mlp.experts.14.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.15" [label="1"];
  "model.layers.4.mlp.experts.15" -> "model.layers.4.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.15" -> "model.layers.4.mlp.experts.15.act_fn" [label="1"];
  "model.layers.4.mlp.experts.15" -> "model.layers.4.mlp.experts.15.up_proj" [label="1"];
  "model.layers.4.mlp.experts.15" -> "model.layers.4.mlp.experts.15.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.16" [label="1"];
  "model.layers.4.mlp.experts.16" -> "model.layers.4.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.16" -> "model.layers.4.mlp.experts.16.act_fn" [label="1"];
  "model.layers.4.mlp.experts.16" -> "model.layers.4.mlp.experts.16.up_proj" [label="1"];
  "model.layers.4.mlp.experts.16" -> "model.layers.4.mlp.experts.16.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.17" [label="1"];
  "model.layers.4.mlp.experts.17" -> "model.layers.4.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.17" -> "model.layers.4.mlp.experts.17.act_fn" [label="1"];
  "model.layers.4.mlp.experts.17" -> "model.layers.4.mlp.experts.17.up_proj" [label="1"];
  "model.layers.4.mlp.experts.17" -> "model.layers.4.mlp.experts.17.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.18" [label="1"];
  "model.layers.4.mlp.experts.18" -> "model.layers.4.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.18" -> "model.layers.4.mlp.experts.18.act_fn" [label="1"];
  "model.layers.4.mlp.experts.18" -> "model.layers.4.mlp.experts.18.up_proj" [label="1"];
  "model.layers.4.mlp.experts.18" -> "model.layers.4.mlp.experts.18.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.19" [label="1"];
  "model.layers.4.mlp.experts.19" -> "model.layers.4.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.19" -> "model.layers.4.mlp.experts.19.act_fn" [label="1"];
  "model.layers.4.mlp.experts.19" -> "model.layers.4.mlp.experts.19.up_proj" [label="1"];
  "model.layers.4.mlp.experts.19" -> "model.layers.4.mlp.experts.19.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.20" [label="1"];
  "model.layers.4.mlp.experts.20" -> "model.layers.4.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.20" -> "model.layers.4.mlp.experts.20.act_fn" [label="1"];
  "model.layers.4.mlp.experts.20" -> "model.layers.4.mlp.experts.20.up_proj" [label="1"];
  "model.layers.4.mlp.experts.20" -> "model.layers.4.mlp.experts.20.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.21" [label="1"];
  "model.layers.4.mlp.experts.21" -> "model.layers.4.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.21" -> "model.layers.4.mlp.experts.21.act_fn" [label="1"];
  "model.layers.4.mlp.experts.21" -> "model.layers.4.mlp.experts.21.up_proj" [label="1"];
  "model.layers.4.mlp.experts.21" -> "model.layers.4.mlp.experts.21.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.22" [label="1"];
  "model.layers.4.mlp.experts.22" -> "model.layers.4.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.22" -> "model.layers.4.mlp.experts.22.act_fn" [label="1"];
  "model.layers.4.mlp.experts.22" -> "model.layers.4.mlp.experts.22.up_proj" [label="1"];
  "model.layers.4.mlp.experts.22" -> "model.layers.4.mlp.experts.22.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.23" [label="1"];
  "model.layers.4.mlp.experts.23" -> "model.layers.4.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.23" -> "model.layers.4.mlp.experts.23.act_fn" [label="1"];
  "model.layers.4.mlp.experts.23" -> "model.layers.4.mlp.experts.23.up_proj" [label="1"];
  "model.layers.4.mlp.experts.23" -> "model.layers.4.mlp.experts.23.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.24" [label="1"];
  "model.layers.4.mlp.experts.24" -> "model.layers.4.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.24" -> "model.layers.4.mlp.experts.24.act_fn" [label="1"];
  "model.layers.4.mlp.experts.24" -> "model.layers.4.mlp.experts.24.up_proj" [label="1"];
  "model.layers.4.mlp.experts.24" -> "model.layers.4.mlp.experts.24.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.25" [label="1"];
  "model.layers.4.mlp.experts.25" -> "model.layers.4.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.25" -> "model.layers.4.mlp.experts.25.act_fn" [label="1"];
  "model.layers.4.mlp.experts.25" -> "model.layers.4.mlp.experts.25.up_proj" [label="1"];
  "model.layers.4.mlp.experts.25" -> "model.layers.4.mlp.experts.25.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.26" [label="1"];
  "model.layers.4.mlp.experts.26" -> "model.layers.4.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.26" -> "model.layers.4.mlp.experts.26.act_fn" [label="1"];
  "model.layers.4.mlp.experts.26" -> "model.layers.4.mlp.experts.26.up_proj" [label="1"];
  "model.layers.4.mlp.experts.26" -> "model.layers.4.mlp.experts.26.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.27" [label="1"];
  "model.layers.4.mlp.experts.27" -> "model.layers.4.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.27" -> "model.layers.4.mlp.experts.27.act_fn" [label="1"];
  "model.layers.4.mlp.experts.27" -> "model.layers.4.mlp.experts.27.up_proj" [label="1"];
  "model.layers.4.mlp.experts.27" -> "model.layers.4.mlp.experts.27.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.28" [label="1"];
  "model.layers.4.mlp.experts.28" -> "model.layers.4.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.28" -> "model.layers.4.mlp.experts.28.act_fn" [label="1"];
  "model.layers.4.mlp.experts.28" -> "model.layers.4.mlp.experts.28.up_proj" [label="1"];
  "model.layers.4.mlp.experts.28" -> "model.layers.4.mlp.experts.28.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.30" [label="1"];
  "model.layers.4.mlp.experts.30" -> "model.layers.4.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.30" -> "model.layers.4.mlp.experts.30.act_fn" [label="1"];
  "model.layers.4.mlp.experts.30" -> "model.layers.4.mlp.experts.30.up_proj" [label="1"];
  "model.layers.4.mlp.experts.30" -> "model.layers.4.mlp.experts.30.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.31" [label="1"];
  "model.layers.4.mlp.experts.31" -> "model.layers.4.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.31" -> "model.layers.4.mlp.experts.31.act_fn" [label="1"];
  "model.layers.4.mlp.experts.31" -> "model.layers.4.mlp.experts.31.up_proj" [label="1"];
  "model.layers.4.mlp.experts.31" -> "model.layers.4.mlp.experts.31.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.32" [label="1"];
  "model.layers.4.mlp.experts.32" -> "model.layers.4.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.32" -> "model.layers.4.mlp.experts.32.act_fn" [label="1"];
  "model.layers.4.mlp.experts.32" -> "model.layers.4.mlp.experts.32.up_proj" [label="1"];
  "model.layers.4.mlp.experts.32" -> "model.layers.4.mlp.experts.32.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.33" [label="1"];
  "model.layers.4.mlp.experts.33" -> "model.layers.4.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.33" -> "model.layers.4.mlp.experts.33.act_fn" [label="1"];
  "model.layers.4.mlp.experts.33" -> "model.layers.4.mlp.experts.33.up_proj" [label="1"];
  "model.layers.4.mlp.experts.33" -> "model.layers.4.mlp.experts.33.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.34" [label="1"];
  "model.layers.4.mlp.experts.34" -> "model.layers.4.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.34" -> "model.layers.4.mlp.experts.34.act_fn" [label="1"];
  "model.layers.4.mlp.experts.34" -> "model.layers.4.mlp.experts.34.up_proj" [label="1"];
  "model.layers.4.mlp.experts.34" -> "model.layers.4.mlp.experts.34.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.35" [label="1"];
  "model.layers.4.mlp.experts.35" -> "model.layers.4.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.35" -> "model.layers.4.mlp.experts.35.act_fn" [label="1"];
  "model.layers.4.mlp.experts.35" -> "model.layers.4.mlp.experts.35.up_proj" [label="1"];
  "model.layers.4.mlp.experts.35" -> "model.layers.4.mlp.experts.35.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.36" [label="1"];
  "model.layers.4.mlp.experts.36" -> "model.layers.4.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.36" -> "model.layers.4.mlp.experts.36.act_fn" [label="1"];
  "model.layers.4.mlp.experts.36" -> "model.layers.4.mlp.experts.36.up_proj" [label="1"];
  "model.layers.4.mlp.experts.36" -> "model.layers.4.mlp.experts.36.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.37" [label="1"];
  "model.layers.4.mlp.experts.37" -> "model.layers.4.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.37" -> "model.layers.4.mlp.experts.37.act_fn" [label="1"];
  "model.layers.4.mlp.experts.37" -> "model.layers.4.mlp.experts.37.up_proj" [label="1"];
  "model.layers.4.mlp.experts.37" -> "model.layers.4.mlp.experts.37.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.39" [label="1"];
  "model.layers.4.mlp.experts.39" -> "model.layers.4.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.39" -> "model.layers.4.mlp.experts.39.act_fn" [label="1"];
  "model.layers.4.mlp.experts.39" -> "model.layers.4.mlp.experts.39.up_proj" [label="1"];
  "model.layers.4.mlp.experts.39" -> "model.layers.4.mlp.experts.39.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.40" [label="1"];
  "model.layers.4.mlp.experts.40" -> "model.layers.4.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.40" -> "model.layers.4.mlp.experts.40.act_fn" [label="1"];
  "model.layers.4.mlp.experts.40" -> "model.layers.4.mlp.experts.40.up_proj" [label="1"];
  "model.layers.4.mlp.experts.40" -> "model.layers.4.mlp.experts.40.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.41" [label="1"];
  "model.layers.4.mlp.experts.41" -> "model.layers.4.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.41" -> "model.layers.4.mlp.experts.41.act_fn" [label="1"];
  "model.layers.4.mlp.experts.41" -> "model.layers.4.mlp.experts.41.up_proj" [label="1"];
  "model.layers.4.mlp.experts.41" -> "model.layers.4.mlp.experts.41.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.42" [label="1"];
  "model.layers.4.mlp.experts.42" -> "model.layers.4.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.42" -> "model.layers.4.mlp.experts.42.act_fn" [label="1"];
  "model.layers.4.mlp.experts.42" -> "model.layers.4.mlp.experts.42.up_proj" [label="1"];
  "model.layers.4.mlp.experts.42" -> "model.layers.4.mlp.experts.42.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.44" [label="1"];
  "model.layers.4.mlp.experts.44" -> "model.layers.4.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.44" -> "model.layers.4.mlp.experts.44.act_fn" [label="1"];
  "model.layers.4.mlp.experts.44" -> "model.layers.4.mlp.experts.44.up_proj" [label="1"];
  "model.layers.4.mlp.experts.44" -> "model.layers.4.mlp.experts.44.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.45" [label="1"];
  "model.layers.4.mlp.experts.45" -> "model.layers.4.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.45" -> "model.layers.4.mlp.experts.45.act_fn" [label="1"];
  "model.layers.4.mlp.experts.45" -> "model.layers.4.mlp.experts.45.up_proj" [label="1"];
  "model.layers.4.mlp.experts.45" -> "model.layers.4.mlp.experts.45.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.46" [label="1"];
  "model.layers.4.mlp.experts.46" -> "model.layers.4.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.46" -> "model.layers.4.mlp.experts.46.act_fn" [label="1"];
  "model.layers.4.mlp.experts.46" -> "model.layers.4.mlp.experts.46.up_proj" [label="1"];
  "model.layers.4.mlp.experts.46" -> "model.layers.4.mlp.experts.46.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.47" [label="1"];
  "model.layers.4.mlp.experts.47" -> "model.layers.4.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.47" -> "model.layers.4.mlp.experts.47.act_fn" [label="1"];
  "model.layers.4.mlp.experts.47" -> "model.layers.4.mlp.experts.47.up_proj" [label="1"];
  "model.layers.4.mlp.experts.47" -> "model.layers.4.mlp.experts.47.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.48" [label="1"];
  "model.layers.4.mlp.experts.48" -> "model.layers.4.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.48" -> "model.layers.4.mlp.experts.48.act_fn" [label="1"];
  "model.layers.4.mlp.experts.48" -> "model.layers.4.mlp.experts.48.up_proj" [label="1"];
  "model.layers.4.mlp.experts.48" -> "model.layers.4.mlp.experts.48.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.49" [label="1"];
  "model.layers.4.mlp.experts.49" -> "model.layers.4.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.49" -> "model.layers.4.mlp.experts.49.act_fn" [label="1"];
  "model.layers.4.mlp.experts.49" -> "model.layers.4.mlp.experts.49.up_proj" [label="1"];
  "model.layers.4.mlp.experts.49" -> "model.layers.4.mlp.experts.49.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.51" [label="1"];
  "model.layers.4.mlp.experts.51" -> "model.layers.4.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.51" -> "model.layers.4.mlp.experts.51.act_fn" [label="1"];
  "model.layers.4.mlp.experts.51" -> "model.layers.4.mlp.experts.51.up_proj" [label="1"];
  "model.layers.4.mlp.experts.51" -> "model.layers.4.mlp.experts.51.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.52" [label="1"];
  "model.layers.4.mlp.experts.52" -> "model.layers.4.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.52" -> "model.layers.4.mlp.experts.52.act_fn" [label="1"];
  "model.layers.4.mlp.experts.52" -> "model.layers.4.mlp.experts.52.up_proj" [label="1"];
  "model.layers.4.mlp.experts.52" -> "model.layers.4.mlp.experts.52.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.53" [label="1"];
  "model.layers.4.mlp.experts.53" -> "model.layers.4.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.53" -> "model.layers.4.mlp.experts.53.act_fn" [label="1"];
  "model.layers.4.mlp.experts.53" -> "model.layers.4.mlp.experts.53.up_proj" [label="1"];
  "model.layers.4.mlp.experts.53" -> "model.layers.4.mlp.experts.53.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.54" [label="1"];
  "model.layers.4.mlp.experts.54" -> "model.layers.4.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.54" -> "model.layers.4.mlp.experts.54.act_fn" [label="1"];
  "model.layers.4.mlp.experts.54" -> "model.layers.4.mlp.experts.54.up_proj" [label="1"];
  "model.layers.4.mlp.experts.54" -> "model.layers.4.mlp.experts.54.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.56" [label="1"];
  "model.layers.4.mlp.experts.56" -> "model.layers.4.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.56" -> "model.layers.4.mlp.experts.56.act_fn" [label="1"];
  "model.layers.4.mlp.experts.56" -> "model.layers.4.mlp.experts.56.up_proj" [label="1"];
  "model.layers.4.mlp.experts.56" -> "model.layers.4.mlp.experts.56.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.58" [label="1"];
  "model.layers.4.mlp.experts.58" -> "model.layers.4.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.58" -> "model.layers.4.mlp.experts.58.act_fn" [label="1"];
  "model.layers.4.mlp.experts.58" -> "model.layers.4.mlp.experts.58.up_proj" [label="1"];
  "model.layers.4.mlp.experts.58" -> "model.layers.4.mlp.experts.58.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.59" [label="1"];
  "model.layers.4.mlp.experts.59" -> "model.layers.4.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.59" -> "model.layers.4.mlp.experts.59.act_fn" [label="1"];
  "model.layers.4.mlp.experts.59" -> "model.layers.4.mlp.experts.59.up_proj" [label="1"];
  "model.layers.4.mlp.experts.59" -> "model.layers.4.mlp.experts.59.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.60" [label="1"];
  "model.layers.4.mlp.experts.60" -> "model.layers.4.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.60" -> "model.layers.4.mlp.experts.60.act_fn" [label="1"];
  "model.layers.4.mlp.experts.60" -> "model.layers.4.mlp.experts.60.up_proj" [label="1"];
  "model.layers.4.mlp.experts.60" -> "model.layers.4.mlp.experts.60.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.61" [label="1"];
  "model.layers.4.mlp.experts.61" -> "model.layers.4.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.61" -> "model.layers.4.mlp.experts.61.act_fn" [label="1"];
  "model.layers.4.mlp.experts.61" -> "model.layers.4.mlp.experts.61.up_proj" [label="1"];
  "model.layers.4.mlp.experts.61" -> "model.layers.4.mlp.experts.61.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.62" [label="1"];
  "model.layers.4.mlp.experts.62" -> "model.layers.4.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.62" -> "model.layers.4.mlp.experts.62.act_fn" [label="1"];
  "model.layers.4.mlp.experts.62" -> "model.layers.4.mlp.experts.62.up_proj" [label="1"];
  "model.layers.4.mlp.experts.62" -> "model.layers.4.mlp.experts.62.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.experts.63" [label="1"];
  "model.layers.4.mlp.experts.63" -> "model.layers.4.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.4.mlp.experts.63" -> "model.layers.4.mlp.experts.63.act_fn" [label="1"];
  "model.layers.4.mlp.experts.63" -> "model.layers.4.mlp.experts.63.up_proj" [label="1"];
  "model.layers.4.mlp.experts.63" -> "model.layers.4.mlp.experts.63.down_proj" [label="1"];
  "model.layers.4.mlp" -> "model.layers.4.mlp.shared_experts" [label="1"];
  "model.layers.4.mlp.shared_experts" -> "model.layers.4.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.4.mlp.shared_experts" -> "model.layers.4.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.4.mlp.shared_experts" -> "model.layers.4.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.4.mlp.shared_experts" -> "model.layers.4.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.5" [label="1"];
  "model.layers.5" -> "model.layers.5.input_layernorm" [label="1"];
  "model.layers.5" -> "model.layers.5.self_attn" [label="1"];
  "model.layers.5.self_attn" -> "model.layers.5.self_attn.q_proj" [label="1"];
  "model.layers.5.self_attn" -> "model.layers.5.self_attn.k_proj" [label="1"];
  "model.layers.5.self_attn" -> "model.layers.5.self_attn.v_proj" [label="1"];
  "model.layers.5.self_attn" -> "model.layers.5.self_attn.o_proj" [label="1"];
  "model.layers.5" -> "model.layers.5.post_attention_layernorm" [label="1"];
  "model.layers.5" -> "model.layers.5.mlp" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.gate" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.0" [label="1"];
  "model.layers.5.mlp.experts.0" -> "model.layers.5.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.0" -> "model.layers.5.mlp.experts.0.act_fn" [label="1"];
  "model.layers.5.mlp.experts.0" -> "model.layers.5.mlp.experts.0.up_proj" [label="1"];
  "model.layers.5.mlp.experts.0" -> "model.layers.5.mlp.experts.0.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.1" [label="1"];
  "model.layers.5.mlp.experts.1" -> "model.layers.5.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.1" -> "model.layers.5.mlp.experts.1.act_fn" [label="1"];
  "model.layers.5.mlp.experts.1" -> "model.layers.5.mlp.experts.1.up_proj" [label="1"];
  "model.layers.5.mlp.experts.1" -> "model.layers.5.mlp.experts.1.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.2" [label="1"];
  "model.layers.5.mlp.experts.2" -> "model.layers.5.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.2" -> "model.layers.5.mlp.experts.2.act_fn" [label="1"];
  "model.layers.5.mlp.experts.2" -> "model.layers.5.mlp.experts.2.up_proj" [label="1"];
  "model.layers.5.mlp.experts.2" -> "model.layers.5.mlp.experts.2.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.3" [label="1"];
  "model.layers.5.mlp.experts.3" -> "model.layers.5.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.3" -> "model.layers.5.mlp.experts.3.act_fn" [label="1"];
  "model.layers.5.mlp.experts.3" -> "model.layers.5.mlp.experts.3.up_proj" [label="1"];
  "model.layers.5.mlp.experts.3" -> "model.layers.5.mlp.experts.3.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.4" [label="1"];
  "model.layers.5.mlp.experts.4" -> "model.layers.5.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.4" -> "model.layers.5.mlp.experts.4.act_fn" [label="1"];
  "model.layers.5.mlp.experts.4" -> "model.layers.5.mlp.experts.4.up_proj" [label="1"];
  "model.layers.5.mlp.experts.4" -> "model.layers.5.mlp.experts.4.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.5" [label="1"];
  "model.layers.5.mlp.experts.5" -> "model.layers.5.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.5" -> "model.layers.5.mlp.experts.5.act_fn" [label="1"];
  "model.layers.5.mlp.experts.5" -> "model.layers.5.mlp.experts.5.up_proj" [label="1"];
  "model.layers.5.mlp.experts.5" -> "model.layers.5.mlp.experts.5.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.6" [label="1"];
  "model.layers.5.mlp.experts.6" -> "model.layers.5.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.6" -> "model.layers.5.mlp.experts.6.act_fn" [label="1"];
  "model.layers.5.mlp.experts.6" -> "model.layers.5.mlp.experts.6.up_proj" [label="1"];
  "model.layers.5.mlp.experts.6" -> "model.layers.5.mlp.experts.6.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.8" [label="1"];
  "model.layers.5.mlp.experts.8" -> "model.layers.5.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.8" -> "model.layers.5.mlp.experts.8.act_fn" [label="1"];
  "model.layers.5.mlp.experts.8" -> "model.layers.5.mlp.experts.8.up_proj" [label="1"];
  "model.layers.5.mlp.experts.8" -> "model.layers.5.mlp.experts.8.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.9" [label="1"];
  "model.layers.5.mlp.experts.9" -> "model.layers.5.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.9" -> "model.layers.5.mlp.experts.9.act_fn" [label="1"];
  "model.layers.5.mlp.experts.9" -> "model.layers.5.mlp.experts.9.up_proj" [label="1"];
  "model.layers.5.mlp.experts.9" -> "model.layers.5.mlp.experts.9.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.10" [label="1"];
  "model.layers.5.mlp.experts.10" -> "model.layers.5.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.10" -> "model.layers.5.mlp.experts.10.act_fn" [label="1"];
  "model.layers.5.mlp.experts.10" -> "model.layers.5.mlp.experts.10.up_proj" [label="1"];
  "model.layers.5.mlp.experts.10" -> "model.layers.5.mlp.experts.10.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.12" [label="1"];
  "model.layers.5.mlp.experts.12" -> "model.layers.5.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.12" -> "model.layers.5.mlp.experts.12.act_fn" [label="1"];
  "model.layers.5.mlp.experts.12" -> "model.layers.5.mlp.experts.12.up_proj" [label="1"];
  "model.layers.5.mlp.experts.12" -> "model.layers.5.mlp.experts.12.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.13" [label="1"];
  "model.layers.5.mlp.experts.13" -> "model.layers.5.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.13" -> "model.layers.5.mlp.experts.13.act_fn" [label="1"];
  "model.layers.5.mlp.experts.13" -> "model.layers.5.mlp.experts.13.up_proj" [label="1"];
  "model.layers.5.mlp.experts.13" -> "model.layers.5.mlp.experts.13.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.14" [label="1"];
  "model.layers.5.mlp.experts.14" -> "model.layers.5.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.14" -> "model.layers.5.mlp.experts.14.act_fn" [label="1"];
  "model.layers.5.mlp.experts.14" -> "model.layers.5.mlp.experts.14.up_proj" [label="1"];
  "model.layers.5.mlp.experts.14" -> "model.layers.5.mlp.experts.14.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.15" [label="1"];
  "model.layers.5.mlp.experts.15" -> "model.layers.5.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.15" -> "model.layers.5.mlp.experts.15.act_fn" [label="1"];
  "model.layers.5.mlp.experts.15" -> "model.layers.5.mlp.experts.15.up_proj" [label="1"];
  "model.layers.5.mlp.experts.15" -> "model.layers.5.mlp.experts.15.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.16" [label="1"];
  "model.layers.5.mlp.experts.16" -> "model.layers.5.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.16" -> "model.layers.5.mlp.experts.16.act_fn" [label="1"];
  "model.layers.5.mlp.experts.16" -> "model.layers.5.mlp.experts.16.up_proj" [label="1"];
  "model.layers.5.mlp.experts.16" -> "model.layers.5.mlp.experts.16.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.17" [label="1"];
  "model.layers.5.mlp.experts.17" -> "model.layers.5.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.17" -> "model.layers.5.mlp.experts.17.act_fn" [label="1"];
  "model.layers.5.mlp.experts.17" -> "model.layers.5.mlp.experts.17.up_proj" [label="1"];
  "model.layers.5.mlp.experts.17" -> "model.layers.5.mlp.experts.17.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.18" [label="1"];
  "model.layers.5.mlp.experts.18" -> "model.layers.5.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.18" -> "model.layers.5.mlp.experts.18.act_fn" [label="1"];
  "model.layers.5.mlp.experts.18" -> "model.layers.5.mlp.experts.18.up_proj" [label="1"];
  "model.layers.5.mlp.experts.18" -> "model.layers.5.mlp.experts.18.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.19" [label="1"];
  "model.layers.5.mlp.experts.19" -> "model.layers.5.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.19" -> "model.layers.5.mlp.experts.19.act_fn" [label="1"];
  "model.layers.5.mlp.experts.19" -> "model.layers.5.mlp.experts.19.up_proj" [label="1"];
  "model.layers.5.mlp.experts.19" -> "model.layers.5.mlp.experts.19.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.20" [label="1"];
  "model.layers.5.mlp.experts.20" -> "model.layers.5.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.20" -> "model.layers.5.mlp.experts.20.act_fn" [label="1"];
  "model.layers.5.mlp.experts.20" -> "model.layers.5.mlp.experts.20.up_proj" [label="1"];
  "model.layers.5.mlp.experts.20" -> "model.layers.5.mlp.experts.20.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.21" [label="1"];
  "model.layers.5.mlp.experts.21" -> "model.layers.5.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.21" -> "model.layers.5.mlp.experts.21.act_fn" [label="1"];
  "model.layers.5.mlp.experts.21" -> "model.layers.5.mlp.experts.21.up_proj" [label="1"];
  "model.layers.5.mlp.experts.21" -> "model.layers.5.mlp.experts.21.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.22" [label="1"];
  "model.layers.5.mlp.experts.22" -> "model.layers.5.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.22" -> "model.layers.5.mlp.experts.22.act_fn" [label="1"];
  "model.layers.5.mlp.experts.22" -> "model.layers.5.mlp.experts.22.up_proj" [label="1"];
  "model.layers.5.mlp.experts.22" -> "model.layers.5.mlp.experts.22.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.23" [label="1"];
  "model.layers.5.mlp.experts.23" -> "model.layers.5.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.23" -> "model.layers.5.mlp.experts.23.act_fn" [label="1"];
  "model.layers.5.mlp.experts.23" -> "model.layers.5.mlp.experts.23.up_proj" [label="1"];
  "model.layers.5.mlp.experts.23" -> "model.layers.5.mlp.experts.23.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.24" [label="1"];
  "model.layers.5.mlp.experts.24" -> "model.layers.5.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.24" -> "model.layers.5.mlp.experts.24.act_fn" [label="1"];
  "model.layers.5.mlp.experts.24" -> "model.layers.5.mlp.experts.24.up_proj" [label="1"];
  "model.layers.5.mlp.experts.24" -> "model.layers.5.mlp.experts.24.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.25" [label="1"];
  "model.layers.5.mlp.experts.25" -> "model.layers.5.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.25" -> "model.layers.5.mlp.experts.25.act_fn" [label="1"];
  "model.layers.5.mlp.experts.25" -> "model.layers.5.mlp.experts.25.up_proj" [label="1"];
  "model.layers.5.mlp.experts.25" -> "model.layers.5.mlp.experts.25.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.27" [label="1"];
  "model.layers.5.mlp.experts.27" -> "model.layers.5.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.27" -> "model.layers.5.mlp.experts.27.act_fn" [label="1"];
  "model.layers.5.mlp.experts.27" -> "model.layers.5.mlp.experts.27.up_proj" [label="1"];
  "model.layers.5.mlp.experts.27" -> "model.layers.5.mlp.experts.27.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.29" [label="1"];
  "model.layers.5.mlp.experts.29" -> "model.layers.5.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.29" -> "model.layers.5.mlp.experts.29.act_fn" [label="1"];
  "model.layers.5.mlp.experts.29" -> "model.layers.5.mlp.experts.29.up_proj" [label="1"];
  "model.layers.5.mlp.experts.29" -> "model.layers.5.mlp.experts.29.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.30" [label="1"];
  "model.layers.5.mlp.experts.30" -> "model.layers.5.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.30" -> "model.layers.5.mlp.experts.30.act_fn" [label="1"];
  "model.layers.5.mlp.experts.30" -> "model.layers.5.mlp.experts.30.up_proj" [label="1"];
  "model.layers.5.mlp.experts.30" -> "model.layers.5.mlp.experts.30.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.31" [label="1"];
  "model.layers.5.mlp.experts.31" -> "model.layers.5.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.31" -> "model.layers.5.mlp.experts.31.act_fn" [label="1"];
  "model.layers.5.mlp.experts.31" -> "model.layers.5.mlp.experts.31.up_proj" [label="1"];
  "model.layers.5.mlp.experts.31" -> "model.layers.5.mlp.experts.31.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.32" [label="1"];
  "model.layers.5.mlp.experts.32" -> "model.layers.5.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.32" -> "model.layers.5.mlp.experts.32.act_fn" [label="1"];
  "model.layers.5.mlp.experts.32" -> "model.layers.5.mlp.experts.32.up_proj" [label="1"];
  "model.layers.5.mlp.experts.32" -> "model.layers.5.mlp.experts.32.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.33" [label="1"];
  "model.layers.5.mlp.experts.33" -> "model.layers.5.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.33" -> "model.layers.5.mlp.experts.33.act_fn" [label="1"];
  "model.layers.5.mlp.experts.33" -> "model.layers.5.mlp.experts.33.up_proj" [label="1"];
  "model.layers.5.mlp.experts.33" -> "model.layers.5.mlp.experts.33.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.34" [label="1"];
  "model.layers.5.mlp.experts.34" -> "model.layers.5.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.34" -> "model.layers.5.mlp.experts.34.act_fn" [label="1"];
  "model.layers.5.mlp.experts.34" -> "model.layers.5.mlp.experts.34.up_proj" [label="1"];
  "model.layers.5.mlp.experts.34" -> "model.layers.5.mlp.experts.34.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.35" [label="1"];
  "model.layers.5.mlp.experts.35" -> "model.layers.5.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.35" -> "model.layers.5.mlp.experts.35.act_fn" [label="1"];
  "model.layers.5.mlp.experts.35" -> "model.layers.5.mlp.experts.35.up_proj" [label="1"];
  "model.layers.5.mlp.experts.35" -> "model.layers.5.mlp.experts.35.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.36" [label="1"];
  "model.layers.5.mlp.experts.36" -> "model.layers.5.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.36" -> "model.layers.5.mlp.experts.36.act_fn" [label="1"];
  "model.layers.5.mlp.experts.36" -> "model.layers.5.mlp.experts.36.up_proj" [label="1"];
  "model.layers.5.mlp.experts.36" -> "model.layers.5.mlp.experts.36.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.37" [label="1"];
  "model.layers.5.mlp.experts.37" -> "model.layers.5.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.37" -> "model.layers.5.mlp.experts.37.act_fn" [label="1"];
  "model.layers.5.mlp.experts.37" -> "model.layers.5.mlp.experts.37.up_proj" [label="1"];
  "model.layers.5.mlp.experts.37" -> "model.layers.5.mlp.experts.37.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.38" [label="1"];
  "model.layers.5.mlp.experts.38" -> "model.layers.5.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.38" -> "model.layers.5.mlp.experts.38.act_fn" [label="1"];
  "model.layers.5.mlp.experts.38" -> "model.layers.5.mlp.experts.38.up_proj" [label="1"];
  "model.layers.5.mlp.experts.38" -> "model.layers.5.mlp.experts.38.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.39" [label="1"];
  "model.layers.5.mlp.experts.39" -> "model.layers.5.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.39" -> "model.layers.5.mlp.experts.39.act_fn" [label="1"];
  "model.layers.5.mlp.experts.39" -> "model.layers.5.mlp.experts.39.up_proj" [label="1"];
  "model.layers.5.mlp.experts.39" -> "model.layers.5.mlp.experts.39.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.40" [label="1"];
  "model.layers.5.mlp.experts.40" -> "model.layers.5.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.40" -> "model.layers.5.mlp.experts.40.act_fn" [label="1"];
  "model.layers.5.mlp.experts.40" -> "model.layers.5.mlp.experts.40.up_proj" [label="1"];
  "model.layers.5.mlp.experts.40" -> "model.layers.5.mlp.experts.40.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.41" [label="1"];
  "model.layers.5.mlp.experts.41" -> "model.layers.5.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.41" -> "model.layers.5.mlp.experts.41.act_fn" [label="1"];
  "model.layers.5.mlp.experts.41" -> "model.layers.5.mlp.experts.41.up_proj" [label="1"];
  "model.layers.5.mlp.experts.41" -> "model.layers.5.mlp.experts.41.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.43" [label="1"];
  "model.layers.5.mlp.experts.43" -> "model.layers.5.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.43" -> "model.layers.5.mlp.experts.43.act_fn" [label="1"];
  "model.layers.5.mlp.experts.43" -> "model.layers.5.mlp.experts.43.up_proj" [label="1"];
  "model.layers.5.mlp.experts.43" -> "model.layers.5.mlp.experts.43.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.44" [label="1"];
  "model.layers.5.mlp.experts.44" -> "model.layers.5.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.44" -> "model.layers.5.mlp.experts.44.act_fn" [label="1"];
  "model.layers.5.mlp.experts.44" -> "model.layers.5.mlp.experts.44.up_proj" [label="1"];
  "model.layers.5.mlp.experts.44" -> "model.layers.5.mlp.experts.44.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.45" [label="1"];
  "model.layers.5.mlp.experts.45" -> "model.layers.5.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.45" -> "model.layers.5.mlp.experts.45.act_fn" [label="1"];
  "model.layers.5.mlp.experts.45" -> "model.layers.5.mlp.experts.45.up_proj" [label="1"];
  "model.layers.5.mlp.experts.45" -> "model.layers.5.mlp.experts.45.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.46" [label="1"];
  "model.layers.5.mlp.experts.46" -> "model.layers.5.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.46" -> "model.layers.5.mlp.experts.46.act_fn" [label="1"];
  "model.layers.5.mlp.experts.46" -> "model.layers.5.mlp.experts.46.up_proj" [label="1"];
  "model.layers.5.mlp.experts.46" -> "model.layers.5.mlp.experts.46.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.47" [label="1"];
  "model.layers.5.mlp.experts.47" -> "model.layers.5.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.47" -> "model.layers.5.mlp.experts.47.act_fn" [label="1"];
  "model.layers.5.mlp.experts.47" -> "model.layers.5.mlp.experts.47.up_proj" [label="1"];
  "model.layers.5.mlp.experts.47" -> "model.layers.5.mlp.experts.47.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.48" [label="1"];
  "model.layers.5.mlp.experts.48" -> "model.layers.5.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.48" -> "model.layers.5.mlp.experts.48.act_fn" [label="1"];
  "model.layers.5.mlp.experts.48" -> "model.layers.5.mlp.experts.48.up_proj" [label="1"];
  "model.layers.5.mlp.experts.48" -> "model.layers.5.mlp.experts.48.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.49" [label="1"];
  "model.layers.5.mlp.experts.49" -> "model.layers.5.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.49" -> "model.layers.5.mlp.experts.49.act_fn" [label="1"];
  "model.layers.5.mlp.experts.49" -> "model.layers.5.mlp.experts.49.up_proj" [label="1"];
  "model.layers.5.mlp.experts.49" -> "model.layers.5.mlp.experts.49.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.50" [label="1"];
  "model.layers.5.mlp.experts.50" -> "model.layers.5.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.50" -> "model.layers.5.mlp.experts.50.act_fn" [label="1"];
  "model.layers.5.mlp.experts.50" -> "model.layers.5.mlp.experts.50.up_proj" [label="1"];
  "model.layers.5.mlp.experts.50" -> "model.layers.5.mlp.experts.50.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.51" [label="1"];
  "model.layers.5.mlp.experts.51" -> "model.layers.5.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.51" -> "model.layers.5.mlp.experts.51.act_fn" [label="1"];
  "model.layers.5.mlp.experts.51" -> "model.layers.5.mlp.experts.51.up_proj" [label="1"];
  "model.layers.5.mlp.experts.51" -> "model.layers.5.mlp.experts.51.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.53" [label="1"];
  "model.layers.5.mlp.experts.53" -> "model.layers.5.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.53" -> "model.layers.5.mlp.experts.53.act_fn" [label="1"];
  "model.layers.5.mlp.experts.53" -> "model.layers.5.mlp.experts.53.up_proj" [label="1"];
  "model.layers.5.mlp.experts.53" -> "model.layers.5.mlp.experts.53.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.54" [label="1"];
  "model.layers.5.mlp.experts.54" -> "model.layers.5.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.54" -> "model.layers.5.mlp.experts.54.act_fn" [label="1"];
  "model.layers.5.mlp.experts.54" -> "model.layers.5.mlp.experts.54.up_proj" [label="1"];
  "model.layers.5.mlp.experts.54" -> "model.layers.5.mlp.experts.54.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.55" [label="1"];
  "model.layers.5.mlp.experts.55" -> "model.layers.5.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.55" -> "model.layers.5.mlp.experts.55.act_fn" [label="1"];
  "model.layers.5.mlp.experts.55" -> "model.layers.5.mlp.experts.55.up_proj" [label="1"];
  "model.layers.5.mlp.experts.55" -> "model.layers.5.mlp.experts.55.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.57" [label="1"];
  "model.layers.5.mlp.experts.57" -> "model.layers.5.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.57" -> "model.layers.5.mlp.experts.57.act_fn" [label="1"];
  "model.layers.5.mlp.experts.57" -> "model.layers.5.mlp.experts.57.up_proj" [label="1"];
  "model.layers.5.mlp.experts.57" -> "model.layers.5.mlp.experts.57.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.58" [label="1"];
  "model.layers.5.mlp.experts.58" -> "model.layers.5.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.58" -> "model.layers.5.mlp.experts.58.act_fn" [label="1"];
  "model.layers.5.mlp.experts.58" -> "model.layers.5.mlp.experts.58.up_proj" [label="1"];
  "model.layers.5.mlp.experts.58" -> "model.layers.5.mlp.experts.58.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.59" [label="1"];
  "model.layers.5.mlp.experts.59" -> "model.layers.5.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.59" -> "model.layers.5.mlp.experts.59.act_fn" [label="1"];
  "model.layers.5.mlp.experts.59" -> "model.layers.5.mlp.experts.59.up_proj" [label="1"];
  "model.layers.5.mlp.experts.59" -> "model.layers.5.mlp.experts.59.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.60" [label="1"];
  "model.layers.5.mlp.experts.60" -> "model.layers.5.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.60" -> "model.layers.5.mlp.experts.60.act_fn" [label="1"];
  "model.layers.5.mlp.experts.60" -> "model.layers.5.mlp.experts.60.up_proj" [label="1"];
  "model.layers.5.mlp.experts.60" -> "model.layers.5.mlp.experts.60.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.61" [label="1"];
  "model.layers.5.mlp.experts.61" -> "model.layers.5.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.61" -> "model.layers.5.mlp.experts.61.act_fn" [label="1"];
  "model.layers.5.mlp.experts.61" -> "model.layers.5.mlp.experts.61.up_proj" [label="1"];
  "model.layers.5.mlp.experts.61" -> "model.layers.5.mlp.experts.61.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.62" [label="1"];
  "model.layers.5.mlp.experts.62" -> "model.layers.5.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.62" -> "model.layers.5.mlp.experts.62.act_fn" [label="1"];
  "model.layers.5.mlp.experts.62" -> "model.layers.5.mlp.experts.62.up_proj" [label="1"];
  "model.layers.5.mlp.experts.62" -> "model.layers.5.mlp.experts.62.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.experts.63" [label="1"];
  "model.layers.5.mlp.experts.63" -> "model.layers.5.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.5.mlp.experts.63" -> "model.layers.5.mlp.experts.63.act_fn" [label="1"];
  "model.layers.5.mlp.experts.63" -> "model.layers.5.mlp.experts.63.up_proj" [label="1"];
  "model.layers.5.mlp.experts.63" -> "model.layers.5.mlp.experts.63.down_proj" [label="1"];
  "model.layers.5.mlp" -> "model.layers.5.mlp.shared_experts" [label="1"];
  "model.layers.5.mlp.shared_experts" -> "model.layers.5.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.5.mlp.shared_experts" -> "model.layers.5.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.5.mlp.shared_experts" -> "model.layers.5.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.5.mlp.shared_experts" -> "model.layers.5.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.6" [label="1"];
  "model.layers.6" -> "model.layers.6.input_layernorm" [label="1"];
  "model.layers.6" -> "model.layers.6.self_attn" [label="1"];
  "model.layers.6.self_attn" -> "model.layers.6.self_attn.q_proj" [label="1"];
  "model.layers.6.self_attn" -> "model.layers.6.self_attn.k_proj" [label="1"];
  "model.layers.6.self_attn" -> "model.layers.6.self_attn.v_proj" [label="1"];
  "model.layers.6.self_attn" -> "model.layers.6.self_attn.o_proj" [label="1"];
  "model.layers.6" -> "model.layers.6.post_attention_layernorm" [label="1"];
  "model.layers.6" -> "model.layers.6.mlp" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.gate" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.0" [label="1"];
  "model.layers.6.mlp.experts.0" -> "model.layers.6.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.0" -> "model.layers.6.mlp.experts.0.act_fn" [label="1"];
  "model.layers.6.mlp.experts.0" -> "model.layers.6.mlp.experts.0.up_proj" [label="1"];
  "model.layers.6.mlp.experts.0" -> "model.layers.6.mlp.experts.0.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.1" [label="1"];
  "model.layers.6.mlp.experts.1" -> "model.layers.6.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.1" -> "model.layers.6.mlp.experts.1.act_fn" [label="1"];
  "model.layers.6.mlp.experts.1" -> "model.layers.6.mlp.experts.1.up_proj" [label="1"];
  "model.layers.6.mlp.experts.1" -> "model.layers.6.mlp.experts.1.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.2" [label="1"];
  "model.layers.6.mlp.experts.2" -> "model.layers.6.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.2" -> "model.layers.6.mlp.experts.2.act_fn" [label="1"];
  "model.layers.6.mlp.experts.2" -> "model.layers.6.mlp.experts.2.up_proj" [label="1"];
  "model.layers.6.mlp.experts.2" -> "model.layers.6.mlp.experts.2.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.3" [label="1"];
  "model.layers.6.mlp.experts.3" -> "model.layers.6.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.3" -> "model.layers.6.mlp.experts.3.act_fn" [label="1"];
  "model.layers.6.mlp.experts.3" -> "model.layers.6.mlp.experts.3.up_proj" [label="1"];
  "model.layers.6.mlp.experts.3" -> "model.layers.6.mlp.experts.3.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.4" [label="1"];
  "model.layers.6.mlp.experts.4" -> "model.layers.6.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.4" -> "model.layers.6.mlp.experts.4.act_fn" [label="1"];
  "model.layers.6.mlp.experts.4" -> "model.layers.6.mlp.experts.4.up_proj" [label="1"];
  "model.layers.6.mlp.experts.4" -> "model.layers.6.mlp.experts.4.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.5" [label="1"];
  "model.layers.6.mlp.experts.5" -> "model.layers.6.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.5" -> "model.layers.6.mlp.experts.5.act_fn" [label="1"];
  "model.layers.6.mlp.experts.5" -> "model.layers.6.mlp.experts.5.up_proj" [label="1"];
  "model.layers.6.mlp.experts.5" -> "model.layers.6.mlp.experts.5.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.6" [label="1"];
  "model.layers.6.mlp.experts.6" -> "model.layers.6.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.6" -> "model.layers.6.mlp.experts.6.act_fn" [label="1"];
  "model.layers.6.mlp.experts.6" -> "model.layers.6.mlp.experts.6.up_proj" [label="1"];
  "model.layers.6.mlp.experts.6" -> "model.layers.6.mlp.experts.6.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.7" [label="1"];
  "model.layers.6.mlp.experts.7" -> "model.layers.6.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.7" -> "model.layers.6.mlp.experts.7.act_fn" [label="1"];
  "model.layers.6.mlp.experts.7" -> "model.layers.6.mlp.experts.7.up_proj" [label="1"];
  "model.layers.6.mlp.experts.7" -> "model.layers.6.mlp.experts.7.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.8" [label="1"];
  "model.layers.6.mlp.experts.8" -> "model.layers.6.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.8" -> "model.layers.6.mlp.experts.8.act_fn" [label="1"];
  "model.layers.6.mlp.experts.8" -> "model.layers.6.mlp.experts.8.up_proj" [label="1"];
  "model.layers.6.mlp.experts.8" -> "model.layers.6.mlp.experts.8.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.9" [label="1"];
  "model.layers.6.mlp.experts.9" -> "model.layers.6.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.9" -> "model.layers.6.mlp.experts.9.act_fn" [label="1"];
  "model.layers.6.mlp.experts.9" -> "model.layers.6.mlp.experts.9.up_proj" [label="1"];
  "model.layers.6.mlp.experts.9" -> "model.layers.6.mlp.experts.9.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.10" [label="1"];
  "model.layers.6.mlp.experts.10" -> "model.layers.6.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.10" -> "model.layers.6.mlp.experts.10.act_fn" [label="1"];
  "model.layers.6.mlp.experts.10" -> "model.layers.6.mlp.experts.10.up_proj" [label="1"];
  "model.layers.6.mlp.experts.10" -> "model.layers.6.mlp.experts.10.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.11" [label="1"];
  "model.layers.6.mlp.experts.11" -> "model.layers.6.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.11" -> "model.layers.6.mlp.experts.11.act_fn" [label="1"];
  "model.layers.6.mlp.experts.11" -> "model.layers.6.mlp.experts.11.up_proj" [label="1"];
  "model.layers.6.mlp.experts.11" -> "model.layers.6.mlp.experts.11.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.12" [label="1"];
  "model.layers.6.mlp.experts.12" -> "model.layers.6.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.12" -> "model.layers.6.mlp.experts.12.act_fn" [label="1"];
  "model.layers.6.mlp.experts.12" -> "model.layers.6.mlp.experts.12.up_proj" [label="1"];
  "model.layers.6.mlp.experts.12" -> "model.layers.6.mlp.experts.12.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.14" [label="1"];
  "model.layers.6.mlp.experts.14" -> "model.layers.6.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.14" -> "model.layers.6.mlp.experts.14.act_fn" [label="1"];
  "model.layers.6.mlp.experts.14" -> "model.layers.6.mlp.experts.14.up_proj" [label="1"];
  "model.layers.6.mlp.experts.14" -> "model.layers.6.mlp.experts.14.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.15" [label="1"];
  "model.layers.6.mlp.experts.15" -> "model.layers.6.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.15" -> "model.layers.6.mlp.experts.15.act_fn" [label="1"];
  "model.layers.6.mlp.experts.15" -> "model.layers.6.mlp.experts.15.up_proj" [label="1"];
  "model.layers.6.mlp.experts.15" -> "model.layers.6.mlp.experts.15.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.16" [label="1"];
  "model.layers.6.mlp.experts.16" -> "model.layers.6.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.16" -> "model.layers.6.mlp.experts.16.act_fn" [label="1"];
  "model.layers.6.mlp.experts.16" -> "model.layers.6.mlp.experts.16.up_proj" [label="1"];
  "model.layers.6.mlp.experts.16" -> "model.layers.6.mlp.experts.16.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.17" [label="1"];
  "model.layers.6.mlp.experts.17" -> "model.layers.6.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.17" -> "model.layers.6.mlp.experts.17.act_fn" [label="1"];
  "model.layers.6.mlp.experts.17" -> "model.layers.6.mlp.experts.17.up_proj" [label="1"];
  "model.layers.6.mlp.experts.17" -> "model.layers.6.mlp.experts.17.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.18" [label="1"];
  "model.layers.6.mlp.experts.18" -> "model.layers.6.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.18" -> "model.layers.6.mlp.experts.18.act_fn" [label="1"];
  "model.layers.6.mlp.experts.18" -> "model.layers.6.mlp.experts.18.up_proj" [label="1"];
  "model.layers.6.mlp.experts.18" -> "model.layers.6.mlp.experts.18.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.19" [label="1"];
  "model.layers.6.mlp.experts.19" -> "model.layers.6.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.19" -> "model.layers.6.mlp.experts.19.act_fn" [label="1"];
  "model.layers.6.mlp.experts.19" -> "model.layers.6.mlp.experts.19.up_proj" [label="1"];
  "model.layers.6.mlp.experts.19" -> "model.layers.6.mlp.experts.19.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.20" [label="1"];
  "model.layers.6.mlp.experts.20" -> "model.layers.6.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.20" -> "model.layers.6.mlp.experts.20.act_fn" [label="1"];
  "model.layers.6.mlp.experts.20" -> "model.layers.6.mlp.experts.20.up_proj" [label="1"];
  "model.layers.6.mlp.experts.20" -> "model.layers.6.mlp.experts.20.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.21" [label="1"];
  "model.layers.6.mlp.experts.21" -> "model.layers.6.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.21" -> "model.layers.6.mlp.experts.21.act_fn" [label="1"];
  "model.layers.6.mlp.experts.21" -> "model.layers.6.mlp.experts.21.up_proj" [label="1"];
  "model.layers.6.mlp.experts.21" -> "model.layers.6.mlp.experts.21.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.22" [label="1"];
  "model.layers.6.mlp.experts.22" -> "model.layers.6.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.22" -> "model.layers.6.mlp.experts.22.act_fn" [label="1"];
  "model.layers.6.mlp.experts.22" -> "model.layers.6.mlp.experts.22.up_proj" [label="1"];
  "model.layers.6.mlp.experts.22" -> "model.layers.6.mlp.experts.22.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.23" [label="1"];
  "model.layers.6.mlp.experts.23" -> "model.layers.6.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.23" -> "model.layers.6.mlp.experts.23.act_fn" [label="1"];
  "model.layers.6.mlp.experts.23" -> "model.layers.6.mlp.experts.23.up_proj" [label="1"];
  "model.layers.6.mlp.experts.23" -> "model.layers.6.mlp.experts.23.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.24" [label="1"];
  "model.layers.6.mlp.experts.24" -> "model.layers.6.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.24" -> "model.layers.6.mlp.experts.24.act_fn" [label="1"];
  "model.layers.6.mlp.experts.24" -> "model.layers.6.mlp.experts.24.up_proj" [label="1"];
  "model.layers.6.mlp.experts.24" -> "model.layers.6.mlp.experts.24.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.25" [label="1"];
  "model.layers.6.mlp.experts.25" -> "model.layers.6.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.25" -> "model.layers.6.mlp.experts.25.act_fn" [label="1"];
  "model.layers.6.mlp.experts.25" -> "model.layers.6.mlp.experts.25.up_proj" [label="1"];
  "model.layers.6.mlp.experts.25" -> "model.layers.6.mlp.experts.25.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.26" [label="1"];
  "model.layers.6.mlp.experts.26" -> "model.layers.6.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.26" -> "model.layers.6.mlp.experts.26.act_fn" [label="1"];
  "model.layers.6.mlp.experts.26" -> "model.layers.6.mlp.experts.26.up_proj" [label="1"];
  "model.layers.6.mlp.experts.26" -> "model.layers.6.mlp.experts.26.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.27" [label="1"];
  "model.layers.6.mlp.experts.27" -> "model.layers.6.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.27" -> "model.layers.6.mlp.experts.27.act_fn" [label="1"];
  "model.layers.6.mlp.experts.27" -> "model.layers.6.mlp.experts.27.up_proj" [label="1"];
  "model.layers.6.mlp.experts.27" -> "model.layers.6.mlp.experts.27.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.28" [label="1"];
  "model.layers.6.mlp.experts.28" -> "model.layers.6.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.28" -> "model.layers.6.mlp.experts.28.act_fn" [label="1"];
  "model.layers.6.mlp.experts.28" -> "model.layers.6.mlp.experts.28.up_proj" [label="1"];
  "model.layers.6.mlp.experts.28" -> "model.layers.6.mlp.experts.28.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.29" [label="1"];
  "model.layers.6.mlp.experts.29" -> "model.layers.6.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.29" -> "model.layers.6.mlp.experts.29.act_fn" [label="1"];
  "model.layers.6.mlp.experts.29" -> "model.layers.6.mlp.experts.29.up_proj" [label="1"];
  "model.layers.6.mlp.experts.29" -> "model.layers.6.mlp.experts.29.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.30" [label="1"];
  "model.layers.6.mlp.experts.30" -> "model.layers.6.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.30" -> "model.layers.6.mlp.experts.30.act_fn" [label="1"];
  "model.layers.6.mlp.experts.30" -> "model.layers.6.mlp.experts.30.up_proj" [label="1"];
  "model.layers.6.mlp.experts.30" -> "model.layers.6.mlp.experts.30.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.31" [label="1"];
  "model.layers.6.mlp.experts.31" -> "model.layers.6.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.31" -> "model.layers.6.mlp.experts.31.act_fn" [label="1"];
  "model.layers.6.mlp.experts.31" -> "model.layers.6.mlp.experts.31.up_proj" [label="1"];
  "model.layers.6.mlp.experts.31" -> "model.layers.6.mlp.experts.31.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.32" [label="1"];
  "model.layers.6.mlp.experts.32" -> "model.layers.6.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.32" -> "model.layers.6.mlp.experts.32.act_fn" [label="1"];
  "model.layers.6.mlp.experts.32" -> "model.layers.6.mlp.experts.32.up_proj" [label="1"];
  "model.layers.6.mlp.experts.32" -> "model.layers.6.mlp.experts.32.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.33" [label="1"];
  "model.layers.6.mlp.experts.33" -> "model.layers.6.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.33" -> "model.layers.6.mlp.experts.33.act_fn" [label="1"];
  "model.layers.6.mlp.experts.33" -> "model.layers.6.mlp.experts.33.up_proj" [label="1"];
  "model.layers.6.mlp.experts.33" -> "model.layers.6.mlp.experts.33.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.34" [label="1"];
  "model.layers.6.mlp.experts.34" -> "model.layers.6.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.34" -> "model.layers.6.mlp.experts.34.act_fn" [label="1"];
  "model.layers.6.mlp.experts.34" -> "model.layers.6.mlp.experts.34.up_proj" [label="1"];
  "model.layers.6.mlp.experts.34" -> "model.layers.6.mlp.experts.34.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.35" [label="1"];
  "model.layers.6.mlp.experts.35" -> "model.layers.6.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.35" -> "model.layers.6.mlp.experts.35.act_fn" [label="1"];
  "model.layers.6.mlp.experts.35" -> "model.layers.6.mlp.experts.35.up_proj" [label="1"];
  "model.layers.6.mlp.experts.35" -> "model.layers.6.mlp.experts.35.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.36" [label="1"];
  "model.layers.6.mlp.experts.36" -> "model.layers.6.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.36" -> "model.layers.6.mlp.experts.36.act_fn" [label="1"];
  "model.layers.6.mlp.experts.36" -> "model.layers.6.mlp.experts.36.up_proj" [label="1"];
  "model.layers.6.mlp.experts.36" -> "model.layers.6.mlp.experts.36.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.37" [label="1"];
  "model.layers.6.mlp.experts.37" -> "model.layers.6.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.37" -> "model.layers.6.mlp.experts.37.act_fn" [label="1"];
  "model.layers.6.mlp.experts.37" -> "model.layers.6.mlp.experts.37.up_proj" [label="1"];
  "model.layers.6.mlp.experts.37" -> "model.layers.6.mlp.experts.37.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.38" [label="1"];
  "model.layers.6.mlp.experts.38" -> "model.layers.6.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.38" -> "model.layers.6.mlp.experts.38.act_fn" [label="1"];
  "model.layers.6.mlp.experts.38" -> "model.layers.6.mlp.experts.38.up_proj" [label="1"];
  "model.layers.6.mlp.experts.38" -> "model.layers.6.mlp.experts.38.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.39" [label="1"];
  "model.layers.6.mlp.experts.39" -> "model.layers.6.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.39" -> "model.layers.6.mlp.experts.39.act_fn" [label="1"];
  "model.layers.6.mlp.experts.39" -> "model.layers.6.mlp.experts.39.up_proj" [label="1"];
  "model.layers.6.mlp.experts.39" -> "model.layers.6.mlp.experts.39.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.40" [label="1"];
  "model.layers.6.mlp.experts.40" -> "model.layers.6.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.40" -> "model.layers.6.mlp.experts.40.act_fn" [label="1"];
  "model.layers.6.mlp.experts.40" -> "model.layers.6.mlp.experts.40.up_proj" [label="1"];
  "model.layers.6.mlp.experts.40" -> "model.layers.6.mlp.experts.40.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.41" [label="1"];
  "model.layers.6.mlp.experts.41" -> "model.layers.6.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.41" -> "model.layers.6.mlp.experts.41.act_fn" [label="1"];
  "model.layers.6.mlp.experts.41" -> "model.layers.6.mlp.experts.41.up_proj" [label="1"];
  "model.layers.6.mlp.experts.41" -> "model.layers.6.mlp.experts.41.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.42" [label="1"];
  "model.layers.6.mlp.experts.42" -> "model.layers.6.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.42" -> "model.layers.6.mlp.experts.42.act_fn" [label="1"];
  "model.layers.6.mlp.experts.42" -> "model.layers.6.mlp.experts.42.up_proj" [label="1"];
  "model.layers.6.mlp.experts.42" -> "model.layers.6.mlp.experts.42.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.43" [label="1"];
  "model.layers.6.mlp.experts.43" -> "model.layers.6.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.43" -> "model.layers.6.mlp.experts.43.act_fn" [label="1"];
  "model.layers.6.mlp.experts.43" -> "model.layers.6.mlp.experts.43.up_proj" [label="1"];
  "model.layers.6.mlp.experts.43" -> "model.layers.6.mlp.experts.43.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.44" [label="1"];
  "model.layers.6.mlp.experts.44" -> "model.layers.6.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.44" -> "model.layers.6.mlp.experts.44.act_fn" [label="1"];
  "model.layers.6.mlp.experts.44" -> "model.layers.6.mlp.experts.44.up_proj" [label="1"];
  "model.layers.6.mlp.experts.44" -> "model.layers.6.mlp.experts.44.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.45" [label="1"];
  "model.layers.6.mlp.experts.45" -> "model.layers.6.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.45" -> "model.layers.6.mlp.experts.45.act_fn" [label="1"];
  "model.layers.6.mlp.experts.45" -> "model.layers.6.mlp.experts.45.up_proj" [label="1"];
  "model.layers.6.mlp.experts.45" -> "model.layers.6.mlp.experts.45.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.46" [label="1"];
  "model.layers.6.mlp.experts.46" -> "model.layers.6.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.46" -> "model.layers.6.mlp.experts.46.act_fn" [label="1"];
  "model.layers.6.mlp.experts.46" -> "model.layers.6.mlp.experts.46.up_proj" [label="1"];
  "model.layers.6.mlp.experts.46" -> "model.layers.6.mlp.experts.46.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.47" [label="1"];
  "model.layers.6.mlp.experts.47" -> "model.layers.6.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.47" -> "model.layers.6.mlp.experts.47.act_fn" [label="1"];
  "model.layers.6.mlp.experts.47" -> "model.layers.6.mlp.experts.47.up_proj" [label="1"];
  "model.layers.6.mlp.experts.47" -> "model.layers.6.mlp.experts.47.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.48" [label="1"];
  "model.layers.6.mlp.experts.48" -> "model.layers.6.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.48" -> "model.layers.6.mlp.experts.48.act_fn" [label="1"];
  "model.layers.6.mlp.experts.48" -> "model.layers.6.mlp.experts.48.up_proj" [label="1"];
  "model.layers.6.mlp.experts.48" -> "model.layers.6.mlp.experts.48.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.49" [label="1"];
  "model.layers.6.mlp.experts.49" -> "model.layers.6.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.49" -> "model.layers.6.mlp.experts.49.act_fn" [label="1"];
  "model.layers.6.mlp.experts.49" -> "model.layers.6.mlp.experts.49.up_proj" [label="1"];
  "model.layers.6.mlp.experts.49" -> "model.layers.6.mlp.experts.49.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.50" [label="1"];
  "model.layers.6.mlp.experts.50" -> "model.layers.6.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.50" -> "model.layers.6.mlp.experts.50.act_fn" [label="1"];
  "model.layers.6.mlp.experts.50" -> "model.layers.6.mlp.experts.50.up_proj" [label="1"];
  "model.layers.6.mlp.experts.50" -> "model.layers.6.mlp.experts.50.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.51" [label="1"];
  "model.layers.6.mlp.experts.51" -> "model.layers.6.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.51" -> "model.layers.6.mlp.experts.51.act_fn" [label="1"];
  "model.layers.6.mlp.experts.51" -> "model.layers.6.mlp.experts.51.up_proj" [label="1"];
  "model.layers.6.mlp.experts.51" -> "model.layers.6.mlp.experts.51.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.52" [label="1"];
  "model.layers.6.mlp.experts.52" -> "model.layers.6.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.52" -> "model.layers.6.mlp.experts.52.act_fn" [label="1"];
  "model.layers.6.mlp.experts.52" -> "model.layers.6.mlp.experts.52.up_proj" [label="1"];
  "model.layers.6.mlp.experts.52" -> "model.layers.6.mlp.experts.52.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.53" [label="1"];
  "model.layers.6.mlp.experts.53" -> "model.layers.6.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.53" -> "model.layers.6.mlp.experts.53.act_fn" [label="1"];
  "model.layers.6.mlp.experts.53" -> "model.layers.6.mlp.experts.53.up_proj" [label="1"];
  "model.layers.6.mlp.experts.53" -> "model.layers.6.mlp.experts.53.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.54" [label="1"];
  "model.layers.6.mlp.experts.54" -> "model.layers.6.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.54" -> "model.layers.6.mlp.experts.54.act_fn" [label="1"];
  "model.layers.6.mlp.experts.54" -> "model.layers.6.mlp.experts.54.up_proj" [label="1"];
  "model.layers.6.mlp.experts.54" -> "model.layers.6.mlp.experts.54.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.55" [label="1"];
  "model.layers.6.mlp.experts.55" -> "model.layers.6.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.55" -> "model.layers.6.mlp.experts.55.act_fn" [label="1"];
  "model.layers.6.mlp.experts.55" -> "model.layers.6.mlp.experts.55.up_proj" [label="1"];
  "model.layers.6.mlp.experts.55" -> "model.layers.6.mlp.experts.55.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.56" [label="1"];
  "model.layers.6.mlp.experts.56" -> "model.layers.6.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.56" -> "model.layers.6.mlp.experts.56.act_fn" [label="1"];
  "model.layers.6.mlp.experts.56" -> "model.layers.6.mlp.experts.56.up_proj" [label="1"];
  "model.layers.6.mlp.experts.56" -> "model.layers.6.mlp.experts.56.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.57" [label="1"];
  "model.layers.6.mlp.experts.57" -> "model.layers.6.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.57" -> "model.layers.6.mlp.experts.57.act_fn" [label="1"];
  "model.layers.6.mlp.experts.57" -> "model.layers.6.mlp.experts.57.up_proj" [label="1"];
  "model.layers.6.mlp.experts.57" -> "model.layers.6.mlp.experts.57.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.58" [label="1"];
  "model.layers.6.mlp.experts.58" -> "model.layers.6.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.58" -> "model.layers.6.mlp.experts.58.act_fn" [label="1"];
  "model.layers.6.mlp.experts.58" -> "model.layers.6.mlp.experts.58.up_proj" [label="1"];
  "model.layers.6.mlp.experts.58" -> "model.layers.6.mlp.experts.58.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.59" [label="1"];
  "model.layers.6.mlp.experts.59" -> "model.layers.6.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.59" -> "model.layers.6.mlp.experts.59.act_fn" [label="1"];
  "model.layers.6.mlp.experts.59" -> "model.layers.6.mlp.experts.59.up_proj" [label="1"];
  "model.layers.6.mlp.experts.59" -> "model.layers.6.mlp.experts.59.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.60" [label="1"];
  "model.layers.6.mlp.experts.60" -> "model.layers.6.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.60" -> "model.layers.6.mlp.experts.60.act_fn" [label="1"];
  "model.layers.6.mlp.experts.60" -> "model.layers.6.mlp.experts.60.up_proj" [label="1"];
  "model.layers.6.mlp.experts.60" -> "model.layers.6.mlp.experts.60.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.61" [label="1"];
  "model.layers.6.mlp.experts.61" -> "model.layers.6.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.61" -> "model.layers.6.mlp.experts.61.act_fn" [label="1"];
  "model.layers.6.mlp.experts.61" -> "model.layers.6.mlp.experts.61.up_proj" [label="1"];
  "model.layers.6.mlp.experts.61" -> "model.layers.6.mlp.experts.61.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.62" [label="1"];
  "model.layers.6.mlp.experts.62" -> "model.layers.6.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.62" -> "model.layers.6.mlp.experts.62.act_fn" [label="1"];
  "model.layers.6.mlp.experts.62" -> "model.layers.6.mlp.experts.62.up_proj" [label="1"];
  "model.layers.6.mlp.experts.62" -> "model.layers.6.mlp.experts.62.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.experts.63" [label="1"];
  "model.layers.6.mlp.experts.63" -> "model.layers.6.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.6.mlp.experts.63" -> "model.layers.6.mlp.experts.63.act_fn" [label="1"];
  "model.layers.6.mlp.experts.63" -> "model.layers.6.mlp.experts.63.up_proj" [label="1"];
  "model.layers.6.mlp.experts.63" -> "model.layers.6.mlp.experts.63.down_proj" [label="1"];
  "model.layers.6.mlp" -> "model.layers.6.mlp.shared_experts" [label="1"];
  "model.layers.6.mlp.shared_experts" -> "model.layers.6.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.6.mlp.shared_experts" -> "model.layers.6.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.6.mlp.shared_experts" -> "model.layers.6.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.6.mlp.shared_experts" -> "model.layers.6.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.7" [label="1"];
  "model.layers.7" -> "model.layers.7.input_layernorm" [label="1"];
  "model.layers.7" -> "model.layers.7.self_attn" [label="1"];
  "model.layers.7.self_attn" -> "model.layers.7.self_attn.q_proj" [label="1"];
  "model.layers.7.self_attn" -> "model.layers.7.self_attn.k_proj" [label="1"];
  "model.layers.7.self_attn" -> "model.layers.7.self_attn.v_proj" [label="1"];
  "model.layers.7.self_attn" -> "model.layers.7.self_attn.o_proj" [label="1"];
  "model.layers.7" -> "model.layers.7.post_attention_layernorm" [label="1"];
  "model.layers.7" -> "model.layers.7.mlp" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.gate" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.0" [label="1"];
  "model.layers.7.mlp.experts.0" -> "model.layers.7.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.0" -> "model.layers.7.mlp.experts.0.act_fn" [label="1"];
  "model.layers.7.mlp.experts.0" -> "model.layers.7.mlp.experts.0.up_proj" [label="1"];
  "model.layers.7.mlp.experts.0" -> "model.layers.7.mlp.experts.0.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.1" [label="1"];
  "model.layers.7.mlp.experts.1" -> "model.layers.7.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.1" -> "model.layers.7.mlp.experts.1.act_fn" [label="1"];
  "model.layers.7.mlp.experts.1" -> "model.layers.7.mlp.experts.1.up_proj" [label="1"];
  "model.layers.7.mlp.experts.1" -> "model.layers.7.mlp.experts.1.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.2" [label="1"];
  "model.layers.7.mlp.experts.2" -> "model.layers.7.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.2" -> "model.layers.7.mlp.experts.2.act_fn" [label="1"];
  "model.layers.7.mlp.experts.2" -> "model.layers.7.mlp.experts.2.up_proj" [label="1"];
  "model.layers.7.mlp.experts.2" -> "model.layers.7.mlp.experts.2.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.3" [label="1"];
  "model.layers.7.mlp.experts.3" -> "model.layers.7.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.3" -> "model.layers.7.mlp.experts.3.act_fn" [label="1"];
  "model.layers.7.mlp.experts.3" -> "model.layers.7.mlp.experts.3.up_proj" [label="1"];
  "model.layers.7.mlp.experts.3" -> "model.layers.7.mlp.experts.3.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.4" [label="1"];
  "model.layers.7.mlp.experts.4" -> "model.layers.7.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.4" -> "model.layers.7.mlp.experts.4.act_fn" [label="1"];
  "model.layers.7.mlp.experts.4" -> "model.layers.7.mlp.experts.4.up_proj" [label="1"];
  "model.layers.7.mlp.experts.4" -> "model.layers.7.mlp.experts.4.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.5" [label="1"];
  "model.layers.7.mlp.experts.5" -> "model.layers.7.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.5" -> "model.layers.7.mlp.experts.5.act_fn" [label="1"];
  "model.layers.7.mlp.experts.5" -> "model.layers.7.mlp.experts.5.up_proj" [label="1"];
  "model.layers.7.mlp.experts.5" -> "model.layers.7.mlp.experts.5.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.6" [label="1"];
  "model.layers.7.mlp.experts.6" -> "model.layers.7.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.6" -> "model.layers.7.mlp.experts.6.act_fn" [label="1"];
  "model.layers.7.mlp.experts.6" -> "model.layers.7.mlp.experts.6.up_proj" [label="1"];
  "model.layers.7.mlp.experts.6" -> "model.layers.7.mlp.experts.6.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.7" [label="1"];
  "model.layers.7.mlp.experts.7" -> "model.layers.7.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.7" -> "model.layers.7.mlp.experts.7.act_fn" [label="1"];
  "model.layers.7.mlp.experts.7" -> "model.layers.7.mlp.experts.7.up_proj" [label="1"];
  "model.layers.7.mlp.experts.7" -> "model.layers.7.mlp.experts.7.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.8" [label="1"];
  "model.layers.7.mlp.experts.8" -> "model.layers.7.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.8" -> "model.layers.7.mlp.experts.8.act_fn" [label="1"];
  "model.layers.7.mlp.experts.8" -> "model.layers.7.mlp.experts.8.up_proj" [label="1"];
  "model.layers.7.mlp.experts.8" -> "model.layers.7.mlp.experts.8.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.9" [label="1"];
  "model.layers.7.mlp.experts.9" -> "model.layers.7.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.9" -> "model.layers.7.mlp.experts.9.act_fn" [label="1"];
  "model.layers.7.mlp.experts.9" -> "model.layers.7.mlp.experts.9.up_proj" [label="1"];
  "model.layers.7.mlp.experts.9" -> "model.layers.7.mlp.experts.9.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.10" [label="1"];
  "model.layers.7.mlp.experts.10" -> "model.layers.7.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.10" -> "model.layers.7.mlp.experts.10.act_fn" [label="1"];
  "model.layers.7.mlp.experts.10" -> "model.layers.7.mlp.experts.10.up_proj" [label="1"];
  "model.layers.7.mlp.experts.10" -> "model.layers.7.mlp.experts.10.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.11" [label="1"];
  "model.layers.7.mlp.experts.11" -> "model.layers.7.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.11" -> "model.layers.7.mlp.experts.11.act_fn" [label="1"];
  "model.layers.7.mlp.experts.11" -> "model.layers.7.mlp.experts.11.up_proj" [label="1"];
  "model.layers.7.mlp.experts.11" -> "model.layers.7.mlp.experts.11.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.12" [label="1"];
  "model.layers.7.mlp.experts.12" -> "model.layers.7.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.12" -> "model.layers.7.mlp.experts.12.act_fn" [label="1"];
  "model.layers.7.mlp.experts.12" -> "model.layers.7.mlp.experts.12.up_proj" [label="1"];
  "model.layers.7.mlp.experts.12" -> "model.layers.7.mlp.experts.12.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.13" [label="1"];
  "model.layers.7.mlp.experts.13" -> "model.layers.7.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.13" -> "model.layers.7.mlp.experts.13.act_fn" [label="1"];
  "model.layers.7.mlp.experts.13" -> "model.layers.7.mlp.experts.13.up_proj" [label="1"];
  "model.layers.7.mlp.experts.13" -> "model.layers.7.mlp.experts.13.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.14" [label="1"];
  "model.layers.7.mlp.experts.14" -> "model.layers.7.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.14" -> "model.layers.7.mlp.experts.14.act_fn" [label="1"];
  "model.layers.7.mlp.experts.14" -> "model.layers.7.mlp.experts.14.up_proj" [label="1"];
  "model.layers.7.mlp.experts.14" -> "model.layers.7.mlp.experts.14.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.15" [label="1"];
  "model.layers.7.mlp.experts.15" -> "model.layers.7.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.15" -> "model.layers.7.mlp.experts.15.act_fn" [label="1"];
  "model.layers.7.mlp.experts.15" -> "model.layers.7.mlp.experts.15.up_proj" [label="1"];
  "model.layers.7.mlp.experts.15" -> "model.layers.7.mlp.experts.15.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.16" [label="1"];
  "model.layers.7.mlp.experts.16" -> "model.layers.7.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.16" -> "model.layers.7.mlp.experts.16.act_fn" [label="1"];
  "model.layers.7.mlp.experts.16" -> "model.layers.7.mlp.experts.16.up_proj" [label="1"];
  "model.layers.7.mlp.experts.16" -> "model.layers.7.mlp.experts.16.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.17" [label="1"];
  "model.layers.7.mlp.experts.17" -> "model.layers.7.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.17" -> "model.layers.7.mlp.experts.17.act_fn" [label="1"];
  "model.layers.7.mlp.experts.17" -> "model.layers.7.mlp.experts.17.up_proj" [label="1"];
  "model.layers.7.mlp.experts.17" -> "model.layers.7.mlp.experts.17.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.18" [label="1"];
  "model.layers.7.mlp.experts.18" -> "model.layers.7.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.18" -> "model.layers.7.mlp.experts.18.act_fn" [label="1"];
  "model.layers.7.mlp.experts.18" -> "model.layers.7.mlp.experts.18.up_proj" [label="1"];
  "model.layers.7.mlp.experts.18" -> "model.layers.7.mlp.experts.18.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.19" [label="1"];
  "model.layers.7.mlp.experts.19" -> "model.layers.7.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.19" -> "model.layers.7.mlp.experts.19.act_fn" [label="1"];
  "model.layers.7.mlp.experts.19" -> "model.layers.7.mlp.experts.19.up_proj" [label="1"];
  "model.layers.7.mlp.experts.19" -> "model.layers.7.mlp.experts.19.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.20" [label="1"];
  "model.layers.7.mlp.experts.20" -> "model.layers.7.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.20" -> "model.layers.7.mlp.experts.20.act_fn" [label="1"];
  "model.layers.7.mlp.experts.20" -> "model.layers.7.mlp.experts.20.up_proj" [label="1"];
  "model.layers.7.mlp.experts.20" -> "model.layers.7.mlp.experts.20.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.21" [label="1"];
  "model.layers.7.mlp.experts.21" -> "model.layers.7.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.21" -> "model.layers.7.mlp.experts.21.act_fn" [label="1"];
  "model.layers.7.mlp.experts.21" -> "model.layers.7.mlp.experts.21.up_proj" [label="1"];
  "model.layers.7.mlp.experts.21" -> "model.layers.7.mlp.experts.21.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.22" [label="1"];
  "model.layers.7.mlp.experts.22" -> "model.layers.7.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.22" -> "model.layers.7.mlp.experts.22.act_fn" [label="1"];
  "model.layers.7.mlp.experts.22" -> "model.layers.7.mlp.experts.22.up_proj" [label="1"];
  "model.layers.7.mlp.experts.22" -> "model.layers.7.mlp.experts.22.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.23" [label="1"];
  "model.layers.7.mlp.experts.23" -> "model.layers.7.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.23" -> "model.layers.7.mlp.experts.23.act_fn" [label="1"];
  "model.layers.7.mlp.experts.23" -> "model.layers.7.mlp.experts.23.up_proj" [label="1"];
  "model.layers.7.mlp.experts.23" -> "model.layers.7.mlp.experts.23.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.24" [label="1"];
  "model.layers.7.mlp.experts.24" -> "model.layers.7.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.24" -> "model.layers.7.mlp.experts.24.act_fn" [label="1"];
  "model.layers.7.mlp.experts.24" -> "model.layers.7.mlp.experts.24.up_proj" [label="1"];
  "model.layers.7.mlp.experts.24" -> "model.layers.7.mlp.experts.24.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.25" [label="1"];
  "model.layers.7.mlp.experts.25" -> "model.layers.7.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.25" -> "model.layers.7.mlp.experts.25.act_fn" [label="1"];
  "model.layers.7.mlp.experts.25" -> "model.layers.7.mlp.experts.25.up_proj" [label="1"];
  "model.layers.7.mlp.experts.25" -> "model.layers.7.mlp.experts.25.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.26" [label="1"];
  "model.layers.7.mlp.experts.26" -> "model.layers.7.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.26" -> "model.layers.7.mlp.experts.26.act_fn" [label="1"];
  "model.layers.7.mlp.experts.26" -> "model.layers.7.mlp.experts.26.up_proj" [label="1"];
  "model.layers.7.mlp.experts.26" -> "model.layers.7.mlp.experts.26.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.27" [label="1"];
  "model.layers.7.mlp.experts.27" -> "model.layers.7.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.27" -> "model.layers.7.mlp.experts.27.act_fn" [label="1"];
  "model.layers.7.mlp.experts.27" -> "model.layers.7.mlp.experts.27.up_proj" [label="1"];
  "model.layers.7.mlp.experts.27" -> "model.layers.7.mlp.experts.27.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.28" [label="1"];
  "model.layers.7.mlp.experts.28" -> "model.layers.7.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.28" -> "model.layers.7.mlp.experts.28.act_fn" [label="1"];
  "model.layers.7.mlp.experts.28" -> "model.layers.7.mlp.experts.28.up_proj" [label="1"];
  "model.layers.7.mlp.experts.28" -> "model.layers.7.mlp.experts.28.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.29" [label="1"];
  "model.layers.7.mlp.experts.29" -> "model.layers.7.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.29" -> "model.layers.7.mlp.experts.29.act_fn" [label="1"];
  "model.layers.7.mlp.experts.29" -> "model.layers.7.mlp.experts.29.up_proj" [label="1"];
  "model.layers.7.mlp.experts.29" -> "model.layers.7.mlp.experts.29.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.30" [label="1"];
  "model.layers.7.mlp.experts.30" -> "model.layers.7.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.30" -> "model.layers.7.mlp.experts.30.act_fn" [label="1"];
  "model.layers.7.mlp.experts.30" -> "model.layers.7.mlp.experts.30.up_proj" [label="1"];
  "model.layers.7.mlp.experts.30" -> "model.layers.7.mlp.experts.30.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.31" [label="1"];
  "model.layers.7.mlp.experts.31" -> "model.layers.7.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.31" -> "model.layers.7.mlp.experts.31.act_fn" [label="1"];
  "model.layers.7.mlp.experts.31" -> "model.layers.7.mlp.experts.31.up_proj" [label="1"];
  "model.layers.7.mlp.experts.31" -> "model.layers.7.mlp.experts.31.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.32" [label="1"];
  "model.layers.7.mlp.experts.32" -> "model.layers.7.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.32" -> "model.layers.7.mlp.experts.32.act_fn" [label="1"];
  "model.layers.7.mlp.experts.32" -> "model.layers.7.mlp.experts.32.up_proj" [label="1"];
  "model.layers.7.mlp.experts.32" -> "model.layers.7.mlp.experts.32.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.33" [label="1"];
  "model.layers.7.mlp.experts.33" -> "model.layers.7.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.33" -> "model.layers.7.mlp.experts.33.act_fn" [label="1"];
  "model.layers.7.mlp.experts.33" -> "model.layers.7.mlp.experts.33.up_proj" [label="1"];
  "model.layers.7.mlp.experts.33" -> "model.layers.7.mlp.experts.33.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.34" [label="1"];
  "model.layers.7.mlp.experts.34" -> "model.layers.7.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.34" -> "model.layers.7.mlp.experts.34.act_fn" [label="1"];
  "model.layers.7.mlp.experts.34" -> "model.layers.7.mlp.experts.34.up_proj" [label="1"];
  "model.layers.7.mlp.experts.34" -> "model.layers.7.mlp.experts.34.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.35" [label="1"];
  "model.layers.7.mlp.experts.35" -> "model.layers.7.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.35" -> "model.layers.7.mlp.experts.35.act_fn" [label="1"];
  "model.layers.7.mlp.experts.35" -> "model.layers.7.mlp.experts.35.up_proj" [label="1"];
  "model.layers.7.mlp.experts.35" -> "model.layers.7.mlp.experts.35.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.36" [label="1"];
  "model.layers.7.mlp.experts.36" -> "model.layers.7.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.36" -> "model.layers.7.mlp.experts.36.act_fn" [label="1"];
  "model.layers.7.mlp.experts.36" -> "model.layers.7.mlp.experts.36.up_proj" [label="1"];
  "model.layers.7.mlp.experts.36" -> "model.layers.7.mlp.experts.36.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.37" [label="1"];
  "model.layers.7.mlp.experts.37" -> "model.layers.7.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.37" -> "model.layers.7.mlp.experts.37.act_fn" [label="1"];
  "model.layers.7.mlp.experts.37" -> "model.layers.7.mlp.experts.37.up_proj" [label="1"];
  "model.layers.7.mlp.experts.37" -> "model.layers.7.mlp.experts.37.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.38" [label="1"];
  "model.layers.7.mlp.experts.38" -> "model.layers.7.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.38" -> "model.layers.7.mlp.experts.38.act_fn" [label="1"];
  "model.layers.7.mlp.experts.38" -> "model.layers.7.mlp.experts.38.up_proj" [label="1"];
  "model.layers.7.mlp.experts.38" -> "model.layers.7.mlp.experts.38.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.39" [label="1"];
  "model.layers.7.mlp.experts.39" -> "model.layers.7.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.39" -> "model.layers.7.mlp.experts.39.act_fn" [label="1"];
  "model.layers.7.mlp.experts.39" -> "model.layers.7.mlp.experts.39.up_proj" [label="1"];
  "model.layers.7.mlp.experts.39" -> "model.layers.7.mlp.experts.39.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.41" [label="1"];
  "model.layers.7.mlp.experts.41" -> "model.layers.7.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.41" -> "model.layers.7.mlp.experts.41.act_fn" [label="1"];
  "model.layers.7.mlp.experts.41" -> "model.layers.7.mlp.experts.41.up_proj" [label="1"];
  "model.layers.7.mlp.experts.41" -> "model.layers.7.mlp.experts.41.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.42" [label="1"];
  "model.layers.7.mlp.experts.42" -> "model.layers.7.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.42" -> "model.layers.7.mlp.experts.42.act_fn" [label="1"];
  "model.layers.7.mlp.experts.42" -> "model.layers.7.mlp.experts.42.up_proj" [label="1"];
  "model.layers.7.mlp.experts.42" -> "model.layers.7.mlp.experts.42.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.43" [label="1"];
  "model.layers.7.mlp.experts.43" -> "model.layers.7.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.43" -> "model.layers.7.mlp.experts.43.act_fn" [label="1"];
  "model.layers.7.mlp.experts.43" -> "model.layers.7.mlp.experts.43.up_proj" [label="1"];
  "model.layers.7.mlp.experts.43" -> "model.layers.7.mlp.experts.43.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.44" [label="1"];
  "model.layers.7.mlp.experts.44" -> "model.layers.7.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.44" -> "model.layers.7.mlp.experts.44.act_fn" [label="1"];
  "model.layers.7.mlp.experts.44" -> "model.layers.7.mlp.experts.44.up_proj" [label="1"];
  "model.layers.7.mlp.experts.44" -> "model.layers.7.mlp.experts.44.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.45" [label="1"];
  "model.layers.7.mlp.experts.45" -> "model.layers.7.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.45" -> "model.layers.7.mlp.experts.45.act_fn" [label="1"];
  "model.layers.7.mlp.experts.45" -> "model.layers.7.mlp.experts.45.up_proj" [label="1"];
  "model.layers.7.mlp.experts.45" -> "model.layers.7.mlp.experts.45.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.46" [label="1"];
  "model.layers.7.mlp.experts.46" -> "model.layers.7.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.46" -> "model.layers.7.mlp.experts.46.act_fn" [label="1"];
  "model.layers.7.mlp.experts.46" -> "model.layers.7.mlp.experts.46.up_proj" [label="1"];
  "model.layers.7.mlp.experts.46" -> "model.layers.7.mlp.experts.46.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.47" [label="1"];
  "model.layers.7.mlp.experts.47" -> "model.layers.7.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.47" -> "model.layers.7.mlp.experts.47.act_fn" [label="1"];
  "model.layers.7.mlp.experts.47" -> "model.layers.7.mlp.experts.47.up_proj" [label="1"];
  "model.layers.7.mlp.experts.47" -> "model.layers.7.mlp.experts.47.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.48" [label="1"];
  "model.layers.7.mlp.experts.48" -> "model.layers.7.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.48" -> "model.layers.7.mlp.experts.48.act_fn" [label="1"];
  "model.layers.7.mlp.experts.48" -> "model.layers.7.mlp.experts.48.up_proj" [label="1"];
  "model.layers.7.mlp.experts.48" -> "model.layers.7.mlp.experts.48.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.49" [label="1"];
  "model.layers.7.mlp.experts.49" -> "model.layers.7.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.49" -> "model.layers.7.mlp.experts.49.act_fn" [label="1"];
  "model.layers.7.mlp.experts.49" -> "model.layers.7.mlp.experts.49.up_proj" [label="1"];
  "model.layers.7.mlp.experts.49" -> "model.layers.7.mlp.experts.49.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.51" [label="1"];
  "model.layers.7.mlp.experts.51" -> "model.layers.7.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.51" -> "model.layers.7.mlp.experts.51.act_fn" [label="1"];
  "model.layers.7.mlp.experts.51" -> "model.layers.7.mlp.experts.51.up_proj" [label="1"];
  "model.layers.7.mlp.experts.51" -> "model.layers.7.mlp.experts.51.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.52" [label="1"];
  "model.layers.7.mlp.experts.52" -> "model.layers.7.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.52" -> "model.layers.7.mlp.experts.52.act_fn" [label="1"];
  "model.layers.7.mlp.experts.52" -> "model.layers.7.mlp.experts.52.up_proj" [label="1"];
  "model.layers.7.mlp.experts.52" -> "model.layers.7.mlp.experts.52.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.53" [label="1"];
  "model.layers.7.mlp.experts.53" -> "model.layers.7.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.53" -> "model.layers.7.mlp.experts.53.act_fn" [label="1"];
  "model.layers.7.mlp.experts.53" -> "model.layers.7.mlp.experts.53.up_proj" [label="1"];
  "model.layers.7.mlp.experts.53" -> "model.layers.7.mlp.experts.53.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.54" [label="1"];
  "model.layers.7.mlp.experts.54" -> "model.layers.7.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.54" -> "model.layers.7.mlp.experts.54.act_fn" [label="1"];
  "model.layers.7.mlp.experts.54" -> "model.layers.7.mlp.experts.54.up_proj" [label="1"];
  "model.layers.7.mlp.experts.54" -> "model.layers.7.mlp.experts.54.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.55" [label="1"];
  "model.layers.7.mlp.experts.55" -> "model.layers.7.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.55" -> "model.layers.7.mlp.experts.55.act_fn" [label="1"];
  "model.layers.7.mlp.experts.55" -> "model.layers.7.mlp.experts.55.up_proj" [label="1"];
  "model.layers.7.mlp.experts.55" -> "model.layers.7.mlp.experts.55.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.56" [label="1"];
  "model.layers.7.mlp.experts.56" -> "model.layers.7.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.56" -> "model.layers.7.mlp.experts.56.act_fn" [label="1"];
  "model.layers.7.mlp.experts.56" -> "model.layers.7.mlp.experts.56.up_proj" [label="1"];
  "model.layers.7.mlp.experts.56" -> "model.layers.7.mlp.experts.56.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.57" [label="1"];
  "model.layers.7.mlp.experts.57" -> "model.layers.7.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.57" -> "model.layers.7.mlp.experts.57.act_fn" [label="1"];
  "model.layers.7.mlp.experts.57" -> "model.layers.7.mlp.experts.57.up_proj" [label="1"];
  "model.layers.7.mlp.experts.57" -> "model.layers.7.mlp.experts.57.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.58" [label="1"];
  "model.layers.7.mlp.experts.58" -> "model.layers.7.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.58" -> "model.layers.7.mlp.experts.58.act_fn" [label="1"];
  "model.layers.7.mlp.experts.58" -> "model.layers.7.mlp.experts.58.up_proj" [label="1"];
  "model.layers.7.mlp.experts.58" -> "model.layers.7.mlp.experts.58.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.59" [label="1"];
  "model.layers.7.mlp.experts.59" -> "model.layers.7.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.59" -> "model.layers.7.mlp.experts.59.act_fn" [label="1"];
  "model.layers.7.mlp.experts.59" -> "model.layers.7.mlp.experts.59.up_proj" [label="1"];
  "model.layers.7.mlp.experts.59" -> "model.layers.7.mlp.experts.59.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.60" [label="1"];
  "model.layers.7.mlp.experts.60" -> "model.layers.7.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.60" -> "model.layers.7.mlp.experts.60.act_fn" [label="1"];
  "model.layers.7.mlp.experts.60" -> "model.layers.7.mlp.experts.60.up_proj" [label="1"];
  "model.layers.7.mlp.experts.60" -> "model.layers.7.mlp.experts.60.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.61" [label="1"];
  "model.layers.7.mlp.experts.61" -> "model.layers.7.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.61" -> "model.layers.7.mlp.experts.61.act_fn" [label="1"];
  "model.layers.7.mlp.experts.61" -> "model.layers.7.mlp.experts.61.up_proj" [label="1"];
  "model.layers.7.mlp.experts.61" -> "model.layers.7.mlp.experts.61.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.62" [label="1"];
  "model.layers.7.mlp.experts.62" -> "model.layers.7.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.62" -> "model.layers.7.mlp.experts.62.act_fn" [label="1"];
  "model.layers.7.mlp.experts.62" -> "model.layers.7.mlp.experts.62.up_proj" [label="1"];
  "model.layers.7.mlp.experts.62" -> "model.layers.7.mlp.experts.62.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.experts.63" [label="1"];
  "model.layers.7.mlp.experts.63" -> "model.layers.7.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.7.mlp.experts.63" -> "model.layers.7.mlp.experts.63.act_fn" [label="1"];
  "model.layers.7.mlp.experts.63" -> "model.layers.7.mlp.experts.63.up_proj" [label="1"];
  "model.layers.7.mlp.experts.63" -> "model.layers.7.mlp.experts.63.down_proj" [label="1"];
  "model.layers.7.mlp" -> "model.layers.7.mlp.shared_experts" [label="1"];
  "model.layers.7.mlp.shared_experts" -> "model.layers.7.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.7.mlp.shared_experts" -> "model.layers.7.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.7.mlp.shared_experts" -> "model.layers.7.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.7.mlp.shared_experts" -> "model.layers.7.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.8" [label="1"];
  "model.layers.8" -> "model.layers.8.input_layernorm" [label="1"];
  "model.layers.8" -> "model.layers.8.self_attn" [label="1"];
  "model.layers.8.self_attn" -> "model.layers.8.self_attn.q_proj" [label="1"];
  "model.layers.8.self_attn" -> "model.layers.8.self_attn.k_proj" [label="1"];
  "model.layers.8.self_attn" -> "model.layers.8.self_attn.v_proj" [label="1"];
  "model.layers.8.self_attn" -> "model.layers.8.self_attn.o_proj" [label="1"];
  "model.layers.8" -> "model.layers.8.post_attention_layernorm" [label="1"];
  "model.layers.8" -> "model.layers.8.mlp" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.gate" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.1" [label="1"];
  "model.layers.8.mlp.experts.1" -> "model.layers.8.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.1" -> "model.layers.8.mlp.experts.1.act_fn" [label="1"];
  "model.layers.8.mlp.experts.1" -> "model.layers.8.mlp.experts.1.up_proj" [label="1"];
  "model.layers.8.mlp.experts.1" -> "model.layers.8.mlp.experts.1.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.2" [label="1"];
  "model.layers.8.mlp.experts.2" -> "model.layers.8.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.2" -> "model.layers.8.mlp.experts.2.act_fn" [label="1"];
  "model.layers.8.mlp.experts.2" -> "model.layers.8.mlp.experts.2.up_proj" [label="1"];
  "model.layers.8.mlp.experts.2" -> "model.layers.8.mlp.experts.2.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.3" [label="1"];
  "model.layers.8.mlp.experts.3" -> "model.layers.8.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.3" -> "model.layers.8.mlp.experts.3.act_fn" [label="1"];
  "model.layers.8.mlp.experts.3" -> "model.layers.8.mlp.experts.3.up_proj" [label="1"];
  "model.layers.8.mlp.experts.3" -> "model.layers.8.mlp.experts.3.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.4" [label="1"];
  "model.layers.8.mlp.experts.4" -> "model.layers.8.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.4" -> "model.layers.8.mlp.experts.4.act_fn" [label="1"];
  "model.layers.8.mlp.experts.4" -> "model.layers.8.mlp.experts.4.up_proj" [label="1"];
  "model.layers.8.mlp.experts.4" -> "model.layers.8.mlp.experts.4.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.5" [label="1"];
  "model.layers.8.mlp.experts.5" -> "model.layers.8.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.5" -> "model.layers.8.mlp.experts.5.act_fn" [label="1"];
  "model.layers.8.mlp.experts.5" -> "model.layers.8.mlp.experts.5.up_proj" [label="1"];
  "model.layers.8.mlp.experts.5" -> "model.layers.8.mlp.experts.5.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.6" [label="1"];
  "model.layers.8.mlp.experts.6" -> "model.layers.8.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.6" -> "model.layers.8.mlp.experts.6.act_fn" [label="1"];
  "model.layers.8.mlp.experts.6" -> "model.layers.8.mlp.experts.6.up_proj" [label="1"];
  "model.layers.8.mlp.experts.6" -> "model.layers.8.mlp.experts.6.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.7" [label="1"];
  "model.layers.8.mlp.experts.7" -> "model.layers.8.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.7" -> "model.layers.8.mlp.experts.7.act_fn" [label="1"];
  "model.layers.8.mlp.experts.7" -> "model.layers.8.mlp.experts.7.up_proj" [label="1"];
  "model.layers.8.mlp.experts.7" -> "model.layers.8.mlp.experts.7.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.8" [label="1"];
  "model.layers.8.mlp.experts.8" -> "model.layers.8.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.8" -> "model.layers.8.mlp.experts.8.act_fn" [label="1"];
  "model.layers.8.mlp.experts.8" -> "model.layers.8.mlp.experts.8.up_proj" [label="1"];
  "model.layers.8.mlp.experts.8" -> "model.layers.8.mlp.experts.8.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.9" [label="1"];
  "model.layers.8.mlp.experts.9" -> "model.layers.8.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.9" -> "model.layers.8.mlp.experts.9.act_fn" [label="1"];
  "model.layers.8.mlp.experts.9" -> "model.layers.8.mlp.experts.9.up_proj" [label="1"];
  "model.layers.8.mlp.experts.9" -> "model.layers.8.mlp.experts.9.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.10" [label="1"];
  "model.layers.8.mlp.experts.10" -> "model.layers.8.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.10" -> "model.layers.8.mlp.experts.10.act_fn" [label="1"];
  "model.layers.8.mlp.experts.10" -> "model.layers.8.mlp.experts.10.up_proj" [label="1"];
  "model.layers.8.mlp.experts.10" -> "model.layers.8.mlp.experts.10.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.11" [label="1"];
  "model.layers.8.mlp.experts.11" -> "model.layers.8.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.11" -> "model.layers.8.mlp.experts.11.act_fn" [label="1"];
  "model.layers.8.mlp.experts.11" -> "model.layers.8.mlp.experts.11.up_proj" [label="1"];
  "model.layers.8.mlp.experts.11" -> "model.layers.8.mlp.experts.11.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.12" [label="1"];
  "model.layers.8.mlp.experts.12" -> "model.layers.8.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.12" -> "model.layers.8.mlp.experts.12.act_fn" [label="1"];
  "model.layers.8.mlp.experts.12" -> "model.layers.8.mlp.experts.12.up_proj" [label="1"];
  "model.layers.8.mlp.experts.12" -> "model.layers.8.mlp.experts.12.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.13" [label="1"];
  "model.layers.8.mlp.experts.13" -> "model.layers.8.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.13" -> "model.layers.8.mlp.experts.13.act_fn" [label="1"];
  "model.layers.8.mlp.experts.13" -> "model.layers.8.mlp.experts.13.up_proj" [label="1"];
  "model.layers.8.mlp.experts.13" -> "model.layers.8.mlp.experts.13.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.14" [label="1"];
  "model.layers.8.mlp.experts.14" -> "model.layers.8.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.14" -> "model.layers.8.mlp.experts.14.act_fn" [label="1"];
  "model.layers.8.mlp.experts.14" -> "model.layers.8.mlp.experts.14.up_proj" [label="1"];
  "model.layers.8.mlp.experts.14" -> "model.layers.8.mlp.experts.14.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.15" [label="1"];
  "model.layers.8.mlp.experts.15" -> "model.layers.8.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.15" -> "model.layers.8.mlp.experts.15.act_fn" [label="1"];
  "model.layers.8.mlp.experts.15" -> "model.layers.8.mlp.experts.15.up_proj" [label="1"];
  "model.layers.8.mlp.experts.15" -> "model.layers.8.mlp.experts.15.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.16" [label="1"];
  "model.layers.8.mlp.experts.16" -> "model.layers.8.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.16" -> "model.layers.8.mlp.experts.16.act_fn" [label="1"];
  "model.layers.8.mlp.experts.16" -> "model.layers.8.mlp.experts.16.up_proj" [label="1"];
  "model.layers.8.mlp.experts.16" -> "model.layers.8.mlp.experts.16.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.17" [label="1"];
  "model.layers.8.mlp.experts.17" -> "model.layers.8.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.17" -> "model.layers.8.mlp.experts.17.act_fn" [label="1"];
  "model.layers.8.mlp.experts.17" -> "model.layers.8.mlp.experts.17.up_proj" [label="1"];
  "model.layers.8.mlp.experts.17" -> "model.layers.8.mlp.experts.17.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.18" [label="1"];
  "model.layers.8.mlp.experts.18" -> "model.layers.8.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.18" -> "model.layers.8.mlp.experts.18.act_fn" [label="1"];
  "model.layers.8.mlp.experts.18" -> "model.layers.8.mlp.experts.18.up_proj" [label="1"];
  "model.layers.8.mlp.experts.18" -> "model.layers.8.mlp.experts.18.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.20" [label="1"];
  "model.layers.8.mlp.experts.20" -> "model.layers.8.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.20" -> "model.layers.8.mlp.experts.20.act_fn" [label="1"];
  "model.layers.8.mlp.experts.20" -> "model.layers.8.mlp.experts.20.up_proj" [label="1"];
  "model.layers.8.mlp.experts.20" -> "model.layers.8.mlp.experts.20.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.21" [label="1"];
  "model.layers.8.mlp.experts.21" -> "model.layers.8.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.21" -> "model.layers.8.mlp.experts.21.act_fn" [label="1"];
  "model.layers.8.mlp.experts.21" -> "model.layers.8.mlp.experts.21.up_proj" [label="1"];
  "model.layers.8.mlp.experts.21" -> "model.layers.8.mlp.experts.21.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.22" [label="1"];
  "model.layers.8.mlp.experts.22" -> "model.layers.8.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.22" -> "model.layers.8.mlp.experts.22.act_fn" [label="1"];
  "model.layers.8.mlp.experts.22" -> "model.layers.8.mlp.experts.22.up_proj" [label="1"];
  "model.layers.8.mlp.experts.22" -> "model.layers.8.mlp.experts.22.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.23" [label="1"];
  "model.layers.8.mlp.experts.23" -> "model.layers.8.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.23" -> "model.layers.8.mlp.experts.23.act_fn" [label="1"];
  "model.layers.8.mlp.experts.23" -> "model.layers.8.mlp.experts.23.up_proj" [label="1"];
  "model.layers.8.mlp.experts.23" -> "model.layers.8.mlp.experts.23.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.24" [label="1"];
  "model.layers.8.mlp.experts.24" -> "model.layers.8.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.24" -> "model.layers.8.mlp.experts.24.act_fn" [label="1"];
  "model.layers.8.mlp.experts.24" -> "model.layers.8.mlp.experts.24.up_proj" [label="1"];
  "model.layers.8.mlp.experts.24" -> "model.layers.8.mlp.experts.24.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.25" [label="1"];
  "model.layers.8.mlp.experts.25" -> "model.layers.8.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.25" -> "model.layers.8.mlp.experts.25.act_fn" [label="1"];
  "model.layers.8.mlp.experts.25" -> "model.layers.8.mlp.experts.25.up_proj" [label="1"];
  "model.layers.8.mlp.experts.25" -> "model.layers.8.mlp.experts.25.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.26" [label="1"];
  "model.layers.8.mlp.experts.26" -> "model.layers.8.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.26" -> "model.layers.8.mlp.experts.26.act_fn" [label="1"];
  "model.layers.8.mlp.experts.26" -> "model.layers.8.mlp.experts.26.up_proj" [label="1"];
  "model.layers.8.mlp.experts.26" -> "model.layers.8.mlp.experts.26.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.27" [label="1"];
  "model.layers.8.mlp.experts.27" -> "model.layers.8.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.27" -> "model.layers.8.mlp.experts.27.act_fn" [label="1"];
  "model.layers.8.mlp.experts.27" -> "model.layers.8.mlp.experts.27.up_proj" [label="1"];
  "model.layers.8.mlp.experts.27" -> "model.layers.8.mlp.experts.27.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.28" [label="1"];
  "model.layers.8.mlp.experts.28" -> "model.layers.8.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.28" -> "model.layers.8.mlp.experts.28.act_fn" [label="1"];
  "model.layers.8.mlp.experts.28" -> "model.layers.8.mlp.experts.28.up_proj" [label="1"];
  "model.layers.8.mlp.experts.28" -> "model.layers.8.mlp.experts.28.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.29" [label="1"];
  "model.layers.8.mlp.experts.29" -> "model.layers.8.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.29" -> "model.layers.8.mlp.experts.29.act_fn" [label="1"];
  "model.layers.8.mlp.experts.29" -> "model.layers.8.mlp.experts.29.up_proj" [label="1"];
  "model.layers.8.mlp.experts.29" -> "model.layers.8.mlp.experts.29.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.30" [label="1"];
  "model.layers.8.mlp.experts.30" -> "model.layers.8.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.30" -> "model.layers.8.mlp.experts.30.act_fn" [label="1"];
  "model.layers.8.mlp.experts.30" -> "model.layers.8.mlp.experts.30.up_proj" [label="1"];
  "model.layers.8.mlp.experts.30" -> "model.layers.8.mlp.experts.30.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.32" [label="1"];
  "model.layers.8.mlp.experts.32" -> "model.layers.8.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.32" -> "model.layers.8.mlp.experts.32.act_fn" [label="1"];
  "model.layers.8.mlp.experts.32" -> "model.layers.8.mlp.experts.32.up_proj" [label="1"];
  "model.layers.8.mlp.experts.32" -> "model.layers.8.mlp.experts.32.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.33" [label="1"];
  "model.layers.8.mlp.experts.33" -> "model.layers.8.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.33" -> "model.layers.8.mlp.experts.33.act_fn" [label="1"];
  "model.layers.8.mlp.experts.33" -> "model.layers.8.mlp.experts.33.up_proj" [label="1"];
  "model.layers.8.mlp.experts.33" -> "model.layers.8.mlp.experts.33.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.34" [label="1"];
  "model.layers.8.mlp.experts.34" -> "model.layers.8.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.34" -> "model.layers.8.mlp.experts.34.act_fn" [label="1"];
  "model.layers.8.mlp.experts.34" -> "model.layers.8.mlp.experts.34.up_proj" [label="1"];
  "model.layers.8.mlp.experts.34" -> "model.layers.8.mlp.experts.34.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.35" [label="1"];
  "model.layers.8.mlp.experts.35" -> "model.layers.8.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.35" -> "model.layers.8.mlp.experts.35.act_fn" [label="1"];
  "model.layers.8.mlp.experts.35" -> "model.layers.8.mlp.experts.35.up_proj" [label="1"];
  "model.layers.8.mlp.experts.35" -> "model.layers.8.mlp.experts.35.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.36" [label="1"];
  "model.layers.8.mlp.experts.36" -> "model.layers.8.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.36" -> "model.layers.8.mlp.experts.36.act_fn" [label="1"];
  "model.layers.8.mlp.experts.36" -> "model.layers.8.mlp.experts.36.up_proj" [label="1"];
  "model.layers.8.mlp.experts.36" -> "model.layers.8.mlp.experts.36.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.37" [label="1"];
  "model.layers.8.mlp.experts.37" -> "model.layers.8.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.37" -> "model.layers.8.mlp.experts.37.act_fn" [label="1"];
  "model.layers.8.mlp.experts.37" -> "model.layers.8.mlp.experts.37.up_proj" [label="1"];
  "model.layers.8.mlp.experts.37" -> "model.layers.8.mlp.experts.37.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.39" [label="1"];
  "model.layers.8.mlp.experts.39" -> "model.layers.8.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.39" -> "model.layers.8.mlp.experts.39.act_fn" [label="1"];
  "model.layers.8.mlp.experts.39" -> "model.layers.8.mlp.experts.39.up_proj" [label="1"];
  "model.layers.8.mlp.experts.39" -> "model.layers.8.mlp.experts.39.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.40" [label="1"];
  "model.layers.8.mlp.experts.40" -> "model.layers.8.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.40" -> "model.layers.8.mlp.experts.40.act_fn" [label="1"];
  "model.layers.8.mlp.experts.40" -> "model.layers.8.mlp.experts.40.up_proj" [label="1"];
  "model.layers.8.mlp.experts.40" -> "model.layers.8.mlp.experts.40.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.41" [label="1"];
  "model.layers.8.mlp.experts.41" -> "model.layers.8.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.41" -> "model.layers.8.mlp.experts.41.act_fn" [label="1"];
  "model.layers.8.mlp.experts.41" -> "model.layers.8.mlp.experts.41.up_proj" [label="1"];
  "model.layers.8.mlp.experts.41" -> "model.layers.8.mlp.experts.41.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.42" [label="1"];
  "model.layers.8.mlp.experts.42" -> "model.layers.8.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.42" -> "model.layers.8.mlp.experts.42.act_fn" [label="1"];
  "model.layers.8.mlp.experts.42" -> "model.layers.8.mlp.experts.42.up_proj" [label="1"];
  "model.layers.8.mlp.experts.42" -> "model.layers.8.mlp.experts.42.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.43" [label="1"];
  "model.layers.8.mlp.experts.43" -> "model.layers.8.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.43" -> "model.layers.8.mlp.experts.43.act_fn" [label="1"];
  "model.layers.8.mlp.experts.43" -> "model.layers.8.mlp.experts.43.up_proj" [label="1"];
  "model.layers.8.mlp.experts.43" -> "model.layers.8.mlp.experts.43.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.44" [label="1"];
  "model.layers.8.mlp.experts.44" -> "model.layers.8.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.44" -> "model.layers.8.mlp.experts.44.act_fn" [label="1"];
  "model.layers.8.mlp.experts.44" -> "model.layers.8.mlp.experts.44.up_proj" [label="1"];
  "model.layers.8.mlp.experts.44" -> "model.layers.8.mlp.experts.44.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.45" [label="1"];
  "model.layers.8.mlp.experts.45" -> "model.layers.8.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.45" -> "model.layers.8.mlp.experts.45.act_fn" [label="1"];
  "model.layers.8.mlp.experts.45" -> "model.layers.8.mlp.experts.45.up_proj" [label="1"];
  "model.layers.8.mlp.experts.45" -> "model.layers.8.mlp.experts.45.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.46" [label="1"];
  "model.layers.8.mlp.experts.46" -> "model.layers.8.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.46" -> "model.layers.8.mlp.experts.46.act_fn" [label="1"];
  "model.layers.8.mlp.experts.46" -> "model.layers.8.mlp.experts.46.up_proj" [label="1"];
  "model.layers.8.mlp.experts.46" -> "model.layers.8.mlp.experts.46.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.47" [label="1"];
  "model.layers.8.mlp.experts.47" -> "model.layers.8.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.47" -> "model.layers.8.mlp.experts.47.act_fn" [label="1"];
  "model.layers.8.mlp.experts.47" -> "model.layers.8.mlp.experts.47.up_proj" [label="1"];
  "model.layers.8.mlp.experts.47" -> "model.layers.8.mlp.experts.47.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.48" [label="1"];
  "model.layers.8.mlp.experts.48" -> "model.layers.8.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.48" -> "model.layers.8.mlp.experts.48.act_fn" [label="1"];
  "model.layers.8.mlp.experts.48" -> "model.layers.8.mlp.experts.48.up_proj" [label="1"];
  "model.layers.8.mlp.experts.48" -> "model.layers.8.mlp.experts.48.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.49" [label="1"];
  "model.layers.8.mlp.experts.49" -> "model.layers.8.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.49" -> "model.layers.8.mlp.experts.49.act_fn" [label="1"];
  "model.layers.8.mlp.experts.49" -> "model.layers.8.mlp.experts.49.up_proj" [label="1"];
  "model.layers.8.mlp.experts.49" -> "model.layers.8.mlp.experts.49.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.50" [label="1"];
  "model.layers.8.mlp.experts.50" -> "model.layers.8.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.50" -> "model.layers.8.mlp.experts.50.act_fn" [label="1"];
  "model.layers.8.mlp.experts.50" -> "model.layers.8.mlp.experts.50.up_proj" [label="1"];
  "model.layers.8.mlp.experts.50" -> "model.layers.8.mlp.experts.50.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.51" [label="1"];
  "model.layers.8.mlp.experts.51" -> "model.layers.8.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.51" -> "model.layers.8.mlp.experts.51.act_fn" [label="1"];
  "model.layers.8.mlp.experts.51" -> "model.layers.8.mlp.experts.51.up_proj" [label="1"];
  "model.layers.8.mlp.experts.51" -> "model.layers.8.mlp.experts.51.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.52" [label="1"];
  "model.layers.8.mlp.experts.52" -> "model.layers.8.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.52" -> "model.layers.8.mlp.experts.52.act_fn" [label="1"];
  "model.layers.8.mlp.experts.52" -> "model.layers.8.mlp.experts.52.up_proj" [label="1"];
  "model.layers.8.mlp.experts.52" -> "model.layers.8.mlp.experts.52.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.53" [label="1"];
  "model.layers.8.mlp.experts.53" -> "model.layers.8.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.53" -> "model.layers.8.mlp.experts.53.act_fn" [label="1"];
  "model.layers.8.mlp.experts.53" -> "model.layers.8.mlp.experts.53.up_proj" [label="1"];
  "model.layers.8.mlp.experts.53" -> "model.layers.8.mlp.experts.53.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.54" [label="1"];
  "model.layers.8.mlp.experts.54" -> "model.layers.8.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.54" -> "model.layers.8.mlp.experts.54.act_fn" [label="1"];
  "model.layers.8.mlp.experts.54" -> "model.layers.8.mlp.experts.54.up_proj" [label="1"];
  "model.layers.8.mlp.experts.54" -> "model.layers.8.mlp.experts.54.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.55" [label="1"];
  "model.layers.8.mlp.experts.55" -> "model.layers.8.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.55" -> "model.layers.8.mlp.experts.55.act_fn" [label="1"];
  "model.layers.8.mlp.experts.55" -> "model.layers.8.mlp.experts.55.up_proj" [label="1"];
  "model.layers.8.mlp.experts.55" -> "model.layers.8.mlp.experts.55.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.56" [label="1"];
  "model.layers.8.mlp.experts.56" -> "model.layers.8.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.56" -> "model.layers.8.mlp.experts.56.act_fn" [label="1"];
  "model.layers.8.mlp.experts.56" -> "model.layers.8.mlp.experts.56.up_proj" [label="1"];
  "model.layers.8.mlp.experts.56" -> "model.layers.8.mlp.experts.56.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.57" [label="1"];
  "model.layers.8.mlp.experts.57" -> "model.layers.8.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.57" -> "model.layers.8.mlp.experts.57.act_fn" [label="1"];
  "model.layers.8.mlp.experts.57" -> "model.layers.8.mlp.experts.57.up_proj" [label="1"];
  "model.layers.8.mlp.experts.57" -> "model.layers.8.mlp.experts.57.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.58" [label="1"];
  "model.layers.8.mlp.experts.58" -> "model.layers.8.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.58" -> "model.layers.8.mlp.experts.58.act_fn" [label="1"];
  "model.layers.8.mlp.experts.58" -> "model.layers.8.mlp.experts.58.up_proj" [label="1"];
  "model.layers.8.mlp.experts.58" -> "model.layers.8.mlp.experts.58.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.59" [label="1"];
  "model.layers.8.mlp.experts.59" -> "model.layers.8.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.59" -> "model.layers.8.mlp.experts.59.act_fn" [label="1"];
  "model.layers.8.mlp.experts.59" -> "model.layers.8.mlp.experts.59.up_proj" [label="1"];
  "model.layers.8.mlp.experts.59" -> "model.layers.8.mlp.experts.59.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.60" [label="1"];
  "model.layers.8.mlp.experts.60" -> "model.layers.8.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.60" -> "model.layers.8.mlp.experts.60.act_fn" [label="1"];
  "model.layers.8.mlp.experts.60" -> "model.layers.8.mlp.experts.60.up_proj" [label="1"];
  "model.layers.8.mlp.experts.60" -> "model.layers.8.mlp.experts.60.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.61" [label="1"];
  "model.layers.8.mlp.experts.61" -> "model.layers.8.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.61" -> "model.layers.8.mlp.experts.61.act_fn" [label="1"];
  "model.layers.8.mlp.experts.61" -> "model.layers.8.mlp.experts.61.up_proj" [label="1"];
  "model.layers.8.mlp.experts.61" -> "model.layers.8.mlp.experts.61.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.62" [label="1"];
  "model.layers.8.mlp.experts.62" -> "model.layers.8.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.62" -> "model.layers.8.mlp.experts.62.act_fn" [label="1"];
  "model.layers.8.mlp.experts.62" -> "model.layers.8.mlp.experts.62.up_proj" [label="1"];
  "model.layers.8.mlp.experts.62" -> "model.layers.8.mlp.experts.62.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.experts.63" [label="1"];
  "model.layers.8.mlp.experts.63" -> "model.layers.8.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.8.mlp.experts.63" -> "model.layers.8.mlp.experts.63.act_fn" [label="1"];
  "model.layers.8.mlp.experts.63" -> "model.layers.8.mlp.experts.63.up_proj" [label="1"];
  "model.layers.8.mlp.experts.63" -> "model.layers.8.mlp.experts.63.down_proj" [label="1"];
  "model.layers.8.mlp" -> "model.layers.8.mlp.shared_experts" [label="1"];
  "model.layers.8.mlp.shared_experts" -> "model.layers.8.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.8.mlp.shared_experts" -> "model.layers.8.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.8.mlp.shared_experts" -> "model.layers.8.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.8.mlp.shared_experts" -> "model.layers.8.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.9" [label="1"];
  "model.layers.9" -> "model.layers.9.input_layernorm" [label="1"];
  "model.layers.9" -> "model.layers.9.self_attn" [label="1"];
  "model.layers.9.self_attn" -> "model.layers.9.self_attn.q_proj" [label="1"];
  "model.layers.9.self_attn" -> "model.layers.9.self_attn.k_proj" [label="1"];
  "model.layers.9.self_attn" -> "model.layers.9.self_attn.v_proj" [label="1"];
  "model.layers.9.self_attn" -> "model.layers.9.self_attn.o_proj" [label="1"];
  "model.layers.9" -> "model.layers.9.post_attention_layernorm" [label="1"];
  "model.layers.9" -> "model.layers.9.mlp" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.gate" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.0" [label="1"];
  "model.layers.9.mlp.experts.0" -> "model.layers.9.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.0" -> "model.layers.9.mlp.experts.0.act_fn" [label="1"];
  "model.layers.9.mlp.experts.0" -> "model.layers.9.mlp.experts.0.up_proj" [label="1"];
  "model.layers.9.mlp.experts.0" -> "model.layers.9.mlp.experts.0.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.1" [label="1"];
  "model.layers.9.mlp.experts.1" -> "model.layers.9.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.1" -> "model.layers.9.mlp.experts.1.act_fn" [label="1"];
  "model.layers.9.mlp.experts.1" -> "model.layers.9.mlp.experts.1.up_proj" [label="1"];
  "model.layers.9.mlp.experts.1" -> "model.layers.9.mlp.experts.1.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.2" [label="1"];
  "model.layers.9.mlp.experts.2" -> "model.layers.9.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.2" -> "model.layers.9.mlp.experts.2.act_fn" [label="1"];
  "model.layers.9.mlp.experts.2" -> "model.layers.9.mlp.experts.2.up_proj" [label="1"];
  "model.layers.9.mlp.experts.2" -> "model.layers.9.mlp.experts.2.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.3" [label="1"];
  "model.layers.9.mlp.experts.3" -> "model.layers.9.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.3" -> "model.layers.9.mlp.experts.3.act_fn" [label="1"];
  "model.layers.9.mlp.experts.3" -> "model.layers.9.mlp.experts.3.up_proj" [label="1"];
  "model.layers.9.mlp.experts.3" -> "model.layers.9.mlp.experts.3.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.4" [label="1"];
  "model.layers.9.mlp.experts.4" -> "model.layers.9.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.4" -> "model.layers.9.mlp.experts.4.act_fn" [label="1"];
  "model.layers.9.mlp.experts.4" -> "model.layers.9.mlp.experts.4.up_proj" [label="1"];
  "model.layers.9.mlp.experts.4" -> "model.layers.9.mlp.experts.4.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.5" [label="1"];
  "model.layers.9.mlp.experts.5" -> "model.layers.9.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.5" -> "model.layers.9.mlp.experts.5.act_fn" [label="1"];
  "model.layers.9.mlp.experts.5" -> "model.layers.9.mlp.experts.5.up_proj" [label="1"];
  "model.layers.9.mlp.experts.5" -> "model.layers.9.mlp.experts.5.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.6" [label="1"];
  "model.layers.9.mlp.experts.6" -> "model.layers.9.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.6" -> "model.layers.9.mlp.experts.6.act_fn" [label="1"];
  "model.layers.9.mlp.experts.6" -> "model.layers.9.mlp.experts.6.up_proj" [label="1"];
  "model.layers.9.mlp.experts.6" -> "model.layers.9.mlp.experts.6.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.7" [label="1"];
  "model.layers.9.mlp.experts.7" -> "model.layers.9.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.7" -> "model.layers.9.mlp.experts.7.act_fn" [label="1"];
  "model.layers.9.mlp.experts.7" -> "model.layers.9.mlp.experts.7.up_proj" [label="1"];
  "model.layers.9.mlp.experts.7" -> "model.layers.9.mlp.experts.7.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.8" [label="1"];
  "model.layers.9.mlp.experts.8" -> "model.layers.9.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.8" -> "model.layers.9.mlp.experts.8.act_fn" [label="1"];
  "model.layers.9.mlp.experts.8" -> "model.layers.9.mlp.experts.8.up_proj" [label="1"];
  "model.layers.9.mlp.experts.8" -> "model.layers.9.mlp.experts.8.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.9" [label="1"];
  "model.layers.9.mlp.experts.9" -> "model.layers.9.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.9" -> "model.layers.9.mlp.experts.9.act_fn" [label="1"];
  "model.layers.9.mlp.experts.9" -> "model.layers.9.mlp.experts.9.up_proj" [label="1"];
  "model.layers.9.mlp.experts.9" -> "model.layers.9.mlp.experts.9.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.10" [label="1"];
  "model.layers.9.mlp.experts.10" -> "model.layers.9.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.10" -> "model.layers.9.mlp.experts.10.act_fn" [label="1"];
  "model.layers.9.mlp.experts.10" -> "model.layers.9.mlp.experts.10.up_proj" [label="1"];
  "model.layers.9.mlp.experts.10" -> "model.layers.9.mlp.experts.10.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.11" [label="1"];
  "model.layers.9.mlp.experts.11" -> "model.layers.9.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.11" -> "model.layers.9.mlp.experts.11.act_fn" [label="1"];
  "model.layers.9.mlp.experts.11" -> "model.layers.9.mlp.experts.11.up_proj" [label="1"];
  "model.layers.9.mlp.experts.11" -> "model.layers.9.mlp.experts.11.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.12" [label="1"];
  "model.layers.9.mlp.experts.12" -> "model.layers.9.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.12" -> "model.layers.9.mlp.experts.12.act_fn" [label="1"];
  "model.layers.9.mlp.experts.12" -> "model.layers.9.mlp.experts.12.up_proj" [label="1"];
  "model.layers.9.mlp.experts.12" -> "model.layers.9.mlp.experts.12.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.13" [label="1"];
  "model.layers.9.mlp.experts.13" -> "model.layers.9.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.13" -> "model.layers.9.mlp.experts.13.act_fn" [label="1"];
  "model.layers.9.mlp.experts.13" -> "model.layers.9.mlp.experts.13.up_proj" [label="1"];
  "model.layers.9.mlp.experts.13" -> "model.layers.9.mlp.experts.13.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.14" [label="1"];
  "model.layers.9.mlp.experts.14" -> "model.layers.9.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.14" -> "model.layers.9.mlp.experts.14.act_fn" [label="1"];
  "model.layers.9.mlp.experts.14" -> "model.layers.9.mlp.experts.14.up_proj" [label="1"];
  "model.layers.9.mlp.experts.14" -> "model.layers.9.mlp.experts.14.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.15" [label="1"];
  "model.layers.9.mlp.experts.15" -> "model.layers.9.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.15" -> "model.layers.9.mlp.experts.15.act_fn" [label="1"];
  "model.layers.9.mlp.experts.15" -> "model.layers.9.mlp.experts.15.up_proj" [label="1"];
  "model.layers.9.mlp.experts.15" -> "model.layers.9.mlp.experts.15.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.16" [label="1"];
  "model.layers.9.mlp.experts.16" -> "model.layers.9.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.16" -> "model.layers.9.mlp.experts.16.act_fn" [label="1"];
  "model.layers.9.mlp.experts.16" -> "model.layers.9.mlp.experts.16.up_proj" [label="1"];
  "model.layers.9.mlp.experts.16" -> "model.layers.9.mlp.experts.16.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.17" [label="1"];
  "model.layers.9.mlp.experts.17" -> "model.layers.9.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.17" -> "model.layers.9.mlp.experts.17.act_fn" [label="1"];
  "model.layers.9.mlp.experts.17" -> "model.layers.9.mlp.experts.17.up_proj" [label="1"];
  "model.layers.9.mlp.experts.17" -> "model.layers.9.mlp.experts.17.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.18" [label="1"];
  "model.layers.9.mlp.experts.18" -> "model.layers.9.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.18" -> "model.layers.9.mlp.experts.18.act_fn" [label="1"];
  "model.layers.9.mlp.experts.18" -> "model.layers.9.mlp.experts.18.up_proj" [label="1"];
  "model.layers.9.mlp.experts.18" -> "model.layers.9.mlp.experts.18.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.19" [label="1"];
  "model.layers.9.mlp.experts.19" -> "model.layers.9.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.19" -> "model.layers.9.mlp.experts.19.act_fn" [label="1"];
  "model.layers.9.mlp.experts.19" -> "model.layers.9.mlp.experts.19.up_proj" [label="1"];
  "model.layers.9.mlp.experts.19" -> "model.layers.9.mlp.experts.19.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.20" [label="1"];
  "model.layers.9.mlp.experts.20" -> "model.layers.9.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.20" -> "model.layers.9.mlp.experts.20.act_fn" [label="1"];
  "model.layers.9.mlp.experts.20" -> "model.layers.9.mlp.experts.20.up_proj" [label="1"];
  "model.layers.9.mlp.experts.20" -> "model.layers.9.mlp.experts.20.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.21" [label="1"];
  "model.layers.9.mlp.experts.21" -> "model.layers.9.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.21" -> "model.layers.9.mlp.experts.21.act_fn" [label="1"];
  "model.layers.9.mlp.experts.21" -> "model.layers.9.mlp.experts.21.up_proj" [label="1"];
  "model.layers.9.mlp.experts.21" -> "model.layers.9.mlp.experts.21.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.22" [label="1"];
  "model.layers.9.mlp.experts.22" -> "model.layers.9.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.22" -> "model.layers.9.mlp.experts.22.act_fn" [label="1"];
  "model.layers.9.mlp.experts.22" -> "model.layers.9.mlp.experts.22.up_proj" [label="1"];
  "model.layers.9.mlp.experts.22" -> "model.layers.9.mlp.experts.22.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.23" [label="1"];
  "model.layers.9.mlp.experts.23" -> "model.layers.9.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.23" -> "model.layers.9.mlp.experts.23.act_fn" [label="1"];
  "model.layers.9.mlp.experts.23" -> "model.layers.9.mlp.experts.23.up_proj" [label="1"];
  "model.layers.9.mlp.experts.23" -> "model.layers.9.mlp.experts.23.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.24" [label="1"];
  "model.layers.9.mlp.experts.24" -> "model.layers.9.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.24" -> "model.layers.9.mlp.experts.24.act_fn" [label="1"];
  "model.layers.9.mlp.experts.24" -> "model.layers.9.mlp.experts.24.up_proj" [label="1"];
  "model.layers.9.mlp.experts.24" -> "model.layers.9.mlp.experts.24.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.25" [label="1"];
  "model.layers.9.mlp.experts.25" -> "model.layers.9.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.25" -> "model.layers.9.mlp.experts.25.act_fn" [label="1"];
  "model.layers.9.mlp.experts.25" -> "model.layers.9.mlp.experts.25.up_proj" [label="1"];
  "model.layers.9.mlp.experts.25" -> "model.layers.9.mlp.experts.25.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.26" [label="1"];
  "model.layers.9.mlp.experts.26" -> "model.layers.9.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.26" -> "model.layers.9.mlp.experts.26.act_fn" [label="1"];
  "model.layers.9.mlp.experts.26" -> "model.layers.9.mlp.experts.26.up_proj" [label="1"];
  "model.layers.9.mlp.experts.26" -> "model.layers.9.mlp.experts.26.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.27" [label="1"];
  "model.layers.9.mlp.experts.27" -> "model.layers.9.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.27" -> "model.layers.9.mlp.experts.27.act_fn" [label="1"];
  "model.layers.9.mlp.experts.27" -> "model.layers.9.mlp.experts.27.up_proj" [label="1"];
  "model.layers.9.mlp.experts.27" -> "model.layers.9.mlp.experts.27.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.28" [label="1"];
  "model.layers.9.mlp.experts.28" -> "model.layers.9.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.28" -> "model.layers.9.mlp.experts.28.act_fn" [label="1"];
  "model.layers.9.mlp.experts.28" -> "model.layers.9.mlp.experts.28.up_proj" [label="1"];
  "model.layers.9.mlp.experts.28" -> "model.layers.9.mlp.experts.28.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.29" [label="1"];
  "model.layers.9.mlp.experts.29" -> "model.layers.9.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.29" -> "model.layers.9.mlp.experts.29.act_fn" [label="1"];
  "model.layers.9.mlp.experts.29" -> "model.layers.9.mlp.experts.29.up_proj" [label="1"];
  "model.layers.9.mlp.experts.29" -> "model.layers.9.mlp.experts.29.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.30" [label="1"];
  "model.layers.9.mlp.experts.30" -> "model.layers.9.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.30" -> "model.layers.9.mlp.experts.30.act_fn" [label="1"];
  "model.layers.9.mlp.experts.30" -> "model.layers.9.mlp.experts.30.up_proj" [label="1"];
  "model.layers.9.mlp.experts.30" -> "model.layers.9.mlp.experts.30.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.31" [label="1"];
  "model.layers.9.mlp.experts.31" -> "model.layers.9.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.31" -> "model.layers.9.mlp.experts.31.act_fn" [label="1"];
  "model.layers.9.mlp.experts.31" -> "model.layers.9.mlp.experts.31.up_proj" [label="1"];
  "model.layers.9.mlp.experts.31" -> "model.layers.9.mlp.experts.31.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.32" [label="1"];
  "model.layers.9.mlp.experts.32" -> "model.layers.9.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.32" -> "model.layers.9.mlp.experts.32.act_fn" [label="1"];
  "model.layers.9.mlp.experts.32" -> "model.layers.9.mlp.experts.32.up_proj" [label="1"];
  "model.layers.9.mlp.experts.32" -> "model.layers.9.mlp.experts.32.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.33" [label="1"];
  "model.layers.9.mlp.experts.33" -> "model.layers.9.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.33" -> "model.layers.9.mlp.experts.33.act_fn" [label="1"];
  "model.layers.9.mlp.experts.33" -> "model.layers.9.mlp.experts.33.up_proj" [label="1"];
  "model.layers.9.mlp.experts.33" -> "model.layers.9.mlp.experts.33.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.34" [label="1"];
  "model.layers.9.mlp.experts.34" -> "model.layers.9.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.34" -> "model.layers.9.mlp.experts.34.act_fn" [label="1"];
  "model.layers.9.mlp.experts.34" -> "model.layers.9.mlp.experts.34.up_proj" [label="1"];
  "model.layers.9.mlp.experts.34" -> "model.layers.9.mlp.experts.34.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.35" [label="1"];
  "model.layers.9.mlp.experts.35" -> "model.layers.9.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.35" -> "model.layers.9.mlp.experts.35.act_fn" [label="1"];
  "model.layers.9.mlp.experts.35" -> "model.layers.9.mlp.experts.35.up_proj" [label="1"];
  "model.layers.9.mlp.experts.35" -> "model.layers.9.mlp.experts.35.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.36" [label="1"];
  "model.layers.9.mlp.experts.36" -> "model.layers.9.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.36" -> "model.layers.9.mlp.experts.36.act_fn" [label="1"];
  "model.layers.9.mlp.experts.36" -> "model.layers.9.mlp.experts.36.up_proj" [label="1"];
  "model.layers.9.mlp.experts.36" -> "model.layers.9.mlp.experts.36.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.37" [label="1"];
  "model.layers.9.mlp.experts.37" -> "model.layers.9.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.37" -> "model.layers.9.mlp.experts.37.act_fn" [label="1"];
  "model.layers.9.mlp.experts.37" -> "model.layers.9.mlp.experts.37.up_proj" [label="1"];
  "model.layers.9.mlp.experts.37" -> "model.layers.9.mlp.experts.37.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.38" [label="1"];
  "model.layers.9.mlp.experts.38" -> "model.layers.9.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.38" -> "model.layers.9.mlp.experts.38.act_fn" [label="1"];
  "model.layers.9.mlp.experts.38" -> "model.layers.9.mlp.experts.38.up_proj" [label="1"];
  "model.layers.9.mlp.experts.38" -> "model.layers.9.mlp.experts.38.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.39" [label="1"];
  "model.layers.9.mlp.experts.39" -> "model.layers.9.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.39" -> "model.layers.9.mlp.experts.39.act_fn" [label="1"];
  "model.layers.9.mlp.experts.39" -> "model.layers.9.mlp.experts.39.up_proj" [label="1"];
  "model.layers.9.mlp.experts.39" -> "model.layers.9.mlp.experts.39.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.40" [label="1"];
  "model.layers.9.mlp.experts.40" -> "model.layers.9.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.40" -> "model.layers.9.mlp.experts.40.act_fn" [label="1"];
  "model.layers.9.mlp.experts.40" -> "model.layers.9.mlp.experts.40.up_proj" [label="1"];
  "model.layers.9.mlp.experts.40" -> "model.layers.9.mlp.experts.40.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.41" [label="1"];
  "model.layers.9.mlp.experts.41" -> "model.layers.9.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.41" -> "model.layers.9.mlp.experts.41.act_fn" [label="1"];
  "model.layers.9.mlp.experts.41" -> "model.layers.9.mlp.experts.41.up_proj" [label="1"];
  "model.layers.9.mlp.experts.41" -> "model.layers.9.mlp.experts.41.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.42" [label="1"];
  "model.layers.9.mlp.experts.42" -> "model.layers.9.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.42" -> "model.layers.9.mlp.experts.42.act_fn" [label="1"];
  "model.layers.9.mlp.experts.42" -> "model.layers.9.mlp.experts.42.up_proj" [label="1"];
  "model.layers.9.mlp.experts.42" -> "model.layers.9.mlp.experts.42.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.43" [label="1"];
  "model.layers.9.mlp.experts.43" -> "model.layers.9.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.43" -> "model.layers.9.mlp.experts.43.act_fn" [label="1"];
  "model.layers.9.mlp.experts.43" -> "model.layers.9.mlp.experts.43.up_proj" [label="1"];
  "model.layers.9.mlp.experts.43" -> "model.layers.9.mlp.experts.43.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.44" [label="1"];
  "model.layers.9.mlp.experts.44" -> "model.layers.9.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.44" -> "model.layers.9.mlp.experts.44.act_fn" [label="1"];
  "model.layers.9.mlp.experts.44" -> "model.layers.9.mlp.experts.44.up_proj" [label="1"];
  "model.layers.9.mlp.experts.44" -> "model.layers.9.mlp.experts.44.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.45" [label="1"];
  "model.layers.9.mlp.experts.45" -> "model.layers.9.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.45" -> "model.layers.9.mlp.experts.45.act_fn" [label="1"];
  "model.layers.9.mlp.experts.45" -> "model.layers.9.mlp.experts.45.up_proj" [label="1"];
  "model.layers.9.mlp.experts.45" -> "model.layers.9.mlp.experts.45.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.46" [label="1"];
  "model.layers.9.mlp.experts.46" -> "model.layers.9.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.46" -> "model.layers.9.mlp.experts.46.act_fn" [label="1"];
  "model.layers.9.mlp.experts.46" -> "model.layers.9.mlp.experts.46.up_proj" [label="1"];
  "model.layers.9.mlp.experts.46" -> "model.layers.9.mlp.experts.46.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.47" [label="1"];
  "model.layers.9.mlp.experts.47" -> "model.layers.9.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.47" -> "model.layers.9.mlp.experts.47.act_fn" [label="1"];
  "model.layers.9.mlp.experts.47" -> "model.layers.9.mlp.experts.47.up_proj" [label="1"];
  "model.layers.9.mlp.experts.47" -> "model.layers.9.mlp.experts.47.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.48" [label="1"];
  "model.layers.9.mlp.experts.48" -> "model.layers.9.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.48" -> "model.layers.9.mlp.experts.48.act_fn" [label="1"];
  "model.layers.9.mlp.experts.48" -> "model.layers.9.mlp.experts.48.up_proj" [label="1"];
  "model.layers.9.mlp.experts.48" -> "model.layers.9.mlp.experts.48.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.49" [label="1"];
  "model.layers.9.mlp.experts.49" -> "model.layers.9.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.49" -> "model.layers.9.mlp.experts.49.act_fn" [label="1"];
  "model.layers.9.mlp.experts.49" -> "model.layers.9.mlp.experts.49.up_proj" [label="1"];
  "model.layers.9.mlp.experts.49" -> "model.layers.9.mlp.experts.49.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.50" [label="1"];
  "model.layers.9.mlp.experts.50" -> "model.layers.9.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.50" -> "model.layers.9.mlp.experts.50.act_fn" [label="1"];
  "model.layers.9.mlp.experts.50" -> "model.layers.9.mlp.experts.50.up_proj" [label="1"];
  "model.layers.9.mlp.experts.50" -> "model.layers.9.mlp.experts.50.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.51" [label="1"];
  "model.layers.9.mlp.experts.51" -> "model.layers.9.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.51" -> "model.layers.9.mlp.experts.51.act_fn" [label="1"];
  "model.layers.9.mlp.experts.51" -> "model.layers.9.mlp.experts.51.up_proj" [label="1"];
  "model.layers.9.mlp.experts.51" -> "model.layers.9.mlp.experts.51.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.52" [label="1"];
  "model.layers.9.mlp.experts.52" -> "model.layers.9.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.52" -> "model.layers.9.mlp.experts.52.act_fn" [label="1"];
  "model.layers.9.mlp.experts.52" -> "model.layers.9.mlp.experts.52.up_proj" [label="1"];
  "model.layers.9.mlp.experts.52" -> "model.layers.9.mlp.experts.52.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.53" [label="1"];
  "model.layers.9.mlp.experts.53" -> "model.layers.9.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.53" -> "model.layers.9.mlp.experts.53.act_fn" [label="1"];
  "model.layers.9.mlp.experts.53" -> "model.layers.9.mlp.experts.53.up_proj" [label="1"];
  "model.layers.9.mlp.experts.53" -> "model.layers.9.mlp.experts.53.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.54" [label="1"];
  "model.layers.9.mlp.experts.54" -> "model.layers.9.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.54" -> "model.layers.9.mlp.experts.54.act_fn" [label="1"];
  "model.layers.9.mlp.experts.54" -> "model.layers.9.mlp.experts.54.up_proj" [label="1"];
  "model.layers.9.mlp.experts.54" -> "model.layers.9.mlp.experts.54.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.55" [label="1"];
  "model.layers.9.mlp.experts.55" -> "model.layers.9.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.55" -> "model.layers.9.mlp.experts.55.act_fn" [label="1"];
  "model.layers.9.mlp.experts.55" -> "model.layers.9.mlp.experts.55.up_proj" [label="1"];
  "model.layers.9.mlp.experts.55" -> "model.layers.9.mlp.experts.55.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.56" [label="1"];
  "model.layers.9.mlp.experts.56" -> "model.layers.9.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.56" -> "model.layers.9.mlp.experts.56.act_fn" [label="1"];
  "model.layers.9.mlp.experts.56" -> "model.layers.9.mlp.experts.56.up_proj" [label="1"];
  "model.layers.9.mlp.experts.56" -> "model.layers.9.mlp.experts.56.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.57" [label="1"];
  "model.layers.9.mlp.experts.57" -> "model.layers.9.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.57" -> "model.layers.9.mlp.experts.57.act_fn" [label="1"];
  "model.layers.9.mlp.experts.57" -> "model.layers.9.mlp.experts.57.up_proj" [label="1"];
  "model.layers.9.mlp.experts.57" -> "model.layers.9.mlp.experts.57.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.58" [label="1"];
  "model.layers.9.mlp.experts.58" -> "model.layers.9.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.58" -> "model.layers.9.mlp.experts.58.act_fn" [label="1"];
  "model.layers.9.mlp.experts.58" -> "model.layers.9.mlp.experts.58.up_proj" [label="1"];
  "model.layers.9.mlp.experts.58" -> "model.layers.9.mlp.experts.58.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.59" [label="1"];
  "model.layers.9.mlp.experts.59" -> "model.layers.9.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.59" -> "model.layers.9.mlp.experts.59.act_fn" [label="1"];
  "model.layers.9.mlp.experts.59" -> "model.layers.9.mlp.experts.59.up_proj" [label="1"];
  "model.layers.9.mlp.experts.59" -> "model.layers.9.mlp.experts.59.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.60" [label="1"];
  "model.layers.9.mlp.experts.60" -> "model.layers.9.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.60" -> "model.layers.9.mlp.experts.60.act_fn" [label="1"];
  "model.layers.9.mlp.experts.60" -> "model.layers.9.mlp.experts.60.up_proj" [label="1"];
  "model.layers.9.mlp.experts.60" -> "model.layers.9.mlp.experts.60.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.61" [label="1"];
  "model.layers.9.mlp.experts.61" -> "model.layers.9.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.61" -> "model.layers.9.mlp.experts.61.act_fn" [label="1"];
  "model.layers.9.mlp.experts.61" -> "model.layers.9.mlp.experts.61.up_proj" [label="1"];
  "model.layers.9.mlp.experts.61" -> "model.layers.9.mlp.experts.61.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.62" [label="1"];
  "model.layers.9.mlp.experts.62" -> "model.layers.9.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.62" -> "model.layers.9.mlp.experts.62.act_fn" [label="1"];
  "model.layers.9.mlp.experts.62" -> "model.layers.9.mlp.experts.62.up_proj" [label="1"];
  "model.layers.9.mlp.experts.62" -> "model.layers.9.mlp.experts.62.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.experts.63" [label="1"];
  "model.layers.9.mlp.experts.63" -> "model.layers.9.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.9.mlp.experts.63" -> "model.layers.9.mlp.experts.63.act_fn" [label="1"];
  "model.layers.9.mlp.experts.63" -> "model.layers.9.mlp.experts.63.up_proj" [label="1"];
  "model.layers.9.mlp.experts.63" -> "model.layers.9.mlp.experts.63.down_proj" [label="1"];
  "model.layers.9.mlp" -> "model.layers.9.mlp.shared_experts" [label="1"];
  "model.layers.9.mlp.shared_experts" -> "model.layers.9.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.9.mlp.shared_experts" -> "model.layers.9.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.9.mlp.shared_experts" -> "model.layers.9.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.9.mlp.shared_experts" -> "model.layers.9.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.10" [label="1"];
  "model.layers.10" -> "model.layers.10.input_layernorm" [label="1"];
  "model.layers.10" -> "model.layers.10.self_attn" [label="1"];
  "model.layers.10.self_attn" -> "model.layers.10.self_attn.q_proj" [label="1"];
  "model.layers.10.self_attn" -> "model.layers.10.self_attn.k_proj" [label="1"];
  "model.layers.10.self_attn" -> "model.layers.10.self_attn.v_proj" [label="1"];
  "model.layers.10.self_attn" -> "model.layers.10.self_attn.o_proj" [label="1"];
  "model.layers.10" -> "model.layers.10.post_attention_layernorm" [label="1"];
  "model.layers.10" -> "model.layers.10.mlp" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.gate" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.0" [label="1"];
  "model.layers.10.mlp.experts.0" -> "model.layers.10.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.0" -> "model.layers.10.mlp.experts.0.act_fn" [label="1"];
  "model.layers.10.mlp.experts.0" -> "model.layers.10.mlp.experts.0.up_proj" [label="1"];
  "model.layers.10.mlp.experts.0" -> "model.layers.10.mlp.experts.0.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.1" [label="1"];
  "model.layers.10.mlp.experts.1" -> "model.layers.10.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.1" -> "model.layers.10.mlp.experts.1.act_fn" [label="1"];
  "model.layers.10.mlp.experts.1" -> "model.layers.10.mlp.experts.1.up_proj" [label="1"];
  "model.layers.10.mlp.experts.1" -> "model.layers.10.mlp.experts.1.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.2" [label="1"];
  "model.layers.10.mlp.experts.2" -> "model.layers.10.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.2" -> "model.layers.10.mlp.experts.2.act_fn" [label="1"];
  "model.layers.10.mlp.experts.2" -> "model.layers.10.mlp.experts.2.up_proj" [label="1"];
  "model.layers.10.mlp.experts.2" -> "model.layers.10.mlp.experts.2.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.3" [label="1"];
  "model.layers.10.mlp.experts.3" -> "model.layers.10.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.3" -> "model.layers.10.mlp.experts.3.act_fn" [label="1"];
  "model.layers.10.mlp.experts.3" -> "model.layers.10.mlp.experts.3.up_proj" [label="1"];
  "model.layers.10.mlp.experts.3" -> "model.layers.10.mlp.experts.3.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.4" [label="1"];
  "model.layers.10.mlp.experts.4" -> "model.layers.10.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.4" -> "model.layers.10.mlp.experts.4.act_fn" [label="1"];
  "model.layers.10.mlp.experts.4" -> "model.layers.10.mlp.experts.4.up_proj" [label="1"];
  "model.layers.10.mlp.experts.4" -> "model.layers.10.mlp.experts.4.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.5" [label="1"];
  "model.layers.10.mlp.experts.5" -> "model.layers.10.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.5" -> "model.layers.10.mlp.experts.5.act_fn" [label="1"];
  "model.layers.10.mlp.experts.5" -> "model.layers.10.mlp.experts.5.up_proj" [label="1"];
  "model.layers.10.mlp.experts.5" -> "model.layers.10.mlp.experts.5.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.6" [label="1"];
  "model.layers.10.mlp.experts.6" -> "model.layers.10.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.6" -> "model.layers.10.mlp.experts.6.act_fn" [label="1"];
  "model.layers.10.mlp.experts.6" -> "model.layers.10.mlp.experts.6.up_proj" [label="1"];
  "model.layers.10.mlp.experts.6" -> "model.layers.10.mlp.experts.6.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.7" [label="1"];
  "model.layers.10.mlp.experts.7" -> "model.layers.10.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.7" -> "model.layers.10.mlp.experts.7.act_fn" [label="1"];
  "model.layers.10.mlp.experts.7" -> "model.layers.10.mlp.experts.7.up_proj" [label="1"];
  "model.layers.10.mlp.experts.7" -> "model.layers.10.mlp.experts.7.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.8" [label="1"];
  "model.layers.10.mlp.experts.8" -> "model.layers.10.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.8" -> "model.layers.10.mlp.experts.8.act_fn" [label="1"];
  "model.layers.10.mlp.experts.8" -> "model.layers.10.mlp.experts.8.up_proj" [label="1"];
  "model.layers.10.mlp.experts.8" -> "model.layers.10.mlp.experts.8.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.9" [label="1"];
  "model.layers.10.mlp.experts.9" -> "model.layers.10.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.9" -> "model.layers.10.mlp.experts.9.act_fn" [label="1"];
  "model.layers.10.mlp.experts.9" -> "model.layers.10.mlp.experts.9.up_proj" [label="1"];
  "model.layers.10.mlp.experts.9" -> "model.layers.10.mlp.experts.9.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.10" [label="1"];
  "model.layers.10.mlp.experts.10" -> "model.layers.10.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.10" -> "model.layers.10.mlp.experts.10.act_fn" [label="1"];
  "model.layers.10.mlp.experts.10" -> "model.layers.10.mlp.experts.10.up_proj" [label="1"];
  "model.layers.10.mlp.experts.10" -> "model.layers.10.mlp.experts.10.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.11" [label="1"];
  "model.layers.10.mlp.experts.11" -> "model.layers.10.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.11" -> "model.layers.10.mlp.experts.11.act_fn" [label="1"];
  "model.layers.10.mlp.experts.11" -> "model.layers.10.mlp.experts.11.up_proj" [label="1"];
  "model.layers.10.mlp.experts.11" -> "model.layers.10.mlp.experts.11.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.12" [label="1"];
  "model.layers.10.mlp.experts.12" -> "model.layers.10.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.12" -> "model.layers.10.mlp.experts.12.act_fn" [label="1"];
  "model.layers.10.mlp.experts.12" -> "model.layers.10.mlp.experts.12.up_proj" [label="1"];
  "model.layers.10.mlp.experts.12" -> "model.layers.10.mlp.experts.12.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.13" [label="1"];
  "model.layers.10.mlp.experts.13" -> "model.layers.10.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.13" -> "model.layers.10.mlp.experts.13.act_fn" [label="1"];
  "model.layers.10.mlp.experts.13" -> "model.layers.10.mlp.experts.13.up_proj" [label="1"];
  "model.layers.10.mlp.experts.13" -> "model.layers.10.mlp.experts.13.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.14" [label="1"];
  "model.layers.10.mlp.experts.14" -> "model.layers.10.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.14" -> "model.layers.10.mlp.experts.14.act_fn" [label="1"];
  "model.layers.10.mlp.experts.14" -> "model.layers.10.mlp.experts.14.up_proj" [label="1"];
  "model.layers.10.mlp.experts.14" -> "model.layers.10.mlp.experts.14.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.15" [label="1"];
  "model.layers.10.mlp.experts.15" -> "model.layers.10.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.15" -> "model.layers.10.mlp.experts.15.act_fn" [label="1"];
  "model.layers.10.mlp.experts.15" -> "model.layers.10.mlp.experts.15.up_proj" [label="1"];
  "model.layers.10.mlp.experts.15" -> "model.layers.10.mlp.experts.15.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.16" [label="1"];
  "model.layers.10.mlp.experts.16" -> "model.layers.10.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.16" -> "model.layers.10.mlp.experts.16.act_fn" [label="1"];
  "model.layers.10.mlp.experts.16" -> "model.layers.10.mlp.experts.16.up_proj" [label="1"];
  "model.layers.10.mlp.experts.16" -> "model.layers.10.mlp.experts.16.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.17" [label="1"];
  "model.layers.10.mlp.experts.17" -> "model.layers.10.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.17" -> "model.layers.10.mlp.experts.17.act_fn" [label="1"];
  "model.layers.10.mlp.experts.17" -> "model.layers.10.mlp.experts.17.up_proj" [label="1"];
  "model.layers.10.mlp.experts.17" -> "model.layers.10.mlp.experts.17.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.19" [label="1"];
  "model.layers.10.mlp.experts.19" -> "model.layers.10.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.19" -> "model.layers.10.mlp.experts.19.act_fn" [label="1"];
  "model.layers.10.mlp.experts.19" -> "model.layers.10.mlp.experts.19.up_proj" [label="1"];
  "model.layers.10.mlp.experts.19" -> "model.layers.10.mlp.experts.19.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.21" [label="1"];
  "model.layers.10.mlp.experts.21" -> "model.layers.10.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.21" -> "model.layers.10.mlp.experts.21.act_fn" [label="1"];
  "model.layers.10.mlp.experts.21" -> "model.layers.10.mlp.experts.21.up_proj" [label="1"];
  "model.layers.10.mlp.experts.21" -> "model.layers.10.mlp.experts.21.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.22" [label="1"];
  "model.layers.10.mlp.experts.22" -> "model.layers.10.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.22" -> "model.layers.10.mlp.experts.22.act_fn" [label="1"];
  "model.layers.10.mlp.experts.22" -> "model.layers.10.mlp.experts.22.up_proj" [label="1"];
  "model.layers.10.mlp.experts.22" -> "model.layers.10.mlp.experts.22.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.23" [label="1"];
  "model.layers.10.mlp.experts.23" -> "model.layers.10.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.23" -> "model.layers.10.mlp.experts.23.act_fn" [label="1"];
  "model.layers.10.mlp.experts.23" -> "model.layers.10.mlp.experts.23.up_proj" [label="1"];
  "model.layers.10.mlp.experts.23" -> "model.layers.10.mlp.experts.23.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.24" [label="1"];
  "model.layers.10.mlp.experts.24" -> "model.layers.10.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.24" -> "model.layers.10.mlp.experts.24.act_fn" [label="1"];
  "model.layers.10.mlp.experts.24" -> "model.layers.10.mlp.experts.24.up_proj" [label="1"];
  "model.layers.10.mlp.experts.24" -> "model.layers.10.mlp.experts.24.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.25" [label="1"];
  "model.layers.10.mlp.experts.25" -> "model.layers.10.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.25" -> "model.layers.10.mlp.experts.25.act_fn" [label="1"];
  "model.layers.10.mlp.experts.25" -> "model.layers.10.mlp.experts.25.up_proj" [label="1"];
  "model.layers.10.mlp.experts.25" -> "model.layers.10.mlp.experts.25.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.26" [label="1"];
  "model.layers.10.mlp.experts.26" -> "model.layers.10.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.26" -> "model.layers.10.mlp.experts.26.act_fn" [label="1"];
  "model.layers.10.mlp.experts.26" -> "model.layers.10.mlp.experts.26.up_proj" [label="1"];
  "model.layers.10.mlp.experts.26" -> "model.layers.10.mlp.experts.26.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.27" [label="1"];
  "model.layers.10.mlp.experts.27" -> "model.layers.10.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.27" -> "model.layers.10.mlp.experts.27.act_fn" [label="1"];
  "model.layers.10.mlp.experts.27" -> "model.layers.10.mlp.experts.27.up_proj" [label="1"];
  "model.layers.10.mlp.experts.27" -> "model.layers.10.mlp.experts.27.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.28" [label="1"];
  "model.layers.10.mlp.experts.28" -> "model.layers.10.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.28" -> "model.layers.10.mlp.experts.28.act_fn" [label="1"];
  "model.layers.10.mlp.experts.28" -> "model.layers.10.mlp.experts.28.up_proj" [label="1"];
  "model.layers.10.mlp.experts.28" -> "model.layers.10.mlp.experts.28.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.29" [label="1"];
  "model.layers.10.mlp.experts.29" -> "model.layers.10.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.29" -> "model.layers.10.mlp.experts.29.act_fn" [label="1"];
  "model.layers.10.mlp.experts.29" -> "model.layers.10.mlp.experts.29.up_proj" [label="1"];
  "model.layers.10.mlp.experts.29" -> "model.layers.10.mlp.experts.29.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.30" [label="1"];
  "model.layers.10.mlp.experts.30" -> "model.layers.10.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.30" -> "model.layers.10.mlp.experts.30.act_fn" [label="1"];
  "model.layers.10.mlp.experts.30" -> "model.layers.10.mlp.experts.30.up_proj" [label="1"];
  "model.layers.10.mlp.experts.30" -> "model.layers.10.mlp.experts.30.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.31" [label="1"];
  "model.layers.10.mlp.experts.31" -> "model.layers.10.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.31" -> "model.layers.10.mlp.experts.31.act_fn" [label="1"];
  "model.layers.10.mlp.experts.31" -> "model.layers.10.mlp.experts.31.up_proj" [label="1"];
  "model.layers.10.mlp.experts.31" -> "model.layers.10.mlp.experts.31.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.32" [label="1"];
  "model.layers.10.mlp.experts.32" -> "model.layers.10.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.32" -> "model.layers.10.mlp.experts.32.act_fn" [label="1"];
  "model.layers.10.mlp.experts.32" -> "model.layers.10.mlp.experts.32.up_proj" [label="1"];
  "model.layers.10.mlp.experts.32" -> "model.layers.10.mlp.experts.32.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.33" [label="1"];
  "model.layers.10.mlp.experts.33" -> "model.layers.10.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.33" -> "model.layers.10.mlp.experts.33.act_fn" [label="1"];
  "model.layers.10.mlp.experts.33" -> "model.layers.10.mlp.experts.33.up_proj" [label="1"];
  "model.layers.10.mlp.experts.33" -> "model.layers.10.mlp.experts.33.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.34" [label="1"];
  "model.layers.10.mlp.experts.34" -> "model.layers.10.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.34" -> "model.layers.10.mlp.experts.34.act_fn" [label="1"];
  "model.layers.10.mlp.experts.34" -> "model.layers.10.mlp.experts.34.up_proj" [label="1"];
  "model.layers.10.mlp.experts.34" -> "model.layers.10.mlp.experts.34.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.35" [label="1"];
  "model.layers.10.mlp.experts.35" -> "model.layers.10.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.35" -> "model.layers.10.mlp.experts.35.act_fn" [label="1"];
  "model.layers.10.mlp.experts.35" -> "model.layers.10.mlp.experts.35.up_proj" [label="1"];
  "model.layers.10.mlp.experts.35" -> "model.layers.10.mlp.experts.35.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.36" [label="1"];
  "model.layers.10.mlp.experts.36" -> "model.layers.10.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.36" -> "model.layers.10.mlp.experts.36.act_fn" [label="1"];
  "model.layers.10.mlp.experts.36" -> "model.layers.10.mlp.experts.36.up_proj" [label="1"];
  "model.layers.10.mlp.experts.36" -> "model.layers.10.mlp.experts.36.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.37" [label="1"];
  "model.layers.10.mlp.experts.37" -> "model.layers.10.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.37" -> "model.layers.10.mlp.experts.37.act_fn" [label="1"];
  "model.layers.10.mlp.experts.37" -> "model.layers.10.mlp.experts.37.up_proj" [label="1"];
  "model.layers.10.mlp.experts.37" -> "model.layers.10.mlp.experts.37.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.38" [label="1"];
  "model.layers.10.mlp.experts.38" -> "model.layers.10.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.38" -> "model.layers.10.mlp.experts.38.act_fn" [label="1"];
  "model.layers.10.mlp.experts.38" -> "model.layers.10.mlp.experts.38.up_proj" [label="1"];
  "model.layers.10.mlp.experts.38" -> "model.layers.10.mlp.experts.38.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.39" [label="1"];
  "model.layers.10.mlp.experts.39" -> "model.layers.10.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.39" -> "model.layers.10.mlp.experts.39.act_fn" [label="1"];
  "model.layers.10.mlp.experts.39" -> "model.layers.10.mlp.experts.39.up_proj" [label="1"];
  "model.layers.10.mlp.experts.39" -> "model.layers.10.mlp.experts.39.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.40" [label="1"];
  "model.layers.10.mlp.experts.40" -> "model.layers.10.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.40" -> "model.layers.10.mlp.experts.40.act_fn" [label="1"];
  "model.layers.10.mlp.experts.40" -> "model.layers.10.mlp.experts.40.up_proj" [label="1"];
  "model.layers.10.mlp.experts.40" -> "model.layers.10.mlp.experts.40.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.41" [label="1"];
  "model.layers.10.mlp.experts.41" -> "model.layers.10.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.41" -> "model.layers.10.mlp.experts.41.act_fn" [label="1"];
  "model.layers.10.mlp.experts.41" -> "model.layers.10.mlp.experts.41.up_proj" [label="1"];
  "model.layers.10.mlp.experts.41" -> "model.layers.10.mlp.experts.41.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.42" [label="1"];
  "model.layers.10.mlp.experts.42" -> "model.layers.10.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.42" -> "model.layers.10.mlp.experts.42.act_fn" [label="1"];
  "model.layers.10.mlp.experts.42" -> "model.layers.10.mlp.experts.42.up_proj" [label="1"];
  "model.layers.10.mlp.experts.42" -> "model.layers.10.mlp.experts.42.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.43" [label="1"];
  "model.layers.10.mlp.experts.43" -> "model.layers.10.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.43" -> "model.layers.10.mlp.experts.43.act_fn" [label="1"];
  "model.layers.10.mlp.experts.43" -> "model.layers.10.mlp.experts.43.up_proj" [label="1"];
  "model.layers.10.mlp.experts.43" -> "model.layers.10.mlp.experts.43.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.44" [label="1"];
  "model.layers.10.mlp.experts.44" -> "model.layers.10.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.44" -> "model.layers.10.mlp.experts.44.act_fn" [label="1"];
  "model.layers.10.mlp.experts.44" -> "model.layers.10.mlp.experts.44.up_proj" [label="1"];
  "model.layers.10.mlp.experts.44" -> "model.layers.10.mlp.experts.44.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.45" [label="1"];
  "model.layers.10.mlp.experts.45" -> "model.layers.10.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.45" -> "model.layers.10.mlp.experts.45.act_fn" [label="1"];
  "model.layers.10.mlp.experts.45" -> "model.layers.10.mlp.experts.45.up_proj" [label="1"];
  "model.layers.10.mlp.experts.45" -> "model.layers.10.mlp.experts.45.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.47" [label="1"];
  "model.layers.10.mlp.experts.47" -> "model.layers.10.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.47" -> "model.layers.10.mlp.experts.47.act_fn" [label="1"];
  "model.layers.10.mlp.experts.47" -> "model.layers.10.mlp.experts.47.up_proj" [label="1"];
  "model.layers.10.mlp.experts.47" -> "model.layers.10.mlp.experts.47.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.48" [label="1"];
  "model.layers.10.mlp.experts.48" -> "model.layers.10.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.48" -> "model.layers.10.mlp.experts.48.act_fn" [label="1"];
  "model.layers.10.mlp.experts.48" -> "model.layers.10.mlp.experts.48.up_proj" [label="1"];
  "model.layers.10.mlp.experts.48" -> "model.layers.10.mlp.experts.48.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.49" [label="1"];
  "model.layers.10.mlp.experts.49" -> "model.layers.10.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.49" -> "model.layers.10.mlp.experts.49.act_fn" [label="1"];
  "model.layers.10.mlp.experts.49" -> "model.layers.10.mlp.experts.49.up_proj" [label="1"];
  "model.layers.10.mlp.experts.49" -> "model.layers.10.mlp.experts.49.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.50" [label="1"];
  "model.layers.10.mlp.experts.50" -> "model.layers.10.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.50" -> "model.layers.10.mlp.experts.50.act_fn" [label="1"];
  "model.layers.10.mlp.experts.50" -> "model.layers.10.mlp.experts.50.up_proj" [label="1"];
  "model.layers.10.mlp.experts.50" -> "model.layers.10.mlp.experts.50.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.51" [label="1"];
  "model.layers.10.mlp.experts.51" -> "model.layers.10.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.51" -> "model.layers.10.mlp.experts.51.act_fn" [label="1"];
  "model.layers.10.mlp.experts.51" -> "model.layers.10.mlp.experts.51.up_proj" [label="1"];
  "model.layers.10.mlp.experts.51" -> "model.layers.10.mlp.experts.51.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.52" [label="1"];
  "model.layers.10.mlp.experts.52" -> "model.layers.10.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.52" -> "model.layers.10.mlp.experts.52.act_fn" [label="1"];
  "model.layers.10.mlp.experts.52" -> "model.layers.10.mlp.experts.52.up_proj" [label="1"];
  "model.layers.10.mlp.experts.52" -> "model.layers.10.mlp.experts.52.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.53" [label="1"];
  "model.layers.10.mlp.experts.53" -> "model.layers.10.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.53" -> "model.layers.10.mlp.experts.53.act_fn" [label="1"];
  "model.layers.10.mlp.experts.53" -> "model.layers.10.mlp.experts.53.up_proj" [label="1"];
  "model.layers.10.mlp.experts.53" -> "model.layers.10.mlp.experts.53.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.54" [label="1"];
  "model.layers.10.mlp.experts.54" -> "model.layers.10.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.54" -> "model.layers.10.mlp.experts.54.act_fn" [label="1"];
  "model.layers.10.mlp.experts.54" -> "model.layers.10.mlp.experts.54.up_proj" [label="1"];
  "model.layers.10.mlp.experts.54" -> "model.layers.10.mlp.experts.54.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.55" [label="1"];
  "model.layers.10.mlp.experts.55" -> "model.layers.10.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.55" -> "model.layers.10.mlp.experts.55.act_fn" [label="1"];
  "model.layers.10.mlp.experts.55" -> "model.layers.10.mlp.experts.55.up_proj" [label="1"];
  "model.layers.10.mlp.experts.55" -> "model.layers.10.mlp.experts.55.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.56" [label="1"];
  "model.layers.10.mlp.experts.56" -> "model.layers.10.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.56" -> "model.layers.10.mlp.experts.56.act_fn" [label="1"];
  "model.layers.10.mlp.experts.56" -> "model.layers.10.mlp.experts.56.up_proj" [label="1"];
  "model.layers.10.mlp.experts.56" -> "model.layers.10.mlp.experts.56.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.57" [label="1"];
  "model.layers.10.mlp.experts.57" -> "model.layers.10.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.57" -> "model.layers.10.mlp.experts.57.act_fn" [label="1"];
  "model.layers.10.mlp.experts.57" -> "model.layers.10.mlp.experts.57.up_proj" [label="1"];
  "model.layers.10.mlp.experts.57" -> "model.layers.10.mlp.experts.57.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.58" [label="1"];
  "model.layers.10.mlp.experts.58" -> "model.layers.10.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.58" -> "model.layers.10.mlp.experts.58.act_fn" [label="1"];
  "model.layers.10.mlp.experts.58" -> "model.layers.10.mlp.experts.58.up_proj" [label="1"];
  "model.layers.10.mlp.experts.58" -> "model.layers.10.mlp.experts.58.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.59" [label="1"];
  "model.layers.10.mlp.experts.59" -> "model.layers.10.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.59" -> "model.layers.10.mlp.experts.59.act_fn" [label="1"];
  "model.layers.10.mlp.experts.59" -> "model.layers.10.mlp.experts.59.up_proj" [label="1"];
  "model.layers.10.mlp.experts.59" -> "model.layers.10.mlp.experts.59.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.60" [label="1"];
  "model.layers.10.mlp.experts.60" -> "model.layers.10.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.60" -> "model.layers.10.mlp.experts.60.act_fn" [label="1"];
  "model.layers.10.mlp.experts.60" -> "model.layers.10.mlp.experts.60.up_proj" [label="1"];
  "model.layers.10.mlp.experts.60" -> "model.layers.10.mlp.experts.60.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.61" [label="1"];
  "model.layers.10.mlp.experts.61" -> "model.layers.10.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.61" -> "model.layers.10.mlp.experts.61.act_fn" [label="1"];
  "model.layers.10.mlp.experts.61" -> "model.layers.10.mlp.experts.61.up_proj" [label="1"];
  "model.layers.10.mlp.experts.61" -> "model.layers.10.mlp.experts.61.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.62" [label="1"];
  "model.layers.10.mlp.experts.62" -> "model.layers.10.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.62" -> "model.layers.10.mlp.experts.62.act_fn" [label="1"];
  "model.layers.10.mlp.experts.62" -> "model.layers.10.mlp.experts.62.up_proj" [label="1"];
  "model.layers.10.mlp.experts.62" -> "model.layers.10.mlp.experts.62.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.experts.63" [label="1"];
  "model.layers.10.mlp.experts.63" -> "model.layers.10.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.10.mlp.experts.63" -> "model.layers.10.mlp.experts.63.act_fn" [label="1"];
  "model.layers.10.mlp.experts.63" -> "model.layers.10.mlp.experts.63.up_proj" [label="1"];
  "model.layers.10.mlp.experts.63" -> "model.layers.10.mlp.experts.63.down_proj" [label="1"];
  "model.layers.10.mlp" -> "model.layers.10.mlp.shared_experts" [label="1"];
  "model.layers.10.mlp.shared_experts" -> "model.layers.10.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.10.mlp.shared_experts" -> "model.layers.10.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.10.mlp.shared_experts" -> "model.layers.10.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.10.mlp.shared_experts" -> "model.layers.10.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.layers.11" [label="1"];
  "model.layers.11" -> "model.layers.11.input_layernorm" [label="1"];
  "model.layers.11" -> "model.layers.11.self_attn" [label="1"];
  "model.layers.11.self_attn" -> "model.layers.11.self_attn.q_proj" [label="1"];
  "model.layers.11.self_attn" -> "model.layers.11.self_attn.k_proj" [label="1"];
  "model.layers.11.self_attn" -> "model.layers.11.self_attn.v_proj" [label="1"];
  "model.layers.11.self_attn" -> "model.layers.11.self_attn.o_proj" [label="1"];
  "model.layers.11" -> "model.layers.11.post_attention_layernorm" [label="1"];
  "model.layers.11" -> "model.layers.11.mlp" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.gate" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.0" [label="1"];
  "model.layers.11.mlp.experts.0" -> "model.layers.11.mlp.experts.0.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.0" -> "model.layers.11.mlp.experts.0.act_fn" [label="1"];
  "model.layers.11.mlp.experts.0" -> "model.layers.11.mlp.experts.0.up_proj" [label="1"];
  "model.layers.11.mlp.experts.0" -> "model.layers.11.mlp.experts.0.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.1" [label="1"];
  "model.layers.11.mlp.experts.1" -> "model.layers.11.mlp.experts.1.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.1" -> "model.layers.11.mlp.experts.1.act_fn" [label="1"];
  "model.layers.11.mlp.experts.1" -> "model.layers.11.mlp.experts.1.up_proj" [label="1"];
  "model.layers.11.mlp.experts.1" -> "model.layers.11.mlp.experts.1.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.2" [label="1"];
  "model.layers.11.mlp.experts.2" -> "model.layers.11.mlp.experts.2.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.2" -> "model.layers.11.mlp.experts.2.act_fn" [label="1"];
  "model.layers.11.mlp.experts.2" -> "model.layers.11.mlp.experts.2.up_proj" [label="1"];
  "model.layers.11.mlp.experts.2" -> "model.layers.11.mlp.experts.2.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.3" [label="1"];
  "model.layers.11.mlp.experts.3" -> "model.layers.11.mlp.experts.3.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.3" -> "model.layers.11.mlp.experts.3.act_fn" [label="1"];
  "model.layers.11.mlp.experts.3" -> "model.layers.11.mlp.experts.3.up_proj" [label="1"];
  "model.layers.11.mlp.experts.3" -> "model.layers.11.mlp.experts.3.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.4" [label="1"];
  "model.layers.11.mlp.experts.4" -> "model.layers.11.mlp.experts.4.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.4" -> "model.layers.11.mlp.experts.4.act_fn" [label="1"];
  "model.layers.11.mlp.experts.4" -> "model.layers.11.mlp.experts.4.up_proj" [label="1"];
  "model.layers.11.mlp.experts.4" -> "model.layers.11.mlp.experts.4.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.5" [label="1"];
  "model.layers.11.mlp.experts.5" -> "model.layers.11.mlp.experts.5.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.5" -> "model.layers.11.mlp.experts.5.act_fn" [label="1"];
  "model.layers.11.mlp.experts.5" -> "model.layers.11.mlp.experts.5.up_proj" [label="1"];
  "model.layers.11.mlp.experts.5" -> "model.layers.11.mlp.experts.5.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.6" [label="1"];
  "model.layers.11.mlp.experts.6" -> "model.layers.11.mlp.experts.6.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.6" -> "model.layers.11.mlp.experts.6.act_fn" [label="1"];
  "model.layers.11.mlp.experts.6" -> "model.layers.11.mlp.experts.6.up_proj" [label="1"];
  "model.layers.11.mlp.experts.6" -> "model.layers.11.mlp.experts.6.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.7" [label="1"];
  "model.layers.11.mlp.experts.7" -> "model.layers.11.mlp.experts.7.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.7" -> "model.layers.11.mlp.experts.7.act_fn" [label="1"];
  "model.layers.11.mlp.experts.7" -> "model.layers.11.mlp.experts.7.up_proj" [label="1"];
  "model.layers.11.mlp.experts.7" -> "model.layers.11.mlp.experts.7.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.8" [label="1"];
  "model.layers.11.mlp.experts.8" -> "model.layers.11.mlp.experts.8.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.8" -> "model.layers.11.mlp.experts.8.act_fn" [label="1"];
  "model.layers.11.mlp.experts.8" -> "model.layers.11.mlp.experts.8.up_proj" [label="1"];
  "model.layers.11.mlp.experts.8" -> "model.layers.11.mlp.experts.8.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.9" [label="1"];
  "model.layers.11.mlp.experts.9" -> "model.layers.11.mlp.experts.9.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.9" -> "model.layers.11.mlp.experts.9.act_fn" [label="1"];
  "model.layers.11.mlp.experts.9" -> "model.layers.11.mlp.experts.9.up_proj" [label="1"];
  "model.layers.11.mlp.experts.9" -> "model.layers.11.mlp.experts.9.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.10" [label="1"];
  "model.layers.11.mlp.experts.10" -> "model.layers.11.mlp.experts.10.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.10" -> "model.layers.11.mlp.experts.10.act_fn" [label="1"];
  "model.layers.11.mlp.experts.10" -> "model.layers.11.mlp.experts.10.up_proj" [label="1"];
  "model.layers.11.mlp.experts.10" -> "model.layers.11.mlp.experts.10.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.11" [label="1"];
  "model.layers.11.mlp.experts.11" -> "model.layers.11.mlp.experts.11.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.11" -> "model.layers.11.mlp.experts.11.act_fn" [label="1"];
  "model.layers.11.mlp.experts.11" -> "model.layers.11.mlp.experts.11.up_proj" [label="1"];
  "model.layers.11.mlp.experts.11" -> "model.layers.11.mlp.experts.11.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.12" [label="1"];
  "model.layers.11.mlp.experts.12" -> "model.layers.11.mlp.experts.12.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.12" -> "model.layers.11.mlp.experts.12.act_fn" [label="1"];
  "model.layers.11.mlp.experts.12" -> "model.layers.11.mlp.experts.12.up_proj" [label="1"];
  "model.layers.11.mlp.experts.12" -> "model.layers.11.mlp.experts.12.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.13" [label="1"];
  "model.layers.11.mlp.experts.13" -> "model.layers.11.mlp.experts.13.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.13" -> "model.layers.11.mlp.experts.13.act_fn" [label="1"];
  "model.layers.11.mlp.experts.13" -> "model.layers.11.mlp.experts.13.up_proj" [label="1"];
  "model.layers.11.mlp.experts.13" -> "model.layers.11.mlp.experts.13.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.14" [label="1"];
  "model.layers.11.mlp.experts.14" -> "model.layers.11.mlp.experts.14.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.14" -> "model.layers.11.mlp.experts.14.act_fn" [label="1"];
  "model.layers.11.mlp.experts.14" -> "model.layers.11.mlp.experts.14.up_proj" [label="1"];
  "model.layers.11.mlp.experts.14" -> "model.layers.11.mlp.experts.14.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.15" [label="1"];
  "model.layers.11.mlp.experts.15" -> "model.layers.11.mlp.experts.15.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.15" -> "model.layers.11.mlp.experts.15.act_fn" [label="1"];
  "model.layers.11.mlp.experts.15" -> "model.layers.11.mlp.experts.15.up_proj" [label="1"];
  "model.layers.11.mlp.experts.15" -> "model.layers.11.mlp.experts.15.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.16" [label="1"];
  "model.layers.11.mlp.experts.16" -> "model.layers.11.mlp.experts.16.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.16" -> "model.layers.11.mlp.experts.16.act_fn" [label="1"];
  "model.layers.11.mlp.experts.16" -> "model.layers.11.mlp.experts.16.up_proj" [label="1"];
  "model.layers.11.mlp.experts.16" -> "model.layers.11.mlp.experts.16.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.17" [label="1"];
  "model.layers.11.mlp.experts.17" -> "model.layers.11.mlp.experts.17.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.17" -> "model.layers.11.mlp.experts.17.act_fn" [label="1"];
  "model.layers.11.mlp.experts.17" -> "model.layers.11.mlp.experts.17.up_proj" [label="1"];
  "model.layers.11.mlp.experts.17" -> "model.layers.11.mlp.experts.17.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.18" [label="1"];
  "model.layers.11.mlp.experts.18" -> "model.layers.11.mlp.experts.18.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.18" -> "model.layers.11.mlp.experts.18.act_fn" [label="1"];
  "model.layers.11.mlp.experts.18" -> "model.layers.11.mlp.experts.18.up_proj" [label="1"];
  "model.layers.11.mlp.experts.18" -> "model.layers.11.mlp.experts.18.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.19" [label="1"];
  "model.layers.11.mlp.experts.19" -> "model.layers.11.mlp.experts.19.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.19" -> "model.layers.11.mlp.experts.19.act_fn" [label="1"];
  "model.layers.11.mlp.experts.19" -> "model.layers.11.mlp.experts.19.up_proj" [label="1"];
  "model.layers.11.mlp.experts.19" -> "model.layers.11.mlp.experts.19.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.20" [label="1"];
  "model.layers.11.mlp.experts.20" -> "model.layers.11.mlp.experts.20.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.20" -> "model.layers.11.mlp.experts.20.act_fn" [label="1"];
  "model.layers.11.mlp.experts.20" -> "model.layers.11.mlp.experts.20.up_proj" [label="1"];
  "model.layers.11.mlp.experts.20" -> "model.layers.11.mlp.experts.20.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.21" [label="1"];
  "model.layers.11.mlp.experts.21" -> "model.layers.11.mlp.experts.21.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.21" -> "model.layers.11.mlp.experts.21.act_fn" [label="1"];
  "model.layers.11.mlp.experts.21" -> "model.layers.11.mlp.experts.21.up_proj" [label="1"];
  "model.layers.11.mlp.experts.21" -> "model.layers.11.mlp.experts.21.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.22" [label="1"];
  "model.layers.11.mlp.experts.22" -> "model.layers.11.mlp.experts.22.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.22" -> "model.layers.11.mlp.experts.22.act_fn" [label="1"];
  "model.layers.11.mlp.experts.22" -> "model.layers.11.mlp.experts.22.up_proj" [label="1"];
  "model.layers.11.mlp.experts.22" -> "model.layers.11.mlp.experts.22.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.23" [label="1"];
  "model.layers.11.mlp.experts.23" -> "model.layers.11.mlp.experts.23.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.23" -> "model.layers.11.mlp.experts.23.act_fn" [label="1"];
  "model.layers.11.mlp.experts.23" -> "model.layers.11.mlp.experts.23.up_proj" [label="1"];
  "model.layers.11.mlp.experts.23" -> "model.layers.11.mlp.experts.23.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.24" [label="1"];
  "model.layers.11.mlp.experts.24" -> "model.layers.11.mlp.experts.24.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.24" -> "model.layers.11.mlp.experts.24.act_fn" [label="1"];
  "model.layers.11.mlp.experts.24" -> "model.layers.11.mlp.experts.24.up_proj" [label="1"];
  "model.layers.11.mlp.experts.24" -> "model.layers.11.mlp.experts.24.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.25" [label="1"];
  "model.layers.11.mlp.experts.25" -> "model.layers.11.mlp.experts.25.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.25" -> "model.layers.11.mlp.experts.25.act_fn" [label="1"];
  "model.layers.11.mlp.experts.25" -> "model.layers.11.mlp.experts.25.up_proj" [label="1"];
  "model.layers.11.mlp.experts.25" -> "model.layers.11.mlp.experts.25.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.26" [label="1"];
  "model.layers.11.mlp.experts.26" -> "model.layers.11.mlp.experts.26.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.26" -> "model.layers.11.mlp.experts.26.act_fn" [label="1"];
  "model.layers.11.mlp.experts.26" -> "model.layers.11.mlp.experts.26.up_proj" [label="1"];
  "model.layers.11.mlp.experts.26" -> "model.layers.11.mlp.experts.26.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.27" [label="1"];
  "model.layers.11.mlp.experts.27" -> "model.layers.11.mlp.experts.27.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.27" -> "model.layers.11.mlp.experts.27.act_fn" [label="1"];
  "model.layers.11.mlp.experts.27" -> "model.layers.11.mlp.experts.27.up_proj" [label="1"];
  "model.layers.11.mlp.experts.27" -> "model.layers.11.mlp.experts.27.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.28" [label="1"];
  "model.layers.11.mlp.experts.28" -> "model.layers.11.mlp.experts.28.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.28" -> "model.layers.11.mlp.experts.28.act_fn" [label="1"];
  "model.layers.11.mlp.experts.28" -> "model.layers.11.mlp.experts.28.up_proj" [label="1"];
  "model.layers.11.mlp.experts.28" -> "model.layers.11.mlp.experts.28.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.29" [label="1"];
  "model.layers.11.mlp.experts.29" -> "model.layers.11.mlp.experts.29.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.29" -> "model.layers.11.mlp.experts.29.act_fn" [label="1"];
  "model.layers.11.mlp.experts.29" -> "model.layers.11.mlp.experts.29.up_proj" [label="1"];
  "model.layers.11.mlp.experts.29" -> "model.layers.11.mlp.experts.29.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.30" [label="1"];
  "model.layers.11.mlp.experts.30" -> "model.layers.11.mlp.experts.30.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.30" -> "model.layers.11.mlp.experts.30.act_fn" [label="1"];
  "model.layers.11.mlp.experts.30" -> "model.layers.11.mlp.experts.30.up_proj" [label="1"];
  "model.layers.11.mlp.experts.30" -> "model.layers.11.mlp.experts.30.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.31" [label="1"];
  "model.layers.11.mlp.experts.31" -> "model.layers.11.mlp.experts.31.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.31" -> "model.layers.11.mlp.experts.31.act_fn" [label="1"];
  "model.layers.11.mlp.experts.31" -> "model.layers.11.mlp.experts.31.up_proj" [label="1"];
  "model.layers.11.mlp.experts.31" -> "model.layers.11.mlp.experts.31.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.32" [label="1"];
  "model.layers.11.mlp.experts.32" -> "model.layers.11.mlp.experts.32.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.32" -> "model.layers.11.mlp.experts.32.act_fn" [label="1"];
  "model.layers.11.mlp.experts.32" -> "model.layers.11.mlp.experts.32.up_proj" [label="1"];
  "model.layers.11.mlp.experts.32" -> "model.layers.11.mlp.experts.32.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.33" [label="1"];
  "model.layers.11.mlp.experts.33" -> "model.layers.11.mlp.experts.33.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.33" -> "model.layers.11.mlp.experts.33.act_fn" [label="1"];
  "model.layers.11.mlp.experts.33" -> "model.layers.11.mlp.experts.33.up_proj" [label="1"];
  "model.layers.11.mlp.experts.33" -> "model.layers.11.mlp.experts.33.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.34" [label="1"];
  "model.layers.11.mlp.experts.34" -> "model.layers.11.mlp.experts.34.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.34" -> "model.layers.11.mlp.experts.34.act_fn" [label="1"];
  "model.layers.11.mlp.experts.34" -> "model.layers.11.mlp.experts.34.up_proj" [label="1"];
  "model.layers.11.mlp.experts.34" -> "model.layers.11.mlp.experts.34.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.35" [label="1"];
  "model.layers.11.mlp.experts.35" -> "model.layers.11.mlp.experts.35.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.35" -> "model.layers.11.mlp.experts.35.act_fn" [label="1"];
  "model.layers.11.mlp.experts.35" -> "model.layers.11.mlp.experts.35.up_proj" [label="1"];
  "model.layers.11.mlp.experts.35" -> "model.layers.11.mlp.experts.35.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.36" [label="1"];
  "model.layers.11.mlp.experts.36" -> "model.layers.11.mlp.experts.36.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.36" -> "model.layers.11.mlp.experts.36.act_fn" [label="1"];
  "model.layers.11.mlp.experts.36" -> "model.layers.11.mlp.experts.36.up_proj" [label="1"];
  "model.layers.11.mlp.experts.36" -> "model.layers.11.mlp.experts.36.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.37" [label="1"];
  "model.layers.11.mlp.experts.37" -> "model.layers.11.mlp.experts.37.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.37" -> "model.layers.11.mlp.experts.37.act_fn" [label="1"];
  "model.layers.11.mlp.experts.37" -> "model.layers.11.mlp.experts.37.up_proj" [label="1"];
  "model.layers.11.mlp.experts.37" -> "model.layers.11.mlp.experts.37.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.38" [label="1"];
  "model.layers.11.mlp.experts.38" -> "model.layers.11.mlp.experts.38.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.38" -> "model.layers.11.mlp.experts.38.act_fn" [label="1"];
  "model.layers.11.mlp.experts.38" -> "model.layers.11.mlp.experts.38.up_proj" [label="1"];
  "model.layers.11.mlp.experts.38" -> "model.layers.11.mlp.experts.38.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.39" [label="1"];
  "model.layers.11.mlp.experts.39" -> "model.layers.11.mlp.experts.39.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.39" -> "model.layers.11.mlp.experts.39.act_fn" [label="1"];
  "model.layers.11.mlp.experts.39" -> "model.layers.11.mlp.experts.39.up_proj" [label="1"];
  "model.layers.11.mlp.experts.39" -> "model.layers.11.mlp.experts.39.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.40" [label="1"];
  "model.layers.11.mlp.experts.40" -> "model.layers.11.mlp.experts.40.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.40" -> "model.layers.11.mlp.experts.40.act_fn" [label="1"];
  "model.layers.11.mlp.experts.40" -> "model.layers.11.mlp.experts.40.up_proj" [label="1"];
  "model.layers.11.mlp.experts.40" -> "model.layers.11.mlp.experts.40.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.41" [label="1"];
  "model.layers.11.mlp.experts.41" -> "model.layers.11.mlp.experts.41.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.41" -> "model.layers.11.mlp.experts.41.act_fn" [label="1"];
  "model.layers.11.mlp.experts.41" -> "model.layers.11.mlp.experts.41.up_proj" [label="1"];
  "model.layers.11.mlp.experts.41" -> "model.layers.11.mlp.experts.41.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.42" [label="1"];
  "model.layers.11.mlp.experts.42" -> "model.layers.11.mlp.experts.42.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.42" -> "model.layers.11.mlp.experts.42.act_fn" [label="1"];
  "model.layers.11.mlp.experts.42" -> "model.layers.11.mlp.experts.42.up_proj" [label="1"];
  "model.layers.11.mlp.experts.42" -> "model.layers.11.mlp.experts.42.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.43" [label="1"];
  "model.layers.11.mlp.experts.43" -> "model.layers.11.mlp.experts.43.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.43" -> "model.layers.11.mlp.experts.43.act_fn" [label="1"];
  "model.layers.11.mlp.experts.43" -> "model.layers.11.mlp.experts.43.up_proj" [label="1"];
  "model.layers.11.mlp.experts.43" -> "model.layers.11.mlp.experts.43.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.44" [label="1"];
  "model.layers.11.mlp.experts.44" -> "model.layers.11.mlp.experts.44.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.44" -> "model.layers.11.mlp.experts.44.act_fn" [label="1"];
  "model.layers.11.mlp.experts.44" -> "model.layers.11.mlp.experts.44.up_proj" [label="1"];
  "model.layers.11.mlp.experts.44" -> "model.layers.11.mlp.experts.44.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.45" [label="1"];
  "model.layers.11.mlp.experts.45" -> "model.layers.11.mlp.experts.45.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.45" -> "model.layers.11.mlp.experts.45.act_fn" [label="1"];
  "model.layers.11.mlp.experts.45" -> "model.layers.11.mlp.experts.45.up_proj" [label="1"];
  "model.layers.11.mlp.experts.45" -> "model.layers.11.mlp.experts.45.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.46" [label="1"];
  "model.layers.11.mlp.experts.46" -> "model.layers.11.mlp.experts.46.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.46" -> "model.layers.11.mlp.experts.46.act_fn" [label="1"];
  "model.layers.11.mlp.experts.46" -> "model.layers.11.mlp.experts.46.up_proj" [label="1"];
  "model.layers.11.mlp.experts.46" -> "model.layers.11.mlp.experts.46.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.47" [label="1"];
  "model.layers.11.mlp.experts.47" -> "model.layers.11.mlp.experts.47.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.47" -> "model.layers.11.mlp.experts.47.act_fn" [label="1"];
  "model.layers.11.mlp.experts.47" -> "model.layers.11.mlp.experts.47.up_proj" [label="1"];
  "model.layers.11.mlp.experts.47" -> "model.layers.11.mlp.experts.47.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.48" [label="1"];
  "model.layers.11.mlp.experts.48" -> "model.layers.11.mlp.experts.48.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.48" -> "model.layers.11.mlp.experts.48.act_fn" [label="1"];
  "model.layers.11.mlp.experts.48" -> "model.layers.11.mlp.experts.48.up_proj" [label="1"];
  "model.layers.11.mlp.experts.48" -> "model.layers.11.mlp.experts.48.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.49" [label="1"];
  "model.layers.11.mlp.experts.49" -> "model.layers.11.mlp.experts.49.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.49" -> "model.layers.11.mlp.experts.49.act_fn" [label="1"];
  "model.layers.11.mlp.experts.49" -> "model.layers.11.mlp.experts.49.up_proj" [label="1"];
  "model.layers.11.mlp.experts.49" -> "model.layers.11.mlp.experts.49.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.50" [label="1"];
  "model.layers.11.mlp.experts.50" -> "model.layers.11.mlp.experts.50.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.50" -> "model.layers.11.mlp.experts.50.act_fn" [label="1"];
  "model.layers.11.mlp.experts.50" -> "model.layers.11.mlp.experts.50.up_proj" [label="1"];
  "model.layers.11.mlp.experts.50" -> "model.layers.11.mlp.experts.50.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.51" [label="1"];
  "model.layers.11.mlp.experts.51" -> "model.layers.11.mlp.experts.51.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.51" -> "model.layers.11.mlp.experts.51.act_fn" [label="1"];
  "model.layers.11.mlp.experts.51" -> "model.layers.11.mlp.experts.51.up_proj" [label="1"];
  "model.layers.11.mlp.experts.51" -> "model.layers.11.mlp.experts.51.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.52" [label="1"];
  "model.layers.11.mlp.experts.52" -> "model.layers.11.mlp.experts.52.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.52" -> "model.layers.11.mlp.experts.52.act_fn" [label="1"];
  "model.layers.11.mlp.experts.52" -> "model.layers.11.mlp.experts.52.up_proj" [label="1"];
  "model.layers.11.mlp.experts.52" -> "model.layers.11.mlp.experts.52.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.53" [label="1"];
  "model.layers.11.mlp.experts.53" -> "model.layers.11.mlp.experts.53.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.53" -> "model.layers.11.mlp.experts.53.act_fn" [label="1"];
  "model.layers.11.mlp.experts.53" -> "model.layers.11.mlp.experts.53.up_proj" [label="1"];
  "model.layers.11.mlp.experts.53" -> "model.layers.11.mlp.experts.53.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.54" [label="1"];
  "model.layers.11.mlp.experts.54" -> "model.layers.11.mlp.experts.54.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.54" -> "model.layers.11.mlp.experts.54.act_fn" [label="1"];
  "model.layers.11.mlp.experts.54" -> "model.layers.11.mlp.experts.54.up_proj" [label="1"];
  "model.layers.11.mlp.experts.54" -> "model.layers.11.mlp.experts.54.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.55" [label="1"];
  "model.layers.11.mlp.experts.55" -> "model.layers.11.mlp.experts.55.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.55" -> "model.layers.11.mlp.experts.55.act_fn" [label="1"];
  "model.layers.11.mlp.experts.55" -> "model.layers.11.mlp.experts.55.up_proj" [label="1"];
  "model.layers.11.mlp.experts.55" -> "model.layers.11.mlp.experts.55.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.56" [label="1"];
  "model.layers.11.mlp.experts.56" -> "model.layers.11.mlp.experts.56.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.56" -> "model.layers.11.mlp.experts.56.act_fn" [label="1"];
  "model.layers.11.mlp.experts.56" -> "model.layers.11.mlp.experts.56.up_proj" [label="1"];
  "model.layers.11.mlp.experts.56" -> "model.layers.11.mlp.experts.56.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.57" [label="1"];
  "model.layers.11.mlp.experts.57" -> "model.layers.11.mlp.experts.57.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.57" -> "model.layers.11.mlp.experts.57.act_fn" [label="1"];
  "model.layers.11.mlp.experts.57" -> "model.layers.11.mlp.experts.57.up_proj" [label="1"];
  "model.layers.11.mlp.experts.57" -> "model.layers.11.mlp.experts.57.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.58" [label="1"];
  "model.layers.11.mlp.experts.58" -> "model.layers.11.mlp.experts.58.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.58" -> "model.layers.11.mlp.experts.58.act_fn" [label="1"];
  "model.layers.11.mlp.experts.58" -> "model.layers.11.mlp.experts.58.up_proj" [label="1"];
  "model.layers.11.mlp.experts.58" -> "model.layers.11.mlp.experts.58.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.59" [label="1"];
  "model.layers.11.mlp.experts.59" -> "model.layers.11.mlp.experts.59.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.59" -> "model.layers.11.mlp.experts.59.act_fn" [label="1"];
  "model.layers.11.mlp.experts.59" -> "model.layers.11.mlp.experts.59.up_proj" [label="1"];
  "model.layers.11.mlp.experts.59" -> "model.layers.11.mlp.experts.59.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.60" [label="1"];
  "model.layers.11.mlp.experts.60" -> "model.layers.11.mlp.experts.60.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.60" -> "model.layers.11.mlp.experts.60.act_fn" [label="1"];
  "model.layers.11.mlp.experts.60" -> "model.layers.11.mlp.experts.60.up_proj" [label="1"];
  "model.layers.11.mlp.experts.60" -> "model.layers.11.mlp.experts.60.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.61" [label="1"];
  "model.layers.11.mlp.experts.61" -> "model.layers.11.mlp.experts.61.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.61" -> "model.layers.11.mlp.experts.61.act_fn" [label="1"];
  "model.layers.11.mlp.experts.61" -> "model.layers.11.mlp.experts.61.up_proj" [label="1"];
  "model.layers.11.mlp.experts.61" -> "model.layers.11.mlp.experts.61.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.62" [label="1"];
  "model.layers.11.mlp.experts.62" -> "model.layers.11.mlp.experts.62.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.62" -> "model.layers.11.mlp.experts.62.act_fn" [label="1"];
  "model.layers.11.mlp.experts.62" -> "model.layers.11.mlp.experts.62.up_proj" [label="1"];
  "model.layers.11.mlp.experts.62" -> "model.layers.11.mlp.experts.62.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.experts.63" [label="1"];
  "model.layers.11.mlp.experts.63" -> "model.layers.11.mlp.experts.63.gate_proj" [label="1"];
  "model.layers.11.mlp.experts.63" -> "model.layers.11.mlp.experts.63.act_fn" [label="1"];
  "model.layers.11.mlp.experts.63" -> "model.layers.11.mlp.experts.63.up_proj" [label="1"];
  "model.layers.11.mlp.experts.63" -> "model.layers.11.mlp.experts.63.down_proj" [label="1"];
  "model.layers.11.mlp" -> "model.layers.11.mlp.shared_experts" [label="1"];
  "model.layers.11.mlp.shared_experts" -> "model.layers.11.mlp.shared_experts.gate_proj" [label="1"];
  "model.layers.11.mlp.shared_experts" -> "model.layers.11.mlp.shared_experts.act_fn" [label="1"];
  "model.layers.11.mlp.shared_experts" -> "model.layers.11.mlp.shared_experts.up_proj" [label="1"];
  "model.layers.11.mlp.shared_experts" -> "model.layers.11.mlp.shared_experts.down_proj" [label="1"];
  "model" -> "model.norm" [label="1"];
}