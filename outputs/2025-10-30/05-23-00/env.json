{
  "gpu": "NVIDIA GeForce RTX 3090",
  "cuda": "12.4",
  "torch": "2.6.0+cu124",
  "transformers": "4.46.3"
}